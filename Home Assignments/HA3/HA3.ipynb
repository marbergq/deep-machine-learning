{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checklist for submission\n",
    "\n",
    "It is extremely important to make sure that:\n",
    "\n",
    "1. Everything runs as expected (no bugs when running cells);\n",
    "2. The output from each cell corresponds to its code (don't change any cell's contents without rerunning it afterwards);\n",
    "3. All outputs are present (don't delete any of the outputs);\n",
    "4. Fill in all the places that say `# YOUR CODE HERE`, or \"**Your answer:** (fill in here)\".\n",
    "5. You should not need to create any new cells in the notebook, but feel free to do it if convenient for you.\n",
    "6. The notebook contains some hidden metadata which is important during our grading process. **Make sure not to corrupt any of this metadata!** The metadata may be corrupted if you perform an unsuccessful git merge / git pull. It may also be pruned completely if using Google Colab, so watch out for this. Searching for \"nbgrader\" when opening the notebook in a text editor should take you to the important metadata entries.\n",
    "7. Fill in your group number and the full names of the members in the cell below;\n",
    "8. Make sure that you are not running an old version of IPython (we provide you with a cell that checks this, make sure you can run it without errors).\n",
    "\n",
    "Failing to meet any of these requirements might lead to either a subtraction of POEs (at best) or a request for resubmission (at worst).\n",
    "\n",
    "We advise you the following steps before submission for ensuring that requirements 1, 2, and 3 are always met: **Restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). This might require a bit of time, so plan ahead for this (and possibly use Google Cloud's GPU in HA1 and HA2 for this step). Finally press the \"Save and Checkout\" button before handing in, to make sure that all your changes are saved to this .ipynb file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Group number and member names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP = \"\"\n",
    "NAME1 = \"\"\n",
    "NAME2 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you can run the following cell without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f4edef3c4e6df4dbb2a29dba78c09d8",
     "grade": false,
     "grade_id": "cell-2f332c3ca731afc6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Home Assignment 3\n",
    "This home assignment will focus on reinforcement learning and deep reinforcement learning. The first part will cover value-table reinforcement learning techniques, and the second part will include neural networks as function approximators, i.e. deep reinforcement learning. \n",
    "\n",
    "When handing in this assignment, make sure that you're handing in the correct version, and more importantly, *that you do no clear any output from your cells*. We'll use these outputs to aid us when grading your assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cc4d88f2e070d5479382bf223b5c5d49",
     "grade": false,
     "grade_id": "cell-8122dcb8d8ca1c9e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 1: Gridworld\n",
    "\n",
    "In this task, you will implement Value Iteration to solve for the optimal policy, $\\pi^*$, and the corresponding state value function, $V^*$.\n",
    "\n",
    "The MDP you will work with in this assignment is illustrated in the figure below\n",
    "\n",
    "![title](./grid_world.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fbdc1c764382473316a629ae7682d1bb",
     "grade": false,
     "grade_id": "cell-b4e5d5337fbaa0e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The agent starts in one of the squares shown in the above figure, and then proceeds to take actions. The available actions at any time step are: **North, West, South,** and **East**. If an action would make the agent bump into a wall, or one of the black (unreachable) states, it instead does nothing, leaving the agent at the same place it was before.\n",
    "\n",
    "The reward $\\mathcal{R}_s^a$ of being in state $s$ and performing actions $a$ is zero for all states, regardless of the action taken, with the exception of the green and the red squares. For the green square, the reward is always 1, and for the red square, always -1, regardless of the action.\n",
    "\n",
    "When the agent is either in the green or the red square, it will be transported to the terminal state in the next time step, regardless of the action taken. The terminal state is shown as the white square with the \"T\" inside.\n",
    "\n",
    "#### State representation\n",
    "The notations used to define the states are illustrated in the table below\n",
    "\n",
    "| $S_0$ | $S_1$ | $S_2$ | $S_3$ | $S_4$ |    |\n",
    "|-------|-------|-------|-------|-------|----|\n",
    "| $S_5$ | $S_6$ | $S_7$ | $S_8$ | $S_9$ |    |\n",
    "| $S_{10}$ | $S_{11}$ | $S_{12}$ | $S_{13}$ | $S_{14}$ | $S_{15}$|\n",
    "\n",
    "where $S_{10}$ corresponds to the initial state of the environment, $S_4$ and $S_9$ to the green and red states of the environment, and $S_{15}$ to the terminal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8d0703fff00f4fb67a72b46968fe7253",
     "grade": false,
     "grade_id": "cell-c54a0f7162b1f260",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "### Task 1.a: Solve for $V^*(s)$ and $Q^*(s,a)$\n",
    "For this task all transition probabilities are assumed to be 1 (that is, trying to move in a certain direction will definitely move the agent in the chosen direction), and a discount factor of .9, i.e. $\\gamma=.9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9894346da453882ad420d049511a5b8b",
     "grade": false,
     "grade_id": "cell-c7fa1d00113f314e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Solve for $V^*(S_{10})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e998cc86ed986eeac11f54b0f6869a67",
     "grade": true,
     "grade_id": "cell-966bc6b1276b31f1",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** 0.5314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c2d30fc8031fa1ff3f06019a9cf1ba27",
     "grade": false,
     "grade_id": "cell-4cc15316add9bd67",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "* Solve $Q^*(S_{10},a)$ for all actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ad5e1409a936a5c1ec6684a1edae79ee",
     "grade": true,
     "grade_id": "cell-0e5efad7ed72fdcb",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** 0.5314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fcab701a30ff0fd17edaa87e562124ba",
     "grade": false,
     "grade_id": "cell-e426e3815f78930a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "\n",
    "### Task 1.b Write a mathematical expression relating $V^\\pi(s)$ to $Q^\\pi(s,a)$ and $\\pi(a|s)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "61bf64e2c38d41b0f0d024faba554e8f",
     "grade": true,
     "grade_id": "cell-343c3ea4883085e1",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** $V_{\\pi}(S)=\\sum_{a \\in A}\\pi(a|s)q_{\\pi}(s,a)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "993f36fffd9ebfd3c89a3b63dd42685d",
     "grade": false,
     "grade_id": "cell-ab80df325256cf89",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "###  Task 1.c: Value Iteration\n",
    "For this task, the transitions are no longer deterministic. Instead, there is a 0.2 probability that the agent will try to travel in an orthogonal direction of the chosen action (0.1 probability for each of the two orthogonal directions). Note that the Markov decision process is still known and does not have to be learned from experience.\n",
    "\n",
    "Your task is to implement value iteration and solve for the\n",
    "* optimal greedy policy $\\pi^*(s)$ \n",
    "* $V^*(s)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "659925b7584671453aaee51f14ec4083",
     "grade": false,
     "grade_id": "cell-74497ad9b13e8362",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### The value iteration algorithm\n",
    "Value iteration is an iterative algorithm used to compute the optimal value function $V^*(s)$. Each iteration starts with a guess of what the value function is and then uses the Bellman equations to improve this guess iteratively. We can describe one iteration of the algorithm as\n",
    "\n",
    "$\n",
    "\\textbf{For} ~ s \\in {\\cal S}:\\qquad  \\\\\n",
    "\\quad V_{k+1}(s) = \\underset{a \\in {\\cal A}}{\\text{max}}~ \\left( \\mathcal{R}_s^a + \\gamma \\underset{{s'\\in \\mathcal{S}}}{\\sum} \\mathcal{P}_{ss'}^a \\cdot V_k(s') \\right)\n",
    "$\n",
    "\n",
    "where $\\mathcal{P}_{ss'}^a={\\mathrm Pr}[S'=s'\\big|S=s,A=a]$ is the probability to transition state $s$ to $s'$ given action $a$.\n",
    "\n",
    "\n",
    "#### The MDP Python class\n",
    "The Markov Decision Process you will work with is defined in `gridworld_mdp.py`. In the implementation, the actions are represented by integers as, North = 0, West = 1, South = 2, and East = 3.\n",
    "To interact with the MDP, you need to instantiate an object as: \n",
    "\n",
    "\n",
    "```python\n",
    "mdp = GridWorldMDP()\n",
    "```\n",
    "\n",
    "At your disposal there are a number of instance-functions implemented for you, and presented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "636b8c5ea0bb7d3b4798564dfc7d580d",
     "grade": false,
     "grade_id": "cell-21e5d7b3d3083cd6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_states in module gridworld_mdp:\n",
      "\n",
      "get_states(self)\n",
      "    Returns complete set of states for the MDP\n",
      "    :return: numpy array of shape [num states,]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gridworld_mdp import *\n",
    "import numpy as np\n",
    "\n",
    "help(GridWorldMDP.get_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "620f4674b0caadf475b4889bd8747b62",
     "grade": false,
     "grade_id": "cell-9706322eb34e16db",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module gridworld_mdp:\n",
      "\n",
      "__init__(self, trans_prob=0.8)\n",
      "    Initializes an instance of the GridWorldMDP class\n",
      "    :param trans_prob: transition probabilities (e.g. =1 for deterministic MDP)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The constructor\n",
    "help(GridWorldMDP.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f9b14ba756ee79811ccba63e1e51f14a",
     "grade": false,
     "grade_id": "cell-38d3ab6fb24c1af8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_actions in module gridworld_mdp:\n",
      "\n",
      "get_actions(self)\n",
      "    Returns complete set of actions for the MDP\n",
      "    :return: numpy array of shape [num actions,]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridWorldMDP.get_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e0b98cbe90baa640578ed1991b4e3501",
     "grade": false,
     "grade_id": "cell-ecb00397472a5faa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function state_transition_func in module gridworld_mdp:\n",
      "\n",
      "state_transition_func(self, s, a)\n",
      "    Returns the transition probabilities to all states given current state and action\n",
      "    :param state: current state as integer\n",
      "    :param action: selected action as integer\n",
      "    :return: state-transition probabilities, i.e.\n",
      "     [P[S_0| S=s, A_t=a], P[S_1| S=s, A=a], ..., P[S_14| S=s, A=a]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridWorldMDP.state_transition_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "40120f95b5767060a8ca55455cf5d485",
     "grade": false,
     "grade_id": "cell-aa8e1498649053a5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reward_function in module gridworld_mdp:\n",
      "\n",
      "reward_function(self, s, a)\n",
      "    Returns the reward r(s,a)\n",
      "    :param state: current state as integer\n",
      "    :param action: selected action as integer\n",
      "    :return: r(s,a)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridWorldMDP.reward_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8defb43e783bcb9464571753a5c6e452",
     "grade": false,
     "grade_id": "cell-c1408cc9707dd7f8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We also provide two helper functions for visualizing the value function and the policies you obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b39ad0b689edcb447e156b888fbc0515",
     "grade": false,
     "grade_id": "cell-b754590784e24eb1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Function for printing a policy pi\n",
    "def print_policy(pi):\n",
    "    print('Policy for non-terminal states: ')\n",
    "    indencies = np.arange(1, 16)\n",
    "    txt = '| '\n",
    "    hor_delimiter = '---------------------'\n",
    "    print(hor_delimiter)\n",
    "    for a, i in zip(pi, indencies):\n",
    "        txt += mdp.act_to_char_dict[a] + ' | '\n",
    "        if i % 5 == 0:\n",
    "            print(txt + '\\n' + hor_delimiter)\n",
    "            txt = '| '\n",
    "    print('                            ---')\n",
    "    print('Policy for terminal state: |', mdp.act_to_char_dict[pi[15]],'|')\n",
    "    print('                            ---')            \n",
    "\n",
    "# Function for printing a table with of the value function\n",
    "def print_value_table(values, num_iterations=None):            \n",
    "    if num_iterations:\n",
    "        print('Values for non-terminal states after: ', num_iterations, 'iterations \\n', np.reshape(values, [3, 5]), '\\n')\n",
    "        print('Value for terminal state:', terminal_value, '\\n')\n",
    "    else: \n",
    "        terminal_value = values[-1]\n",
    "        print('Values for non-terminal states: \\n', np.reshape(values[:-1], [3, 5]))\n",
    "        print('Value for terminal state:', terminal_value, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c04d9592932bc9c1e92df4949bcea301",
     "grade": false,
     "grade_id": "cell-87e02763b23fe1f8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now it's time for you to implement your own version of value iteration to solve for the greedy policy and $V^*(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4ec5804f5a67633ffcbb04d6e0f2addf",
     "grade": true,
     "grade_id": "cell-d473b99fe1825067",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def value_iteration(gamma, mdp):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        V - state value table, numpy array of shape (16,)\n",
    "        pi - greedy policy table, numpy array of shape (16,)\n",
    "    \"\"\"\n",
    "    V = np.zeros([16]) # state value table\n",
    "    pi = np.zeros([16]) # policy table\n",
    "    actions = mdp.get_actions()\n",
    "    ittr = 0\n",
    "\n",
    "    while True:\n",
    "        V_before = V.copy()\n",
    "        for s in mdp.get_states():\n",
    "            action_values = [mdp.reward_function(s,action) + gamma * np.dot(mdp.state_transition_func(s,action),V) \\\n",
    "                             for action in actions]\n",
    "            V[s] = max(action_values)\n",
    "            pi[s] = np.argmax(action_values)\n",
    "        \n",
    "        if np.array_equal(V,V_before):\n",
    "            break\n",
    "\n",
    "    \n",
    "    return V, pi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41ca129edbe5353b31ec35933bf28cdb",
     "grade": false,
     "grade_id": "cell-99c149095318adac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run your implementation for the deterministic version of our MDP. As a sanity check, compare your analytical solutions with the output from your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8a8722a6c33a96991f1091e2418def51",
     "grade": false,
     "grade_id": "cell-bd495acfe33d405f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for non-terminal states: \n",
      " [[ 0.6561    0.729     0.81      0.9       1.      ]\n",
      " [ 0.59049   0.        0.        0.81     -1.      ]\n",
      " [ 0.531441  0.59049   0.6561    0.729     0.6561  ]]\n",
      "Value for terminal state: 0.0 \n",
      "\n",
      "Policy for non-terminal states: \n",
      "---------------------\n",
      "| E | E | E | E | N | \n",
      "---------------------\n",
      "| N | N | N | N | N | \n",
      "---------------------\n",
      "| N | E | E | N | W | \n",
      "---------------------\n",
      "                            ---\n",
      "Policy for terminal state: | N |\n",
      "                            ---\n"
     ]
    }
   ],
   "source": [
    "mdp = GridWorldMDP(trans_prob=1.)\n",
    "v, pi = value_iteration(.9, mdp)\n",
    "print_value_table(v)\n",
    "print_policy(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "172eb8e58e4dbdcca83bb2bb8589032d",
     "grade": false,
     "grade_id": "cell-5a24214a0645d4b4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Once your implementation passed the sanity check, run it for the stochastic case, where the probability of an action succeding is 0.8, and 0.2 of moving the agent in an orthogonal direction to the intended. Use $\\gamma = .99$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "60e210ba654df60fcc54a7d6eda59aae",
     "grade": false,
     "grade_id": "cell-c6d0282ee295bb85",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for non-terminal states: \n",
      " [[ 0.93861973  0.95193393  0.9639533   0.97612443  1.        ]\n",
      " [ 0.92691625  0.          0.          0.88371826 -1.        ]\n",
      " [ 0.91395196  0.90255605  0.89130223  0.88057656  0.79978972]]\n",
      "Value for terminal state: 0.0 \n",
      "\n",
      "Policy for non-terminal states: \n",
      "---------------------\n",
      "| E | E | E | E | N | \n",
      "---------------------\n",
      "| N | N | N | W | N | \n",
      "---------------------\n",
      "| N | W | W | W | S | \n",
      "---------------------\n",
      "                            ---\n",
      "Policy for terminal state: | N |\n",
      "                            ---\n"
     ]
    }
   ],
   "source": [
    "# Run for stochastic MDP, gamma = .99\n",
    "mdp = GridWorldMDP()\n",
    "v, pi = value_iteration(.99, mdp)\n",
    "print_value_table(v)\n",
    "print_policy(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6d055e91280e2309b99724e4b6d6b1c6",
     "grade": false,
     "grade_id": "cell-b80f5f5b9d1398a6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Does the policy that the algorithm found looks reasonable? For instance, what's the policy for state $S_8$? Is that a good idea? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c078f48627ee20611cff693693deb293",
     "grade": true,
     "grade_id": "cell-daff5655fe78f131",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** Yes, it will keep bouncing against the wall, in order to not end up in the negative state. there is a small probability to go north, which is desirable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5c94489bd5a5a7608e4fa04705176796",
     "grade": false,
     "grade_id": "cell-d4840da19cbbb63a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Test your implementation using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e5071817f08d1145df1c5095dab2e7dc",
     "grade": false,
     "grade_id": "cell-f89a5e7709d41efc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed: state-value test, for gamma=.99\n",
      "Passed: policy test, for gamma=.99\n"
     ]
    }
   ],
   "source": [
    "test_value_iteration(v, pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7a2a2376284478e5ff87e8fc45681df1",
     "grade": false,
     "grade_id": "cell-32b52b966ea12de5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run value iteration for the same scenario as above, but now with $\\gamma=.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for non-terminal states: \n",
      " [[ 4.09845891e-13  5.12256092e-10  6.40192051e-07  8.00080016e-04\n",
      "   1.00000000e+00]\n",
      " [ 3.27942301e-16  0.00000000e+00  0.00000000e+00  8.00720657e-08\n",
      "  -1.00000000e+00]\n",
      " [ 2.66481820e-19  4.10133050e-17  5.12563779e-14  6.40576583e-11\n",
      "   6.41153621e-15]]\n",
      "Value for terminal state: 0.0 \n",
      "\n",
      "Policy for non-terminal states: \n",
      "---------------------\n",
      "| E | E | E | E | N | \n",
      "---------------------\n",
      "| N | N | N | W | N | \n",
      "---------------------\n",
      "| N | E | E | N | S | \n",
      "---------------------\n",
      "                            ---\n",
      "Policy for terminal state: | N |\n",
      "                            ---\n"
     ]
    }
   ],
   "source": [
    "# Run for stochastic MDP, gamma = .9\n",
    "mdp = GridWorldMDP()\n",
    "v, pi = value_iteration(.001, mdp)\n",
    "print_value_table(v)\n",
    "print_policy(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "45da583d4680e326a85cde59f0373b3e",
     "grade": false,
     "grade_id": "cell-3f797c0f704c2394",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for non-terminal states: \n",
      " [[ 0.56631445  0.65360208  0.74438015  0.84776628  1.        ]\n",
      " [ 0.49725171  0.          0.          0.57185903 -1.        ]\n",
      " [ 0.43084446  0.37830245  0.41624465  0.47405641  0.2761765 ]]\n",
      "Value for terminal state: 0.0 \n",
      "\n",
      "Policy for non-terminal states: \n",
      "---------------------\n",
      "| E | E | E | E | N | \n",
      "---------------------\n",
      "| N | N | N | N | N | \n",
      "---------------------\n",
      "| N | W | E | N | W | \n",
      "---------------------\n",
      "                            ---\n",
      "Policy for terminal state: | N |\n",
      "                            ---\n"
     ]
    }
   ],
   "source": [
    "# Run for stochastic MDP, gamma = .9\n",
    "mdp = GridWorldMDP()\n",
    "v, pi = value_iteration(.9, mdp)\n",
    "print_value_table(v)\n",
    "print_policy(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "90e75aaf90f849962cc2170695e557c0",
     "grade": false,
     "grade_id": "cell-9192d61af754d47b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Do you notice any difference between the greedy policy for the two different discount factors. If so, what's the difference, and why do you think this happened?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5bd2832c73ff6f59dd2dfe977ff3fd50",
     "grade": true,
     "grade_id": "cell-1a675e7574dce1d5",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** The model with $\\gamma=0.9$ cares less about future rewards than the model with $\\gamma=0.99$. \n",
    "The probability for getting higher reward along the clockwise path around grid world is higher than the counter clockwise path. In this grid world, we don't get any instantaneous rewards, the only real rewards are in the red and green squares. Therefore a model that cares more about future will select clockwise path. (fill in / check later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "79f657022c51018529b8d26b0ddd63c8",
     "grade": false,
     "grade_id": "cell-01feb7e04644407c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 2: Q-learning\n",
    "\n",
    "In the previous task, you solved for $V^*(s)$ and the greedy policy $\\pi^*(s)$, with the entire model of the MDP being available to you. This is however not very practical since for most problems we are trying to solve, the model is not known, and estimating the model is quite often a very tedious process which often also requires a lot of simplifications. \n",
    "\n",
    "#### Q-learning algorithm\n",
    "$\n",
    "\\text{Initialize}~Q(s,a), ~ \\forall~ s \\in {\\cal S},~ a~\\in {\\cal A} \\\\\n",
    "\\textbf{Repeat}~\\text{(for each episode):}\\\\\n",
    "\\quad \\text{Initialize}~s\\\\\n",
    "\\qquad \\textbf{Repeat}~\\text{(for each step in episode):}\\\\\n",
    "\\qquad\\quad \\text{Chose $a$ from $s$ using poliy derived from $Q$ (e.g., $\\epsilon$-greedy)}\\\\\n",
    "\\qquad\\quad \\text{Take action a, observe r, s'}\\\\\n",
    "\\qquad\\quad Q(s,a) \\leftarrow Q(s,a) + \\alpha \\left(r + \\gamma~\\underset{a}{\\text{max}}~Q(s',a) - Q(s,a) \\right) \\\\\n",
    "\\qquad\\quad s \\leftarrow s' \\\\\n",
    "\\qquad \\text{Until s is terminal}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f704f54a37111f555333212087572ac6",
     "grade": false,
     "grade_id": "cell-c974d24244fe78ca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Task 2.1 Model-free control\n",
    "Why is it that Q-learning does not require a model of the MDP to solve for it?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b369cc3d0a009ff83d971bc83c58fe69",
     "grade": true,
     "grade_id": "cell-448842959cfe9780",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9570fd8489dd5eec632778ab56e56c8b",
     "grade": false,
     "grade_id": "cell-bbe7f99d1cc4e6af",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Task 2.2  Implement an $\\epsilon$-greedy policy\n",
    "The goal of the Q-learning algorithm is to find the optimal policy $\\pi^*$, by estimating the state action value function under the optimal policy, i.e. $Q^*(s, a)$. From $Q^*(s,a)$, the agent can follow $\\pi^*$, by choosing the action with that yields the largest expected value for each state, i.e. $\\underset{a}{\\text{argmax}}~Q^*(s, a)$.\n",
    "\n",
    "However, when training a Q-learning model, the agent typically follows another policy to explore the environment. In reinforcement learning this is known as off-policy learning. \n",
    "\n",
    "Your task is to implement a widely popular exploration policy, known as  the $\\epsilon$-greedy policy, in the cell below.\n",
    "\n",
    "An $\\epsilon$-Greedy policy should:\n",
    "* with probability $\\epsilon$ take an uniformly-random action.\n",
    "* otherwise choose the best action according to the estimated state action values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ec694eb01517a447e2d27c05d3e69b9a",
     "grade": true,
     "grade_id": "cell-48c826a87791fb56",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def eps_greedy_policy(q_values, eps):\n",
    "    '''\n",
    "    Creates an epsilon-greedy policy\n",
    "    :param q_values: set of Q-values of shape (num actions,)\n",
    "    :param eps: probability of taking a uniform random action \n",
    "    :return: policy of shape (num actions,)\n",
    "    '''\n",
    "    pi = np.zeros((len(q_values),))\n",
    "\n",
    "    a = np.argmax(q_values)\n",
    "    \n",
    "    e_m = eps/len(q_values)\n",
    "    \n",
    "    for idx in range(len(q_values)):\n",
    "        pi[idx] = e_m\n",
    "        if idx == a:\n",
    "            pi[idx] += (1-eps)\n",
    "\n",
    "    return pi\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "583492c65cb090c181c66b42c2a51eff",
     "grade": false,
     "grade_id": "cell-6d33489b428b1179",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run the cell below to test your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8803a2f8fb24390fc517a97579e04242",
     "grade": false,
     "grade_id": "cell-80bd577e278ec0b0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed, good job!\n"
     ]
    }
   ],
   "source": [
    "mdp = GridWorldMDP()\n",
    "\n",
    "# Test shape of output\n",
    "actions = mdp.get_actions()\n",
    "for eps in (0, 1):\n",
    "    foo = np.zeros([len(actions)])\n",
    "    foo[0] = 1.\n",
    "    eps_greedy = eps_greedy_policy(foo, eps)\n",
    "    assert foo.shape == eps_greedy.shape, \"wrong shape of output\"\n",
    "actions = [i for i in range(10)]\n",
    "for eps in (0, 1):\n",
    "    foo = np.zeros([len(actions)])\n",
    "    foo[0] = 1.\n",
    "    eps_greedy = eps_greedy_policy(foo, eps)\n",
    "    assert foo.shape == eps_greedy.shape, \"wrong shape of output\"\n",
    "\n",
    "# Test for greedy actions\n",
    "for a in actions:\n",
    "    foo = np.zeros([len(actions)])\n",
    "    foo[a] = 1.\n",
    "    eps_greedy = eps_greedy_policy(foo, 0)\n",
    "    assert np.array_equal(foo, eps_greedy), \"policy is not greedy\"\n",
    "\n",
    "# Test for uniform distribution, when eps=1\n",
    "eps_greedy = eps_greedy_policy(foo, 1)\n",
    "assert all(p==eps_greedy[0] for p in eps_greedy) and np.sum(eps_greedy)==1, \\\n",
    "\"policy does not return a uniform distribution for eps=1\"\n",
    "\n",
    "print('Test passed, good job!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "21d88565b3663fe971606656dd045804",
     "grade": false,
     "grade_id": "cell-1dccaeebe5a41325",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Task 2.2: Implement the Q-learning algorithm\n",
    "\n",
    "Now it's time to actually implement the Q-learning algorithm. Unlike the Value iteration where there is no direct interactions with the environment, the Q-learning algorithm builds up its estimations by interacting and exploring the environment. \n",
    "\n",
    "To enable the agent to explore the environment a set of helper functions are provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "02bb92b833a3dc4e535cda13a4a1fae4",
     "grade": false,
     "grade_id": "cell-881edd2be439489e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reset in module gridworld_mdp:\n",
      "\n",
      "reset(self)\n",
      "    Resets the environment and the agent is positioned in the initial state in the bottom left corner.\n",
      "    :return: state, reward, terminal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridWorldMDP.reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "589834a8662125b7792560c134990d91",
     "grade": false,
     "grade_id": "cell-061e7670ebd7b35c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function step in module gridworld_mdp:\n",
      "\n",
      "step(self, action)\n",
      "    Takes one step in the environment using the selected action\n",
      "    :param action: action to execute, integer\n",
      "    :return: state, reward, terminal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridWorldMDP.step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8b92ae99e0b252016ed7040a0f706cec",
     "grade": false,
     "grade_id": "cell-15fa6bbf763cdc6f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Implement your version of Q-learning in the cell below. \n",
    "\n",
    "**Hint:** It might be useful to study the pseudocode provided above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\text{Initialize}~Q(s,a), ~ \\forall~ s \\in {\\cal S},~ a~\\in {\\cal A} \\\\\n",
    "\\textbf{Repeat}~\\text{(for each episode):}\\\\\n",
    "\\quad \\text{Initialize}~s\\\\\n",
    "\\qquad \\textbf{Repeat}~\\text{(for each step in episode):}\\\\\n",
    "\\qquad\\quad \\text{Chose $a$ from $s$ using poliy derived from $Q$ (e.g., $\\epsilon$-greedy)}\\\\\n",
    "\\qquad\\quad \\text{Take action a, observe r, s'}\\\\\n",
    "\\qquad\\quad Q(s,a) \\leftarrow Q(s,a) + \\alpha \\left(r + \\gamma~\\underset{a}{\\text{max}}~Q(s',a) - Q(s,a) \\right) \\\\\n",
    "\\qquad\\quad s \\leftarrow s' \\\\\n",
    "\\qquad \\text{Until s is terminal}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "465ba05d25e3bc7b0121f8a025b38831",
     "grade": true,
     "grade_id": "cell-3912d729d9527acd",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def q_learning(eps, gamma):\n",
    "    Q = np.zeros([16, 4]) # state action value table\n",
    "    alpha = .01\n",
    "    mdp = GridWorldMDP()\n",
    "    patience = 0\n",
    "    pi = np.zeros([16,4])\n",
    "    for episode in range(10000):\n",
    "        Q_old = Q.copy()\n",
    "        state, _, is_terminal = mdp.reset()\n",
    "        state_count = 0\n",
    "        while not is_terminal or state_count < 5:\n",
    "            action = np.random.choice(4, p=eps_greedy_policy(Q[state],eps))\n",
    "            next_state, reward, is_terminal = mdp.step(action)\n",
    "            max_next_state = Q[next_state, np.argmax(Q[next_state])]\n",
    "            \n",
    "            Q[state,action] = Q[state,action] + alpha*(reward+gamma*(max_next_state)-Q[state,action])\n",
    "\n",
    "            state_count = (state_count if state != next_state else state_count+1)\n",
    "            state = next_state\n",
    "        \n",
    "        if np.allclose(Q,Q_old,atol=1e-4):\n",
    "            print('early stopping after', episode)\n",
    "            return np.argmax(Q, axis=1), Q\n",
    "    return np.argmax(Q, axis=1), Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2db55b6a6838a75f15ef87f979ead425",
     "grade": false,
     "grade_id": "cell-b48032d234ecb11d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run Q-learning with  $\\epsilon = 1$ for the MDP with $\\gamma=0.99$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bebc79f9656b76b9e936221eb633cc4b",
     "grade": false,
     "grade_id": "cell-0464324eb2e2bf9c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping after 7751\n",
      "Policy for non-terminal states: \n",
      "---------------------\n",
      "| E | E | E | E | S | \n",
      "---------------------\n",
      "| N | N | N | W | W | \n",
      "---------------------\n",
      "| N | W | W | W | S | \n",
      "---------------------\n",
      "                            ---\n",
      "Policy for terminal state: | N |\n",
      "                            ---\n"
     ]
    }
   ],
   "source": [
    "pi, Q = q_learning(1, .99)\n",
    "print_policy(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9bc5026e570acf5162847f04d4b2daf3",
     "grade": false,
     "grade_id": "cell-a424df8abe557f2e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Test your implementation by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fe0420c08764bdf6ddec81e380ccf729",
     "grade": false,
     "grade_id": "cell-e2832d3538099d67",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed: policy test, for gamma=.99\n"
     ]
    }
   ],
   "source": [
    "test_q_learning(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "49f7e5d4884836a1c3c968b767d51f40",
     "grade": false,
     "grade_id": "cell-d3623c3f5c170bd4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run Q-learning with $\\epsilon=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8913eaf75e0f0d1c388d682d5767e0e6",
     "grade": false,
     "grade_id": "cell-1c095409c30320d7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy for non-terminal states: \n",
      "---------------------\n",
      "| N | N | N | N | N | \n",
      "---------------------\n",
      "| N | N | N | N | S | \n",
      "---------------------\n",
      "| N | N | N | N | W | \n",
      "---------------------\n",
      "                            ---\n",
      "Policy for terminal state: | N |\n",
      "                            ---\n"
     ]
    }
   ],
   "source": [
    "pi, Q = q_learning(0, .99)\n",
    "print_policy(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f8211c5750767a6a9ad1290cffb73aa7",
     "grade": false,
     "grade_id": "cell-d3383d13bae73e68",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You ran your implementation with $\\epsilon$ set to both 0 and 1. What are the results, and your conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f4556e9c53e5bfbac90a17601f48d1c1",
     "grade": true,
     "grade_id": "cell-54eb158e84c99275",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** With $\\epsilon = 1$ we will select actions completely random, and with $\\epsilon = 0$ we select actions completely greedily. With the completely greedy action selection we select the best action in every state, and we will therefore not explore the entire state space. In our case, allmost all cells indicates north (Since the greedy-epsilon function returns always $[1,0,0,0]$ if the Q values are all the same). \n",
    "\n",
    "If the transition probability of the MDP is smaller than 1 $(\\text{in our case } 0.8)$, we will end up in the terminal state eventually, but if the transition probability is 1, we will keep on going north and never terminate (if there is no limit to the number of steps in the episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f272655e0a5e12f3fcfe70c514467e1f",
     "grade": false,
     "grade_id": "cell-ae2a001335118014",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Task 3: Deep Double Q-learning (DDQN)\n",
    "For this task, you will implement a DDQN (double deep Q-learning network) to solve one of the problems of the OpenAI gym. Before we get into details about these type of networks, let's first review the simpler, DQN (deep Q-learning network) version. \n",
    "\n",
    "#### Deep Q Networks\n",
    "As we saw in the video lectures, using a neural network as a state action value approximator is a great idea. However, if one tries to use this approach with Q-learning, it's very likely that the optimization will be very unstable. To remediate this, two main ideas are used. First, we use experience replay, in order to decorrelate the experience samples we obtain when exploring the environment. Second, we use two networks instead of one, in order to fix the optimization targets. That is, for a given minibatch sampled from the replay buffer, we'll optimize the weights of only one of the networks (commonly denoted as the \"online\" network), using the gradients w.r.t a loss function. This loss function is computed as the mean squared error between the current action values, computed according to the **online** network, and the temporal difference (TD) targets, computed using the other, **fixed network** (which we'll refer to as the \"target\" network).\n",
    "\n",
    "That is, the loss function is \n",
    "\n",
    "$$ L(\\theta) = \\frac{1}{N}\\sum_{i=1}^N \\left(Q(s_i,a_i; \\theta\\right) - Y_i)^2~,$$\n",
    "\n",
    "where $N$ is the number of samples in your minibatch, $Q(s,a;\\theta)$ is the state action value estimate, according to the online network (with parameters $\\theta$), and $Y_t$ is the TD target, computed as\n",
    "\n",
    "$$ Y_i = r_i +  \\gamma ~\\underset{a}{\\text{max}}~Q(s_i', a; \\theta^-)~, $$\n",
    "\n",
    "where $Q(s', a;\\theta')$ is the action value estimate, according to the fixed network (with parameters $\\theta^-$).\n",
    "\n",
    "Finally, so that the offline parameters are also updated, we periodically change the roles of the networks, fixing the online one, and training the other.\n",
    "\n",
    "#### Double Deep Q Networks\n",
    "\n",
    "The idea explained above works well in practice, but later it was discovered that this approach is very prone to overestimating the state action values. The main reason for this is that the max operator, used to select the greedy action when computing the TD target, uses the same values both to select and to evaluate an action (this tends to prefer overestimated actions). In order to prevent this, we can decouple the selection from the evaluation, which is the idea that created DDQN. More concretely, the TD target for a DDQN is now \n",
    "\n",
    "$$ Y_i = r_i + \\gamma Q(s_i', \\underset{a}{\\text{argmax}}Q(s_i',a;\\theta); \\theta^-)~. $$\n",
    "\n",
    "Hence, we're using the **online** network to select which action is best, but we use the **fixed** network to evaluate the state action value for that chosen action in the next state. This is what makes DDQN not overestimate (as much) the state action values, which in turn helps us to train faster and obtain better policies.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ffc8f76962e410ad44919896b9d0de31",
     "grade": false,
     "grade_id": "cell-b37fc5ebe369b45a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Environment\n",
    "\n",
    "The problem you will solve for this task is the inverted pendulum problem. \n",
    "On [Open AIs environment documentation](https://gym.openai.com/envs/CartPole-v0) , the following description is provided:\n",
    "\n",
    "*A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every time step that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center.*\n",
    "\n",
    "![title](./cartpole.jpg) \n",
    "\n",
    "#### Implementation\n",
    "We'll solve this task using a DDQN. Most of the code is provided for you, in the file **ddqn_model.py**. This file contains the implementation of a neural network, which is described in the table below (feel free to experiment with different architectures).\n",
    "\n",
    "|Layer 1: units, activation | Layer 2: units, activation | Layer 3: units, activation | Cost function |\n",
    "|---------------------------|----------------------------|----------------------------|---------------|\n",
    "| 100, ReLu                 | 60, ReLu                   | number of actions, linear | MSE           |\n",
    "\n",
    "The only missing part of the code is the function that computes the TD targets for each minibatch of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55a5b74265fad2a849d7bcf7b7d09d45",
     "grade": false,
     "grade_id": "cell-ae647de789982b2e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 3.1:  Calculate TD-target\n",
    "\n",
    "For this task, you will calculate the temporal difference target used for the loss in the double Q-learning algorithm. Your implementation should follow precisely the equation defined above for the TD target of DDQNs, with one exception: when s' is terminal, the TD target for it should simply be $ Y_i = r_i$. Why is this necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "40e03a98c7372496040da5499e1fc29a",
     "grade": true,
     "grade_id": "cell-d28bf13d3d581368",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** The TD target is composed of immediate return and the (est.) expected return from the next state onwards. Since we are in the terminal state there are no rewards from any subsequent actions. Therefore, the term $\\gamma Q(s_i', \\underset{a}{\\text{argmax}}Q(s_i',a;\\theta); \\theta^-)~.$ has to be 0, for it to make sense.\n",
    "\n",
    "$$ Y_i = r_i + \\gamma Q(s_i', \\underset{a}{\\text{argmax}}Q(s_i',a;\\theta); \\theta^-)~. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f6a429aaede47e041414f7fac4093390",
     "grade": false,
     "grade_id": "cell-26a12456d7c70776",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Implement your function in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5b73cff549519ebc4c082c01928539b0",
     "grade": true,
     "grade_id": "cell-e73bca0bd9d5574a",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_td_targets(q1_batch, q2_batch, r_batch, t_batch, gamma=.99):\n",
    "    '''\n",
    "    Calculates the TD-target used for the loss\n",
    "    : param q1_batch: Batch of Q(s', a) from online network, shape (N, num actions)\n",
    "    : param q2_batch: Batch of Q(s', a) from target network, shape (N, num actions)\n",
    "    : param r_batch: Batch of rewards, shape (N, 1)\n",
    "    : param t_batch: Batch of booleans indicating if state, s' is terminal, shape (N, 1)\n",
    "    : return: TD-target, shape (N, 1)\n",
    "    '''\n",
    "    \n",
    "    Y = np.zeros(r_batch.shape)\n",
    "    for y_i in range(len(Y)):\n",
    "        Y[y_i] = r_batch[y_i]\n",
    "        if t_batch[y_i] == False:\n",
    "            online_max_action = np.argmax(q1_batch[y_i])\n",
    "            Y[y_i] += gamma*(q2_batch[y_i, online_max_action])\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b22afaa707ff45fb62badaadf2d632e7",
     "grade": false,
     "grade_id": "cell-401656fa71e3f227",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Test your implementation by trying to solve the reinforcement learning problem for the Cartpole environment. The following cell defines the `train_loop_ddqn` function, which will be called ahead.\n",
    "\n",
    "**Note:** If you have issues with the env.render() command below on your system, you may simply comment it out. However, you would be missing out on a visualization of the training episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import gym\n",
    "from keras.utils.np_utils import to_categorical as one_hot\n",
    "from collections import namedtuple\n",
    "from dqn_model import DoubleQLearningModel, ExperienceReplay\n",
    "\n",
    "def train_loop_ddqn(model, env, num_episodes, batch_size=64, gamma=.94, eps_decay = .001,stopping_criteria=195):        \n",
    "    Transition = namedtuple(\"Transition\", [\"s\", \"a\", \"r\", \"next_s\", \"t\"])\n",
    "    eps = 1.\n",
    "    eps_end = .1 \n",
    "    \n",
    "    R_buffer = []\n",
    "    R_avg = []\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset() #reset to initial state\n",
    "        state = np.expand_dims(state, axis=0)/2\n",
    "        terminal = False # reset terminal flag\n",
    "        ep_reward = 0\n",
    "        q_buffer = []\n",
    "        steps = 0\n",
    "        while not terminal:\n",
    "            #env.render() # comment this line out if you don't want to / cannot render the environment on your system\n",
    "            steps += 1\n",
    "            q_values = model.get_q_values(state)\n",
    "            q_buffer.append(q_values)\n",
    "            policy = eps_greedy_policy(q_values.squeeze(), eps) \n",
    "            action = np.random.choice(num_actions, p=policy) # sample action from epsilon-greedy policy\n",
    "            new_state, reward, terminal, _ = env.step(action) # take one step in the evironment\n",
    "            new_state = np.expand_dims(new_state, axis=0)/2\n",
    "            \n",
    "            # only use the terminal flag for ending the episode and not for training\n",
    "            # if the flag is set due to that the maximum amount of steps is reached \n",
    "            t_to_buffer = terminal if not steps == 200 else False\n",
    "            \n",
    "            # store data to replay buffer\n",
    "            replay_buffer.add(Transition(s=state, a=action, r=reward, next_s=new_state, t=t_to_buffer))\n",
    "            state = new_state\n",
    "            ep_reward += reward\n",
    "            \n",
    "            # if buffer contains more than 1000 samples, perform one training step\n",
    "            if replay_buffer.buffer_length > 1000:\n",
    "                s, a, r, s_, t = replay_buffer.sample_minibatch(batch_size) # sample a minibatch of transitions\n",
    "                q_1, q_2 = model.get_q_values_for_both_models(np.squeeze(s_))\n",
    "                td_target = calculate_td_targets(q_1, q_2, r, t, gamma)\n",
    "                model.update(s, td_target, a)    \n",
    "                \n",
    "        eps = max(eps - eps_decay, eps_end) # decrease epsilon        \n",
    "        R_buffer.append(ep_reward)\n",
    "        \n",
    "        # running average of episodic rewards\n",
    "        R_avg.append(.05 * R_buffer[i] + .95 * R_avg[i-1]) if i > 0 else R_avg.append(R_buffer[i])\n",
    "        print('Episode: ', i, 'Reward:', ep_reward, 'Epsilon', eps, 'mean q', np.mean(np.array(q_buffer)))\n",
    "        \n",
    "        # if running average > 195, the task is considerd solved\n",
    "        if R_avg[-1] > stopping_criteria:\n",
    "            return R_buffer, R_avg\n",
    "    return R_buffer, R_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "51f90902daf95d61d17b1d2c32877abf",
     "grade": false,
     "grade_id": "cell-75c84628ce999711",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "and the next cell performs the actual training. \n",
    "\n",
    "A Working implementation should start to improve after 500 episodes. An episodic reward of around 200 is likely to be achieved after 800 episodes for a batchsize of 128, and 1000 episodes for a batchsize of 64. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Box(4,)\n",
      "Episode:  0 Reward: 52.0 Epsilon 0.999 mean q -1.4133639e-07\n",
      "Episode:  1 Reward: 46.0 Epsilon 0.998 mean q -3.7171785e-07\n",
      "Episode:  2 Reward: 14.0 Epsilon 0.997 mean q -3.631732e-07\n",
      "Episode:  3 Reward: 24.0 Epsilon 0.996 mean q -3.247304e-07\n",
      "Episode:  4 Reward: 14.0 Epsilon 0.995 mean q -5.0732723e-07\n",
      "Episode:  5 Reward: 15.0 Epsilon 0.994 mean q -2.2009476e-07\n",
      "Episode:  6 Reward: 16.0 Epsilon 0.993 mean q -3.3124348e-07\n",
      "Episode:  7 Reward: 18.0 Epsilon 0.992 mean q -3.4985447e-07\n",
      "Episode:  8 Reward: 15.0 Epsilon 0.991 mean q -4.3110796e-07\n",
      "Episode:  9 Reward: 33.0 Epsilon 0.99 mean q -3.1913154e-07\n",
      "Episode:  10 Reward: 53.0 Epsilon 0.989 mean q -1.932225e-07\n",
      "Episode:  11 Reward: 12.0 Epsilon 0.988 mean q -3.1767863e-07\n",
      "Episode:  12 Reward: 12.0 Epsilon 0.987 mean q -5.1157605e-07\n",
      "Episode:  13 Reward: 21.0 Epsilon 0.986 mean q -2.549184e-07\n",
      "Episode:  14 Reward: 64.0 Epsilon 0.985 mean q -3.9242632e-08\n",
      "Episode:  15 Reward: 68.0 Epsilon 0.984 mean q -2.7984782e-07\n",
      "Episode:  16 Reward: 16.0 Epsilon 0.983 mean q -3.729831e-07\n",
      "Episode:  17 Reward: 44.0 Epsilon 0.982 mean q -2.5001785e-07\n",
      "Episode:  18 Reward: 28.0 Epsilon 0.981 mean q -8.488569e-08\n",
      "Episode:  19 Reward: 18.0 Epsilon 0.98 mean q -4.0503764e-07\n",
      "Episode:  20 Reward: 21.0 Epsilon 0.979 mean q -3.3300574e-07\n",
      "Episode:  21 Reward: 24.0 Epsilon 0.978 mean q -2.4472988e-07\n",
      "Episode:  22 Reward: 13.0 Epsilon 0.977 mean q -5.7374797e-07\n",
      "Episode:  23 Reward: 18.0 Epsilon 0.976 mean q -2.3974513e-07\n",
      "Episode:  24 Reward: 22.0 Epsilon 0.975 mean q -1.903392e-07\n",
      "Episode:  25 Reward: 21.0 Epsilon 0.974 mean q -3.8205482e-07\n",
      "Episode:  26 Reward: 11.0 Epsilon 0.973 mean q -4.019177e-07\n",
      "Episode:  27 Reward: 34.0 Epsilon 0.972 mean q -2.5070906e-07\n",
      "Episode:  28 Reward: 19.0 Epsilon 0.971 mean q -1.3549094e-07\n",
      "Episode:  29 Reward: 33.0 Epsilon 0.97 mean q -3.778273e-07\n",
      "Episode:  30 Reward: 15.0 Epsilon 0.969 mean q -3.5501418e-07\n",
      "Episode:  31 Reward: 16.0 Epsilon 0.968 mean q -4.6014435e-07\n",
      "Episode:  32 Reward: 15.0 Epsilon 0.967 mean q -1.8230763e-07\n",
      "Episode:  33 Reward: 24.0 Epsilon 0.966 mean q -3.2595187e-07\n",
      "Episode:  34 Reward: 15.0 Epsilon 0.965 mean q -2.2536436e-07\n",
      "Episode:  35 Reward: 16.0 Epsilon 0.964 mean q -3.5690175e-07\n",
      "Episode:  36 Reward: 8.0 Epsilon 0.963 mean q -5.980993e-07\n",
      "Episode:  37 Reward: 29.0 Epsilon 0.962 mean q -1.1997373e-07\n",
      "Episode:  38 Reward: 13.0 Epsilon 0.961 mean q -4.120451e-07\n",
      "Episode:  39 Reward: 23.0 Epsilon 0.96 mean q -2.0888481e-07\n",
      "Episode:  40 Reward: 19.0 Epsilon 0.959 mean q -4.0916325e-07\n",
      "Episode:  41 Reward: 73.0 Epsilon 0.958 mean q 0.008600367\n",
      "Episode:  42 Reward: 15.0 Epsilon 0.957 mean q 0.034426257\n",
      "Episode:  43 Reward: 21.0 Epsilon 0.956 mean q 0.023470733\n",
      "Episode:  44 Reward: 29.0 Epsilon 0.955 mean q 0.03585662\n",
      "Episode:  45 Reward: 17.0 Epsilon 0.954 mean q 0.07232219\n",
      "Episode:  46 Reward: 15.0 Epsilon 0.953 mean q 0.09253819\n",
      "Episode:  47 Reward: 13.0 Epsilon 0.952 mean q 0.078213006\n",
      "Episode:  48 Reward: 34.0 Epsilon 0.951 mean q 0.12299552\n",
      "Episode:  49 Reward: 37.0 Epsilon 0.95 mean q 0.13056152\n",
      "Episode:  50 Reward: 14.0 Epsilon 0.949 mean q 0.13130644\n",
      "Episode:  51 Reward: 18.0 Epsilon 0.948 mean q 0.20017603\n",
      "Episode:  52 Reward: 36.0 Epsilon 0.947 mean q 0.1613223\n",
      "Episode:  53 Reward: 15.0 Epsilon 0.946 mean q 0.25449917\n",
      "Episode:  54 Reward: 26.0 Epsilon 0.945 mean q 0.2700656\n",
      "Episode:  55 Reward: 23.0 Epsilon 0.944 mean q 0.20636654\n",
      "Episode:  56 Reward: 39.0 Epsilon 0.943 mean q 0.3272936\n",
      "Episode:  57 Reward: 15.0 Epsilon 0.942 mean q 0.4776993\n",
      "Episode:  58 Reward: 20.0 Epsilon 0.941 mean q 0.44088554\n",
      "Episode:  59 Reward: 13.0 Epsilon 0.94 mean q 0.51744646\n",
      "Episode:  60 Reward: 17.0 Epsilon 0.939 mean q 0.41707978\n",
      "Episode:  61 Reward: 14.0 Epsilon 0.938 mean q 0.55773634\n",
      "Episode:  62 Reward: 10.0 Epsilon 0.9369999999999999 mean q 0.70343053\n",
      "Episode:  63 Reward: 15.0 Epsilon 0.9359999999999999 mean q 0.5383755\n",
      "Episode:  64 Reward: 14.0 Epsilon 0.9349999999999999 mean q 0.7819118\n",
      "Episode:  65 Reward: 21.0 Epsilon 0.9339999999999999 mean q 0.42939878\n",
      "Episode:  66 Reward: 20.0 Epsilon 0.9329999999999999 mean q 0.6339675\n",
      "Episode:  67 Reward: 25.0 Epsilon 0.9319999999999999 mean q 0.62926954\n",
      "Episode:  68 Reward: 10.0 Epsilon 0.9309999999999999 mean q 1.1140015\n",
      "Episode:  69 Reward: 15.0 Epsilon 0.9299999999999999 mean q 1.1156678\n",
      "Episode:  70 Reward: 12.0 Epsilon 0.9289999999999999 mean q 1.0188651\n",
      "Episode:  71 Reward: 19.0 Epsilon 0.9279999999999999 mean q 0.82657415\n",
      "Episode:  72 Reward: 16.0 Epsilon 0.9269999999999999 mean q 1.0024288\n",
      "Episode:  73 Reward: 26.0 Epsilon 0.9259999999999999 mean q 0.7728532\n",
      "Episode:  74 Reward: 19.0 Epsilon 0.9249999999999999 mean q 0.86720026\n",
      "Episode:  75 Reward: 24.0 Epsilon 0.9239999999999999 mean q 0.99010086\n",
      "Episode:  76 Reward: 12.0 Epsilon 0.9229999999999999 mean q 1.9041237\n",
      "Episode:  77 Reward: 14.0 Epsilon 0.9219999999999999 mean q 1.6306362\n",
      "Episode:  78 Reward: 17.0 Epsilon 0.9209999999999999 mean q 1.07333\n",
      "Episode:  79 Reward: 12.0 Epsilon 0.9199999999999999 mean q 1.6331679\n",
      "Episode:  80 Reward: 23.0 Epsilon 0.9189999999999999 mean q 1.472869\n",
      "Episode:  81 Reward: 73.0 Epsilon 0.9179999999999999 mean q 1.0103152\n",
      "Episode:  82 Reward: 19.0 Epsilon 0.9169999999999999 mean q 2.0229475\n",
      "Episode:  83 Reward: 19.0 Epsilon 0.9159999999999999 mean q 1.9005942\n",
      "Episode:  84 Reward: 14.0 Epsilon 0.9149999999999999 mean q 2.096812\n",
      "Episode:  85 Reward: 22.0 Epsilon 0.9139999999999999 mean q 1.9484172\n",
      "Episode:  86 Reward: 31.0 Epsilon 0.9129999999999999 mean q 1.7820857\n",
      "Episode:  87 Reward: 33.0 Epsilon 0.9119999999999999 mean q 1.7848979\n",
      "Episode:  88 Reward: 17.0 Epsilon 0.9109999999999999 mean q 2.428359\n",
      "Episode:  89 Reward: 18.0 Epsilon 0.9099999999999999 mean q 2.198162\n",
      "Episode:  90 Reward: 13.0 Epsilon 0.9089999999999999 mean q 2.4729846\n",
      "Episode:  91 Reward: 21.0 Epsilon 0.9079999999999999 mean q 1.9003938\n",
      "Episode:  92 Reward: 30.0 Epsilon 0.9069999999999999 mean q 2.3867707\n",
      "Episode:  93 Reward: 31.0 Epsilon 0.9059999999999999 mean q 2.2946956\n",
      "Episode:  94 Reward: 16.0 Epsilon 0.9049999999999999 mean q 3.550706\n",
      "Episode:  95 Reward: 21.0 Epsilon 0.9039999999999999 mean q 2.9938006\n",
      "Episode:  96 Reward: 12.0 Epsilon 0.9029999999999999 mean q 4.4643693\n",
      "Episode:  97 Reward: 22.0 Epsilon 0.9019999999999999 mean q 3.3546674\n",
      "Episode:  98 Reward: 46.0 Epsilon 0.9009999999999999 mean q 3.1750116\n",
      "Episode:  99 Reward: 24.0 Epsilon 0.8999999999999999 mean q 3.1227844\n",
      "Episode:  100 Reward: 28.0 Epsilon 0.8989999999999999 mean q 3.5105302\n",
      "Episode:  101 Reward: 16.0 Epsilon 0.8979999999999999 mean q 3.766405\n",
      "Episode:  102 Reward: 14.0 Epsilon 0.8969999999999999 mean q 4.315766\n",
      "Episode:  103 Reward: 16.0 Epsilon 0.8959999999999999 mean q 4.078842\n",
      "Episode:  104 Reward: 47.0 Epsilon 0.8949999999999999 mean q 4.272857\n",
      "Episode:  105 Reward: 11.0 Epsilon 0.8939999999999999 mean q 4.9517903\n",
      "Episode:  106 Reward: 35.0 Epsilon 0.8929999999999999 mean q 3.2694635\n",
      "Episode:  107 Reward: 34.0 Epsilon 0.8919999999999999 mean q 5.092268\n",
      "Episode:  108 Reward: 32.0 Epsilon 0.8909999999999999 mean q 4.9012337\n",
      "Episode:  109 Reward: 15.0 Epsilon 0.8899999999999999 mean q 5.4178867\n",
      "Episode:  110 Reward: 13.0 Epsilon 0.8889999999999999 mean q 4.7146106\n",
      "Episode:  111 Reward: 42.0 Epsilon 0.8879999999999999 mean q 4.076913\n",
      "Episode:  112 Reward: 12.0 Epsilon 0.8869999999999999 mean q 7.2356143\n",
      "Episode:  113 Reward: 30.0 Epsilon 0.8859999999999999 mean q 4.3224607\n",
      "Episode:  114 Reward: 20.0 Epsilon 0.8849999999999999 mean q 5.091861\n",
      "Episode:  115 Reward: 23.0 Epsilon 0.8839999999999999 mean q 6.687691\n",
      "Episode:  116 Reward: 16.0 Epsilon 0.8829999999999999 mean q 6.4522314\n",
      "Episode:  117 Reward: 23.0 Epsilon 0.8819999999999999 mean q 4.395065\n",
      "Episode:  118 Reward: 27.0 Epsilon 0.8809999999999999 mean q 5.003382\n",
      "Episode:  119 Reward: 11.0 Epsilon 0.8799999999999999 mean q 7.495694\n",
      "Episode:  120 Reward: 17.0 Epsilon 0.8789999999999999 mean q 6.5915995\n",
      "Episode:  121 Reward: 10.0 Epsilon 0.8779999999999999 mean q 7.855088\n",
      "Episode:  122 Reward: 9.0 Epsilon 0.8769999999999999 mean q 9.124057\n",
      "Episode:  123 Reward: 16.0 Epsilon 0.8759999999999999 mean q 5.8757305\n",
      "Episode:  124 Reward: 15.0 Epsilon 0.8749999999999999 mean q 6.625086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  125 Reward: 56.0 Epsilon 0.8739999999999999 mean q 6.918457\n",
      "Episode:  126 Reward: 17.0 Epsilon 0.8729999999999999 mean q 7.8712077\n",
      "Episode:  127 Reward: 18.0 Epsilon 0.8719999999999999 mean q 7.630377\n",
      "Episode:  128 Reward: 12.0 Epsilon 0.8709999999999999 mean q 7.0052543\n",
      "Episode:  129 Reward: 21.0 Epsilon 0.8699999999999999 mean q 6.289572\n",
      "Episode:  130 Reward: 40.0 Epsilon 0.8689999999999999 mean q 5.3801193\n",
      "Episode:  131 Reward: 12.0 Epsilon 0.8679999999999999 mean q 8.411772\n",
      "Episode:  132 Reward: 18.0 Epsilon 0.8669999999999999 mean q 7.989191\n",
      "Episode:  133 Reward: 13.0 Epsilon 0.8659999999999999 mean q 8.759055\n",
      "Episode:  134 Reward: 15.0 Epsilon 0.8649999999999999 mean q 7.492245\n",
      "Episode:  135 Reward: 14.0 Epsilon 0.8639999999999999 mean q 8.564258\n",
      "Episode:  136 Reward: 13.0 Epsilon 0.8629999999999999 mean q 7.802111\n",
      "Episode:  137 Reward: 21.0 Epsilon 0.8619999999999999 mean q 7.7321277\n",
      "Episode:  138 Reward: 11.0 Epsilon 0.8609999999999999 mean q 9.040299\n",
      "Episode:  139 Reward: 21.0 Epsilon 0.8599999999999999 mean q 6.843649\n",
      "Episode:  140 Reward: 16.0 Epsilon 0.8589999999999999 mean q 8.632315\n",
      "Episode:  141 Reward: 33.0 Epsilon 0.8579999999999999 mean q 8.20056\n",
      "Episode:  142 Reward: 14.0 Epsilon 0.8569999999999999 mean q 9.538768\n",
      "Episode:  143 Reward: 15.0 Epsilon 0.8559999999999999 mean q 9.369311\n",
      "Episode:  144 Reward: 14.0 Epsilon 0.8549999999999999 mean q 10.638182\n",
      "Episode:  145 Reward: 13.0 Epsilon 0.8539999999999999 mean q 9.266316\n",
      "Episode:  146 Reward: 10.0 Epsilon 0.8529999999999999 mean q 9.90586\n",
      "Episode:  147 Reward: 16.0 Epsilon 0.8519999999999999 mean q 8.680924\n",
      "Episode:  148 Reward: 18.0 Epsilon 0.8509999999999999 mean q 8.542832\n",
      "Episode:  149 Reward: 24.0 Epsilon 0.8499999999999999 mean q 9.217092\n",
      "Episode:  150 Reward: 14.0 Epsilon 0.8489999999999999 mean q 10.821813\n",
      "Episode:  151 Reward: 13.0 Epsilon 0.8479999999999999 mean q 9.830685\n",
      "Episode:  152 Reward: 11.0 Epsilon 0.8469999999999999 mean q 11.3689165\n",
      "Episode:  153 Reward: 27.0 Epsilon 0.8459999999999999 mean q 8.56085\n",
      "Episode:  154 Reward: 21.0 Epsilon 0.8449999999999999 mean q 9.942163\n",
      "Episode:  155 Reward: 14.0 Epsilon 0.8439999999999999 mean q 11.871598\n",
      "Episode:  156 Reward: 12.0 Epsilon 0.8429999999999999 mean q 12.074177\n",
      "Episode:  157 Reward: 22.0 Epsilon 0.8419999999999999 mean q 10.459408\n",
      "Episode:  158 Reward: 20.0 Epsilon 0.8409999999999999 mean q 9.103648\n",
      "Episode:  159 Reward: 19.0 Epsilon 0.8399999999999999 mean q 9.989301\n",
      "Episode:  160 Reward: 32.0 Epsilon 0.8389999999999999 mean q 9.74609\n",
      "Episode:  161 Reward: 18.0 Epsilon 0.8379999999999999 mean q 10.603526\n",
      "Episode:  162 Reward: 13.0 Epsilon 0.8369999999999999 mean q 12.455385\n",
      "Episode:  163 Reward: 10.0 Epsilon 0.8359999999999999 mean q 12.087614\n",
      "Episode:  164 Reward: 13.0 Epsilon 0.8349999999999999 mean q 11.961569\n",
      "Episode:  165 Reward: 19.0 Epsilon 0.8339999999999999 mean q 10.701081\n",
      "Episode:  166 Reward: 34.0 Epsilon 0.8329999999999999 mean q 8.990639\n",
      "Episode:  167 Reward: 10.0 Epsilon 0.8319999999999999 mean q 11.419565\n",
      "Episode:  168 Reward: 13.0 Epsilon 0.8309999999999998 mean q 10.29297\n",
      "Episode:  169 Reward: 11.0 Epsilon 0.8299999999999998 mean q 10.607959\n",
      "Episode:  170 Reward: 45.0 Epsilon 0.8289999999999998 mean q 10.402896\n",
      "Episode:  171 Reward: 10.0 Epsilon 0.8279999999999998 mean q 13.451548\n",
      "Episode:  172 Reward: 17.0 Epsilon 0.8269999999999998 mean q 10.014389\n",
      "Episode:  173 Reward: 10.0 Epsilon 0.8259999999999998 mean q 12.930704\n",
      "Episode:  174 Reward: 15.0 Epsilon 0.8249999999999998 mean q 10.359249\n",
      "Episode:  175 Reward: 13.0 Epsilon 0.8239999999999998 mean q 12.013688\n",
      "Episode:  176 Reward: 15.0 Epsilon 0.8229999999999998 mean q 10.657672\n",
      "Episode:  177 Reward: 28.0 Epsilon 0.8219999999999998 mean q 10.864661\n",
      "Episode:  178 Reward: 30.0 Epsilon 0.8209999999999998 mean q 10.205536\n",
      "Episode:  179 Reward: 15.0 Epsilon 0.8199999999999998 mean q 10.449341\n",
      "Episode:  180 Reward: 31.0 Epsilon 0.8189999999999998 mean q 12.684908\n",
      "Episode:  181 Reward: 14.0 Epsilon 0.8179999999999998 mean q 11.942001\n",
      "Episode:  182 Reward: 16.0 Epsilon 0.8169999999999998 mean q 12.4367075\n",
      "Episode:  183 Reward: 17.0 Epsilon 0.8159999999999998 mean q 10.512216\n",
      "Episode:  184 Reward: 22.0 Epsilon 0.8149999999999998 mean q 11.278765\n",
      "Episode:  185 Reward: 25.0 Epsilon 0.8139999999999998 mean q 10.160162\n",
      "Episode:  186 Reward: 73.0 Epsilon 0.8129999999999998 mean q 12.79797\n",
      "Episode:  187 Reward: 19.0 Epsilon 0.8119999999999998 mean q 11.228436\n",
      "Episode:  188 Reward: 20.0 Epsilon 0.8109999999999998 mean q 11.954448\n",
      "Episode:  189 Reward: 17.0 Epsilon 0.8099999999999998 mean q 12.25623\n",
      "Episode:  190 Reward: 16.0 Epsilon 0.8089999999999998 mean q 12.425011\n",
      "Episode:  191 Reward: 15.0 Epsilon 0.8079999999999998 mean q 11.291053\n",
      "Episode:  192 Reward: 13.0 Epsilon 0.8069999999999998 mean q 11.9730015\n",
      "Episode:  193 Reward: 11.0 Epsilon 0.8059999999999998 mean q 12.018701\n",
      "Episode:  194 Reward: 13.0 Epsilon 0.8049999999999998 mean q 12.133658\n",
      "Episode:  195 Reward: 15.0 Epsilon 0.8039999999999998 mean q 12.680925\n",
      "Episode:  196 Reward: 11.0 Epsilon 0.8029999999999998 mean q 12.366308\n",
      "Episode:  197 Reward: 13.0 Epsilon 0.8019999999999998 mean q 11.760235\n",
      "Episode:  198 Reward: 16.0 Epsilon 0.8009999999999998 mean q 12.132535\n",
      "Episode:  199 Reward: 17.0 Epsilon 0.7999999999999998 mean q 11.956986\n",
      "Episode:  200 Reward: 22.0 Epsilon 0.7989999999999998 mean q 11.650509\n",
      "Episode:  201 Reward: 30.0 Epsilon 0.7979999999999998 mean q 11.081571\n",
      "Episode:  202 Reward: 14.0 Epsilon 0.7969999999999998 mean q 13.151219\n",
      "Episode:  203 Reward: 21.0 Epsilon 0.7959999999999998 mean q 11.42778\n",
      "Episode:  204 Reward: 15.0 Epsilon 0.7949999999999998 mean q 12.240604\n",
      "Episode:  205 Reward: 21.0 Epsilon 0.7939999999999998 mean q 12.494182\n",
      "Episode:  206 Reward: 13.0 Epsilon 0.7929999999999998 mean q 13.424759\n",
      "Episode:  207 Reward: 20.0 Epsilon 0.7919999999999998 mean q 12.176584\n",
      "Episode:  208 Reward: 11.0 Epsilon 0.7909999999999998 mean q 12.207027\n",
      "Episode:  209 Reward: 12.0 Epsilon 0.7899999999999998 mean q 12.954895\n",
      "Episode:  210 Reward: 38.0 Epsilon 0.7889999999999998 mean q 11.196668\n",
      "Episode:  211 Reward: 15.0 Epsilon 0.7879999999999998 mean q 12.51237\n",
      "Episode:  212 Reward: 20.0 Epsilon 0.7869999999999998 mean q 11.216449\n",
      "Episode:  213 Reward: 16.0 Epsilon 0.7859999999999998 mean q 12.743114\n",
      "Episode:  214 Reward: 16.0 Epsilon 0.7849999999999998 mean q 11.483201\n",
      "Episode:  215 Reward: 11.0 Epsilon 0.7839999999999998 mean q 13.908398\n",
      "Episode:  216 Reward: 12.0 Epsilon 0.7829999999999998 mean q 12.684827\n",
      "Episode:  217 Reward: 11.0 Epsilon 0.7819999999999998 mean q 12.88671\n",
      "Episode:  218 Reward: 11.0 Epsilon 0.7809999999999998 mean q 13.75687\n",
      "Episode:  219 Reward: 29.0 Epsilon 0.7799999999999998 mean q 11.807508\n",
      "Episode:  220 Reward: 12.0 Epsilon 0.7789999999999998 mean q 13.367358\n",
      "Episode:  221 Reward: 11.0 Epsilon 0.7779999999999998 mean q 14.272428\n",
      "Episode:  222 Reward: 26.0 Epsilon 0.7769999999999998 mean q 12.052369\n",
      "Episode:  223 Reward: 21.0 Epsilon 0.7759999999999998 mean q 12.2400255\n",
      "Episode:  224 Reward: 29.0 Epsilon 0.7749999999999998 mean q 11.157034\n",
      "Episode:  225 Reward: 17.0 Epsilon 0.7739999999999998 mean q 12.349232\n",
      "Episode:  226 Reward: 12.0 Epsilon 0.7729999999999998 mean q 12.357834\n",
      "Episode:  227 Reward: 12.0 Epsilon 0.7719999999999998 mean q 12.579457\n",
      "Episode:  228 Reward: 20.0 Epsilon 0.7709999999999998 mean q 11.523906\n",
      "Episode:  229 Reward: 14.0 Epsilon 0.7699999999999998 mean q 12.773414\n",
      "Episode:  230 Reward: 18.0 Epsilon 0.7689999999999998 mean q 11.995928\n",
      "Episode:  231 Reward: 13.0 Epsilon 0.7679999999999998 mean q 12.249553\n",
      "Episode:  232 Reward: 12.0 Epsilon 0.7669999999999998 mean q 11.819386\n",
      "Episode:  233 Reward: 14.0 Epsilon 0.7659999999999998 mean q 13.379149\n",
      "Episode:  234 Reward: 12.0 Epsilon 0.7649999999999998 mean q 12.074628\n",
      "Episode:  235 Reward: 14.0 Epsilon 0.7639999999999998 mean q 11.328372\n",
      "Episode:  236 Reward: 10.0 Epsilon 0.7629999999999998 mean q 13.505318\n",
      "Episode:  237 Reward: 18.0 Epsilon 0.7619999999999998 mean q 11.98296\n",
      "Episode:  238 Reward: 9.0 Epsilon 0.7609999999999998 mean q 13.840106\n",
      "Episode:  239 Reward: 12.0 Epsilon 0.7599999999999998 mean q 12.554859\n",
      "Episode:  240 Reward: 10.0 Epsilon 0.7589999999999998 mean q 13.969737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  241 Reward: 12.0 Epsilon 0.7579999999999998 mean q 13.834149\n",
      "Episode:  242 Reward: 13.0 Epsilon 0.7569999999999998 mean q 11.932855\n",
      "Episode:  243 Reward: 19.0 Epsilon 0.7559999999999998 mean q 12.526334\n",
      "Episode:  244 Reward: 58.0 Epsilon 0.7549999999999998 mean q 11.536388\n",
      "Episode:  245 Reward: 13.0 Epsilon 0.7539999999999998 mean q 11.6741705\n",
      "Episode:  246 Reward: 24.0 Epsilon 0.7529999999999998 mean q 10.939092\n",
      "Episode:  247 Reward: 13.0 Epsilon 0.7519999999999998 mean q 12.750831\n",
      "Episode:  248 Reward: 16.0 Epsilon 0.7509999999999998 mean q 11.691376\n",
      "Episode:  249 Reward: 10.0 Epsilon 0.7499999999999998 mean q 11.855659\n",
      "Episode:  250 Reward: 18.0 Epsilon 0.7489999999999998 mean q 11.105529\n",
      "Episode:  251 Reward: 12.0 Epsilon 0.7479999999999998 mean q 13.631991\n",
      "Episode:  252 Reward: 15.0 Epsilon 0.7469999999999998 mean q 11.427362\n",
      "Episode:  253 Reward: 14.0 Epsilon 0.7459999999999998 mean q 12.380399\n",
      "Episode:  254 Reward: 13.0 Epsilon 0.7449999999999998 mean q 13.922158\n",
      "Episode:  255 Reward: 16.0 Epsilon 0.7439999999999998 mean q 11.501734\n",
      "Episode:  256 Reward: 12.0 Epsilon 0.7429999999999998 mean q 14.710839\n",
      "Episode:  257 Reward: 10.0 Epsilon 0.7419999999999998 mean q 11.931089\n",
      "Episode:  258 Reward: 13.0 Epsilon 0.7409999999999998 mean q 14.047515\n",
      "Episode:  259 Reward: 13.0 Epsilon 0.7399999999999998 mean q 13.782263\n",
      "Episode:  260 Reward: 35.0 Epsilon 0.7389999999999998 mean q 13.367872\n",
      "Episode:  261 Reward: 11.0 Epsilon 0.7379999999999998 mean q 13.017477\n",
      "Episode:  262 Reward: 11.0 Epsilon 0.7369999999999998 mean q 14.313586\n",
      "Episode:  263 Reward: 10.0 Epsilon 0.7359999999999998 mean q 11.975437\n",
      "Episode:  264 Reward: 15.0 Epsilon 0.7349999999999998 mean q 12.820217\n",
      "Episode:  265 Reward: 11.0 Epsilon 0.7339999999999998 mean q 12.191667\n",
      "Episode:  266 Reward: 12.0 Epsilon 0.7329999999999998 mean q 11.14581\n",
      "Episode:  267 Reward: 22.0 Epsilon 0.7319999999999998 mean q 12.212681\n",
      "Episode:  268 Reward: 11.0 Epsilon 0.7309999999999998 mean q 13.494101\n",
      "Episode:  269 Reward: 12.0 Epsilon 0.7299999999999998 mean q 11.363473\n",
      "Episode:  270 Reward: 11.0 Epsilon 0.7289999999999998 mean q 13.314091\n",
      "Episode:  271 Reward: 15.0 Epsilon 0.7279999999999998 mean q 13.789578\n",
      "Episode:  272 Reward: 12.0 Epsilon 0.7269999999999998 mean q 10.654083\n",
      "Episode:  273 Reward: 23.0 Epsilon 0.7259999999999998 mean q 12.501732\n",
      "Episode:  274 Reward: 8.0 Epsilon 0.7249999999999998 mean q 14.39307\n",
      "Episode:  275 Reward: 9.0 Epsilon 0.7239999999999998 mean q 14.902671\n",
      "Episode:  276 Reward: 34.0 Epsilon 0.7229999999999998 mean q 12.010856\n",
      "Episode:  277 Reward: 19.0 Epsilon 0.7219999999999998 mean q 11.156209\n",
      "Episode:  278 Reward: 14.0 Epsilon 0.7209999999999998 mean q 13.429543\n",
      "Episode:  279 Reward: 18.0 Epsilon 0.7199999999999998 mean q 12.9231615\n",
      "Episode:  280 Reward: 12.0 Epsilon 0.7189999999999998 mean q 11.017731\n",
      "Episode:  281 Reward: 13.0 Epsilon 0.7179999999999997 mean q 14.539758\n",
      "Episode:  282 Reward: 10.0 Epsilon 0.7169999999999997 mean q 14.682783\n",
      "Episode:  283 Reward: 15.0 Epsilon 0.7159999999999997 mean q 14.863195\n",
      "Episode:  284 Reward: 13.0 Epsilon 0.7149999999999997 mean q 14.858252\n",
      "Episode:  285 Reward: 13.0 Epsilon 0.7139999999999997 mean q 13.387501\n",
      "Episode:  286 Reward: 10.0 Epsilon 0.7129999999999997 mean q 13.631032\n",
      "Episode:  287 Reward: 18.0 Epsilon 0.7119999999999997 mean q 14.138841\n",
      "Episode:  288 Reward: 19.0 Epsilon 0.7109999999999997 mean q 12.90107\n",
      "Episode:  289 Reward: 12.0 Epsilon 0.7099999999999997 mean q 14.495579\n",
      "Episode:  290 Reward: 26.0 Epsilon 0.7089999999999997 mean q 12.615475\n",
      "Episode:  291 Reward: 11.0 Epsilon 0.7079999999999997 mean q 14.329016\n",
      "Episode:  292 Reward: 27.0 Epsilon 0.7069999999999997 mean q 13.259143\n",
      "Episode:  293 Reward: 15.0 Epsilon 0.7059999999999997 mean q 10.951644\n",
      "Episode:  294 Reward: 8.0 Epsilon 0.7049999999999997 mean q 11.3165245\n",
      "Episode:  295 Reward: 22.0 Epsilon 0.7039999999999997 mean q 13.509793\n",
      "Episode:  296 Reward: 12.0 Epsilon 0.7029999999999997 mean q 14.1259\n",
      "Episode:  297 Reward: 17.0 Epsilon 0.7019999999999997 mean q 13.925458\n",
      "Episode:  298 Reward: 8.0 Epsilon 0.7009999999999997 mean q 15.439222\n",
      "Episode:  299 Reward: 17.0 Epsilon 0.6999999999999997 mean q 14.415935\n",
      "Episode:  300 Reward: 12.0 Epsilon 0.6989999999999997 mean q 14.37362\n",
      "Episode:  301 Reward: 16.0 Epsilon 0.6979999999999997 mean q 11.360511\n",
      "Episode:  302 Reward: 16.0 Epsilon 0.6969999999999997 mean q 13.921793\n",
      "Episode:  303 Reward: 12.0 Epsilon 0.6959999999999997 mean q 14.61245\n",
      "Episode:  304 Reward: 9.0 Epsilon 0.6949999999999997 mean q 16.005585\n",
      "Episode:  305 Reward: 12.0 Epsilon 0.6939999999999997 mean q 16.214788\n",
      "Episode:  306 Reward: 30.0 Epsilon 0.6929999999999997 mean q 11.484456\n",
      "Episode:  307 Reward: 30.0 Epsilon 0.6919999999999997 mean q 11.7016535\n",
      "Episode:  308 Reward: 16.0 Epsilon 0.6909999999999997 mean q 14.456181\n",
      "Episode:  309 Reward: 15.0 Epsilon 0.6899999999999997 mean q 11.299772\n",
      "Episode:  310 Reward: 21.0 Epsilon 0.6889999999999997 mean q 13.554763\n",
      "Episode:  311 Reward: 17.0 Epsilon 0.6879999999999997 mean q 11.110063\n",
      "Episode:  312 Reward: 19.0 Epsilon 0.6869999999999997 mean q 11.248578\n",
      "Episode:  313 Reward: 15.0 Epsilon 0.6859999999999997 mean q 11.2036495\n",
      "Episode:  314 Reward: 22.0 Epsilon 0.6849999999999997 mean q 14.48732\n",
      "Episode:  315 Reward: 10.0 Epsilon 0.6839999999999997 mean q 16.54872\n",
      "Episode:  316 Reward: 24.0 Epsilon 0.6829999999999997 mean q 14.338195\n",
      "Episode:  317 Reward: 10.0 Epsilon 0.6819999999999997 mean q 15.303047\n",
      "Episode:  318 Reward: 10.0 Epsilon 0.6809999999999997 mean q 16.000364\n",
      "Episode:  319 Reward: 35.0 Epsilon 0.6799999999999997 mean q 13.541356\n",
      "Episode:  320 Reward: 10.0 Epsilon 0.6789999999999997 mean q 10.869027\n",
      "Episode:  321 Reward: 26.0 Epsilon 0.6779999999999997 mean q 13.695909\n",
      "Episode:  322 Reward: 13.0 Epsilon 0.6769999999999997 mean q 11.063877\n",
      "Episode:  323 Reward: 24.0 Epsilon 0.6759999999999997 mean q 14.460838\n",
      "Episode:  324 Reward: 19.0 Epsilon 0.6749999999999997 mean q 14.9211445\n",
      "Episode:  325 Reward: 12.0 Epsilon 0.6739999999999997 mean q 15.350262\n",
      "Episode:  326 Reward: 16.0 Epsilon 0.6729999999999997 mean q 14.64743\n",
      "Episode:  327 Reward: 16.0 Epsilon 0.6719999999999997 mean q 15.414392\n",
      "Episode:  328 Reward: 9.0 Epsilon 0.6709999999999997 mean q 16.795963\n",
      "Episode:  329 Reward: 15.0 Epsilon 0.6699999999999997 mean q 15.518804\n",
      "Episode:  330 Reward: 16.0 Epsilon 0.6689999999999997 mean q 15.224971\n",
      "Episode:  331 Reward: 11.0 Epsilon 0.6679999999999997 mean q 15.777719\n",
      "Episode:  332 Reward: 12.0 Epsilon 0.6669999999999997 mean q 16.430492\n",
      "Episode:  333 Reward: 21.0 Epsilon 0.6659999999999997 mean q 11.902\n",
      "Episode:  334 Reward: 28.0 Epsilon 0.6649999999999997 mean q 14.820659\n",
      "Episode:  335 Reward: 20.0 Epsilon 0.6639999999999997 mean q 12.019724\n",
      "Episode:  336 Reward: 32.0 Epsilon 0.6629999999999997 mean q 14.0272045\n",
      "Episode:  337 Reward: 12.0 Epsilon 0.6619999999999997 mean q 16.062328\n",
      "Episode:  338 Reward: 17.0 Epsilon 0.6609999999999997 mean q 15.420728\n",
      "Episode:  339 Reward: 11.0 Epsilon 0.6599999999999997 mean q 16.16079\n",
      "Episode:  340 Reward: 14.0 Epsilon 0.6589999999999997 mean q 14.994927\n",
      "Episode:  341 Reward: 15.0 Epsilon 0.6579999999999997 mean q 15.483586\n",
      "Episode:  342 Reward: 10.0 Epsilon 0.6569999999999997 mean q 15.530408\n",
      "Episode:  343 Reward: 12.0 Epsilon 0.6559999999999997 mean q 15.891011\n",
      "Episode:  344 Reward: 8.0 Epsilon 0.6549999999999997 mean q 16.471533\n",
      "Episode:  345 Reward: 15.0 Epsilon 0.6539999999999997 mean q 15.244008\n",
      "Episode:  346 Reward: 16.0 Epsilon 0.6529999999999997 mean q 15.140722\n",
      "Episode:  347 Reward: 16.0 Epsilon 0.6519999999999997 mean q 15.155902\n",
      "Episode:  348 Reward: 15.0 Epsilon 0.6509999999999997 mean q 15.695678\n",
      "Episode:  349 Reward: 16.0 Epsilon 0.6499999999999997 mean q 15.076593\n",
      "Episode:  350 Reward: 25.0 Epsilon 0.6489999999999997 mean q 14.919653\n",
      "Episode:  351 Reward: 13.0 Epsilon 0.6479999999999997 mean q 16.214436\n",
      "Episode:  352 Reward: 14.0 Epsilon 0.6469999999999997 mean q 15.243451\n",
      "Episode:  353 Reward: 18.0 Epsilon 0.6459999999999997 mean q 14.978871\n",
      "Episode:  354 Reward: 10.0 Epsilon 0.6449999999999997 mean q 16.84095\n",
      "Episode:  355 Reward: 16.0 Epsilon 0.6439999999999997 mean q 15.748485\n",
      "Episode:  356 Reward: 14.0 Epsilon 0.6429999999999997 mean q 15.260108\n",
      "Episode:  357 Reward: 16.0 Epsilon 0.6419999999999997 mean q 15.135753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  358 Reward: 18.0 Epsilon 0.6409999999999997 mean q 15.401418\n",
      "Episode:  359 Reward: 11.0 Epsilon 0.6399999999999997 mean q 15.991422\n",
      "Episode:  360 Reward: 10.0 Epsilon 0.6389999999999997 mean q 15.610153\n",
      "Episode:  361 Reward: 17.0 Epsilon 0.6379999999999997 mean q 14.888023\n",
      "Episode:  362 Reward: 27.0 Epsilon 0.6369999999999997 mean q 14.863054\n",
      "Episode:  363 Reward: 9.0 Epsilon 0.6359999999999997 mean q 16.265955\n",
      "Episode:  364 Reward: 12.0 Epsilon 0.6349999999999997 mean q 15.282746\n",
      "Episode:  365 Reward: 13.0 Epsilon 0.6339999999999997 mean q 15.039944\n",
      "Episode:  366 Reward: 12.0 Epsilon 0.6329999999999997 mean q 15.249354\n",
      "Episode:  367 Reward: 17.0 Epsilon 0.6319999999999997 mean q 14.806006\n",
      "Episode:  368 Reward: 10.0 Epsilon 0.6309999999999997 mean q 16.323046\n",
      "Episode:  369 Reward: 9.0 Epsilon 0.6299999999999997 mean q 16.35294\n",
      "Episode:  370 Reward: 15.0 Epsilon 0.6289999999999997 mean q 15.504057\n",
      "Episode:  371 Reward: 12.0 Epsilon 0.6279999999999997 mean q 15.986392\n",
      "Episode:  372 Reward: 19.0 Epsilon 0.6269999999999997 mean q 15.281269\n",
      "Episode:  373 Reward: 11.0 Epsilon 0.6259999999999997 mean q 15.698352\n",
      "Episode:  374 Reward: 20.0 Epsilon 0.6249999999999997 mean q 14.348173\n",
      "Episode:  375 Reward: 10.0 Epsilon 0.6239999999999997 mean q 15.394693\n",
      "Episode:  376 Reward: 19.0 Epsilon 0.6229999999999997 mean q 14.696601\n",
      "Episode:  377 Reward: 11.0 Epsilon 0.6219999999999997 mean q 15.725836\n",
      "Episode:  378 Reward: 15.0 Epsilon 0.6209999999999997 mean q 14.719595\n",
      "Episode:  379 Reward: 10.0 Epsilon 0.6199999999999997 mean q 15.184033\n",
      "Episode:  380 Reward: 16.0 Epsilon 0.6189999999999997 mean q 14.150436\n",
      "Episode:  381 Reward: 15.0 Epsilon 0.6179999999999997 mean q 15.220931\n",
      "Episode:  382 Reward: 15.0 Epsilon 0.6169999999999997 mean q 15.193629\n",
      "Episode:  383 Reward: 10.0 Epsilon 0.6159999999999997 mean q 14.663442\n",
      "Episode:  384 Reward: 10.0 Epsilon 0.6149999999999997 mean q 15.743666\n",
      "Episode:  385 Reward: 9.0 Epsilon 0.6139999999999997 mean q 15.330013\n",
      "Episode:  386 Reward: 10.0 Epsilon 0.6129999999999997 mean q 14.693838\n",
      "Episode:  387 Reward: 12.0 Epsilon 0.6119999999999997 mean q 14.376244\n",
      "Episode:  388 Reward: 9.0 Epsilon 0.6109999999999997 mean q 14.591095\n",
      "Episode:  389 Reward: 16.0 Epsilon 0.6099999999999997 mean q 14.222454\n",
      "Episode:  390 Reward: 16.0 Epsilon 0.6089999999999997 mean q 13.853137\n",
      "Episode:  391 Reward: 20.0 Epsilon 0.6079999999999997 mean q 13.912806\n",
      "Episode:  392 Reward: 10.0 Epsilon 0.6069999999999997 mean q 14.7655735\n",
      "Episode:  393 Reward: 10.0 Epsilon 0.6059999999999997 mean q 14.59299\n",
      "Episode:  394 Reward: 17.0 Epsilon 0.6049999999999996 mean q 11.404723\n",
      "Episode:  395 Reward: 14.0 Epsilon 0.6039999999999996 mean q 14.154924\n",
      "Episode:  396 Reward: 22.0 Epsilon 0.6029999999999996 mean q 11.734651\n",
      "Episode:  397 Reward: 13.0 Epsilon 0.6019999999999996 mean q 13.883245\n",
      "Episode:  398 Reward: 10.0 Epsilon 0.6009999999999996 mean q 14.426092\n",
      "Episode:  399 Reward: 13.0 Epsilon 0.5999999999999996 mean q 13.863744\n",
      "Episode:  400 Reward: 12.0 Epsilon 0.5989999999999996 mean q 14.190671\n",
      "Episode:  401 Reward: 16.0 Epsilon 0.5979999999999996 mean q 13.580816\n",
      "Episode:  402 Reward: 37.0 Epsilon 0.5969999999999996 mean q 13.091702\n",
      "Episode:  403 Reward: 19.0 Epsilon 0.5959999999999996 mean q 13.329793\n",
      "Episode:  404 Reward: 37.0 Epsilon 0.5949999999999996 mean q 12.907265\n",
      "Episode:  405 Reward: 13.0 Epsilon 0.5939999999999996 mean q 13.760026\n",
      "Episode:  406 Reward: 11.0 Epsilon 0.5929999999999996 mean q 13.555878\n",
      "Episode:  407 Reward: 25.0 Epsilon 0.5919999999999996 mean q 13.039699\n",
      "Episode:  408 Reward: 18.0 Epsilon 0.5909999999999996 mean q 13.054553\n",
      "Episode:  409 Reward: 10.0 Epsilon 0.5899999999999996 mean q 13.499563\n",
      "Episode:  410 Reward: 21.0 Epsilon 0.5889999999999996 mean q 11.359228\n",
      "Episode:  411 Reward: 12.0 Epsilon 0.5879999999999996 mean q 13.157998\n",
      "Episode:  412 Reward: 13.0 Epsilon 0.5869999999999996 mean q 10.634443\n",
      "Episode:  413 Reward: 11.0 Epsilon 0.5859999999999996 mean q 13.160363\n",
      "Episode:  414 Reward: 11.0 Epsilon 0.5849999999999996 mean q 13.356402\n",
      "Episode:  415 Reward: 16.0 Epsilon 0.5839999999999996 mean q 12.942936\n",
      "Episode:  416 Reward: 18.0 Epsilon 0.5829999999999996 mean q 12.655518\n",
      "Episode:  417 Reward: 18.0 Epsilon 0.5819999999999996 mean q 12.59985\n",
      "Episode:  418 Reward: 20.0 Epsilon 0.5809999999999996 mean q 12.511742\n",
      "Episode:  419 Reward: 11.0 Epsilon 0.5799999999999996 mean q 12.789262\n",
      "Episode:  420 Reward: 15.0 Epsilon 0.5789999999999996 mean q 12.596093\n",
      "Episode:  421 Reward: 12.0 Epsilon 0.5779999999999996 mean q 12.664338\n",
      "Episode:  422 Reward: 27.0 Epsilon 0.5769999999999996 mean q 12.066276\n",
      "Episode:  423 Reward: 16.0 Epsilon 0.5759999999999996 mean q 12.224638\n",
      "Episode:  424 Reward: 13.0 Epsilon 0.5749999999999996 mean q 12.223525\n",
      "Episode:  425 Reward: 11.0 Epsilon 0.5739999999999996 mean q 12.205142\n",
      "Episode:  426 Reward: 9.0 Epsilon 0.5729999999999996 mean q 12.134539\n",
      "Episode:  427 Reward: 18.0 Epsilon 0.5719999999999996 mean q 11.98055\n",
      "Episode:  428 Reward: 10.0 Epsilon 0.5709999999999996 mean q 12.131712\n",
      "Episode:  429 Reward: 11.0 Epsilon 0.5699999999999996 mean q 12.038931\n",
      "Episode:  430 Reward: 17.0 Epsilon 0.5689999999999996 mean q 11.830138\n",
      "Episode:  431 Reward: 11.0 Epsilon 0.5679999999999996 mean q 11.776022\n",
      "Episode:  432 Reward: 11.0 Epsilon 0.5669999999999996 mean q 11.639988\n",
      "Episode:  433 Reward: 17.0 Epsilon 0.5659999999999996 mean q 11.348024\n",
      "Episode:  434 Reward: 12.0 Epsilon 0.5649999999999996 mean q 11.573735\n",
      "Episode:  435 Reward: 10.0 Epsilon 0.5639999999999996 mean q 11.587477\n",
      "Episode:  436 Reward: 12.0 Epsilon 0.5629999999999996 mean q 11.389699\n",
      "Episode:  437 Reward: 10.0 Epsilon 0.5619999999999996 mean q 11.400852\n",
      "Episode:  438 Reward: 14.0 Epsilon 0.5609999999999996 mean q 11.399963\n",
      "Episode:  439 Reward: 9.0 Epsilon 0.5599999999999996 mean q 11.504283\n",
      "Episode:  440 Reward: 12.0 Epsilon 0.5589999999999996 mean q 11.339419\n",
      "Episode:  441 Reward: 10.0 Epsilon 0.5579999999999996 mean q 11.184858\n",
      "Episode:  442 Reward: 28.0 Epsilon 0.5569999999999996 mean q 10.825761\n",
      "Episode:  443 Reward: 12.0 Epsilon 0.5559999999999996 mean q 11.193606\n",
      "Episode:  444 Reward: 11.0 Epsilon 0.5549999999999996 mean q 11.078971\n",
      "Episode:  445 Reward: 11.0 Epsilon 0.5539999999999996 mean q 11.115111\n",
      "Episode:  446 Reward: 17.0 Epsilon 0.5529999999999996 mean q 11.0375595\n",
      "Episode:  447 Reward: 17.0 Epsilon 0.5519999999999996 mean q 10.96843\n",
      "Episode:  448 Reward: 12.0 Epsilon 0.5509999999999996 mean q 10.892525\n",
      "Episode:  449 Reward: 12.0 Epsilon 0.5499999999999996 mean q 10.754416\n",
      "Episode:  450 Reward: 17.0 Epsilon 0.5489999999999996 mean q 10.922205\n",
      "Episode:  451 Reward: 15.0 Epsilon 0.5479999999999996 mean q 10.824481\n",
      "Episode:  452 Reward: 33.0 Epsilon 0.5469999999999996 mean q 10.394857\n",
      "Episode:  453 Reward: 15.0 Epsilon 0.5459999999999996 mean q 10.427219\n",
      "Episode:  454 Reward: 18.0 Epsilon 0.5449999999999996 mean q 9.667017\n",
      "Episode:  455 Reward: 15.0 Epsilon 0.5439999999999996 mean q 10.392849\n",
      "Episode:  456 Reward: 12.0 Epsilon 0.5429999999999996 mean q 10.221221\n",
      "Episode:  457 Reward: 11.0 Epsilon 0.5419999999999996 mean q 10.429838\n",
      "Episode:  458 Reward: 12.0 Epsilon 0.5409999999999996 mean q 10.169907\n",
      "Episode:  459 Reward: 12.0 Epsilon 0.5399999999999996 mean q 10.237636\n",
      "Episode:  460 Reward: 15.0 Epsilon 0.5389999999999996 mean q 10.217469\n",
      "Episode:  461 Reward: 15.0 Epsilon 0.5379999999999996 mean q 10.198329\n",
      "Episode:  462 Reward: 17.0 Epsilon 0.5369999999999996 mean q 10.344459\n",
      "Episode:  463 Reward: 9.0 Epsilon 0.5359999999999996 mean q 10.155177\n",
      "Episode:  464 Reward: 19.0 Epsilon 0.5349999999999996 mean q 10.242199\n",
      "Episode:  465 Reward: 12.0 Epsilon 0.5339999999999996 mean q 9.960345\n",
      "Episode:  466 Reward: 16.0 Epsilon 0.5329999999999996 mean q 10.210856\n",
      "Episode:  467 Reward: 16.0 Epsilon 0.5319999999999996 mean q 9.669566\n",
      "Episode:  468 Reward: 10.0 Epsilon 0.5309999999999996 mean q 9.601213\n",
      "Episode:  469 Reward: 14.0 Epsilon 0.5299999999999996 mean q 10.212398\n",
      "Episode:  470 Reward: 12.0 Epsilon 0.5289999999999996 mean q 9.753341\n",
      "Episode:  471 Reward: 11.0 Epsilon 0.5279999999999996 mean q 9.687544\n",
      "Episode:  472 Reward: 14.0 Epsilon 0.5269999999999996 mean q 9.539479\n",
      "Episode:  473 Reward: 18.0 Epsilon 0.5259999999999996 mean q 10.01077\n",
      "Episode:  474 Reward: 10.0 Epsilon 0.5249999999999996 mean q 9.39386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  475 Reward: 13.0 Epsilon 0.5239999999999996 mean q 9.439852\n",
      "Episode:  476 Reward: 13.0 Epsilon 0.5229999999999996 mean q 9.31732\n",
      "Episode:  477 Reward: 8.0 Epsilon 0.5219999999999996 mean q 8.51522\n",
      "Episode:  478 Reward: 10.0 Epsilon 0.5209999999999996 mean q 9.108007\n",
      "Episode:  479 Reward: 15.0 Epsilon 0.5199999999999996 mean q 8.68466\n",
      "Episode:  480 Reward: 10.0 Epsilon 0.5189999999999996 mean q 9.164098\n",
      "Episode:  481 Reward: 11.0 Epsilon 0.5179999999999996 mean q 9.282746\n",
      "Episode:  482 Reward: 12.0 Epsilon 0.5169999999999996 mean q 9.101352\n",
      "Episode:  483 Reward: 11.0 Epsilon 0.5159999999999996 mean q 9.151985\n",
      "Episode:  484 Reward: 15.0 Epsilon 0.5149999999999996 mean q 9.160341\n",
      "Episode:  485 Reward: 21.0 Epsilon 0.5139999999999996 mean q 9.178052\n",
      "Episode:  486 Reward: 10.0 Epsilon 0.5129999999999996 mean q 8.673009\n",
      "Episode:  487 Reward: 20.0 Epsilon 0.5119999999999996 mean q 9.200349\n",
      "Episode:  488 Reward: 15.0 Epsilon 0.5109999999999996 mean q 8.919387\n",
      "Episode:  489 Reward: 17.0 Epsilon 0.5099999999999996 mean q 8.912059\n",
      "Episode:  490 Reward: 22.0 Epsilon 0.5089999999999996 mean q 8.946439\n",
      "Episode:  491 Reward: 11.0 Epsilon 0.5079999999999996 mean q 8.827257\n",
      "Episode:  492 Reward: 16.0 Epsilon 0.5069999999999996 mean q 9.029373\n",
      "Episode:  493 Reward: 14.0 Epsilon 0.5059999999999996 mean q 8.691358\n",
      "Episode:  494 Reward: 13.0 Epsilon 0.5049999999999996 mean q 9.168014\n",
      "Episode:  495 Reward: 10.0 Epsilon 0.5039999999999996 mean q 8.171331\n",
      "Episode:  496 Reward: 14.0 Epsilon 0.5029999999999996 mean q 9.148489\n",
      "Episode:  497 Reward: 33.0 Epsilon 0.5019999999999996 mean q 9.04522\n",
      "Episode:  498 Reward: 8.0 Epsilon 0.5009999999999996 mean q 8.057684\n",
      "Episode:  499 Reward: 52.0 Epsilon 0.49999999999999956 mean q 8.876715\n",
      "Episode:  500 Reward: 9.0 Epsilon 0.49899999999999956 mean q 7.924638\n",
      "Episode:  501 Reward: 19.0 Epsilon 0.49799999999999955 mean q 8.157038\n",
      "Episode:  502 Reward: 19.0 Epsilon 0.49699999999999955 mean q 8.757796\n",
      "Episode:  503 Reward: 13.0 Epsilon 0.49599999999999955 mean q 8.350954\n",
      "Episode:  504 Reward: 18.0 Epsilon 0.49499999999999955 mean q 8.713007\n",
      "Episode:  505 Reward: 79.0 Epsilon 0.49399999999999955 mean q 9.45734\n",
      "Episode:  506 Reward: 57.0 Epsilon 0.49299999999999955 mean q 9.0877\n",
      "Episode:  507 Reward: 28.0 Epsilon 0.49199999999999955 mean q 8.851226\n",
      "Episode:  508 Reward: 17.0 Epsilon 0.49099999999999955 mean q 8.867376\n",
      "Episode:  509 Reward: 50.0 Epsilon 0.48999999999999955 mean q 9.289791\n",
      "Episode:  510 Reward: 126.0 Epsilon 0.48899999999999955 mean q 11.0837965\n",
      "Episode:  511 Reward: 55.0 Epsilon 0.48799999999999955 mean q 10.173545\n",
      "Episode:  512 Reward: 36.0 Epsilon 0.48699999999999954 mean q 9.761711\n",
      "Episode:  513 Reward: 29.0 Epsilon 0.48599999999999954 mean q 9.7344\n",
      "Episode:  514 Reward: 45.0 Epsilon 0.48499999999999954 mean q 9.7778015\n",
      "Episode:  515 Reward: 35.0 Epsilon 0.48399999999999954 mean q 9.591926\n",
      "Episode:  516 Reward: 14.0 Epsilon 0.48299999999999954 mean q 9.301474\n",
      "Episode:  517 Reward: 56.0 Epsilon 0.48199999999999954 mean q 10.175496\n",
      "Episode:  518 Reward: 11.0 Epsilon 0.48099999999999954 mean q 9.335297\n",
      "Episode:  519 Reward: 130.0 Epsilon 0.47999999999999954 mean q 10.73777\n",
      "Episode:  520 Reward: 37.0 Epsilon 0.47899999999999954 mean q 10.26617\n",
      "Episode:  521 Reward: 11.0 Epsilon 0.47799999999999954 mean q 9.224769\n",
      "Episode:  522 Reward: 73.0 Epsilon 0.47699999999999954 mean q 10.939442\n",
      "Episode:  523 Reward: 51.0 Epsilon 0.47599999999999953 mean q 10.585073\n",
      "Episode:  524 Reward: 66.0 Epsilon 0.47499999999999953 mean q 10.433102\n",
      "Episode:  525 Reward: 46.0 Epsilon 0.47399999999999953 mean q 10.6583395\n",
      "Episode:  526 Reward: 116.0 Epsilon 0.47299999999999953 mean q 12.143435\n",
      "Episode:  527 Reward: 57.0 Epsilon 0.47199999999999953 mean q 11.232573\n",
      "Episode:  528 Reward: 74.0 Epsilon 0.47099999999999953 mean q 11.0838375\n",
      "Episode:  529 Reward: 60.0 Epsilon 0.46999999999999953 mean q 11.479503\n",
      "Episode:  530 Reward: 22.0 Epsilon 0.46899999999999953 mean q 10.7651415\n",
      "Episode:  531 Reward: 40.0 Epsilon 0.4679999999999995 mean q 11.398695\n",
      "Episode:  532 Reward: 46.0 Epsilon 0.4669999999999995 mean q 11.541745\n",
      "Episode:  533 Reward: 71.0 Epsilon 0.4659999999999995 mean q 13.037556\n",
      "Episode:  534 Reward: 89.0 Epsilon 0.4649999999999995 mean q 12.055185\n",
      "Episode:  535 Reward: 20.0 Epsilon 0.4639999999999995 mean q 11.264334\n",
      "Episode:  536 Reward: 56.0 Epsilon 0.4629999999999995 mean q 11.7349\n",
      "Episode:  537 Reward: 33.0 Epsilon 0.4619999999999995 mean q 12.155883\n",
      "Episode:  538 Reward: 22.0 Epsilon 0.4609999999999995 mean q 11.364791\n",
      "Episode:  539 Reward: 53.0 Epsilon 0.4599999999999995 mean q 11.976934\n",
      "Episode:  540 Reward: 43.0 Epsilon 0.4589999999999995 mean q 11.88121\n",
      "Episode:  541 Reward: 39.0 Epsilon 0.4579999999999995 mean q 12.691558\n",
      "Episode:  542 Reward: 61.0 Epsilon 0.4569999999999995 mean q 13.977592\n",
      "Episode:  543 Reward: 44.0 Epsilon 0.4559999999999995 mean q 11.991717\n",
      "Episode:  544 Reward: 67.0 Epsilon 0.4549999999999995 mean q 12.844818\n",
      "Episode:  545 Reward: 37.0 Epsilon 0.4539999999999995 mean q 12.141795\n",
      "Episode:  546 Reward: 48.0 Epsilon 0.4529999999999995 mean q 12.485141\n",
      "Episode:  547 Reward: 17.0 Epsilon 0.4519999999999995 mean q 11.082244\n",
      "Episode:  548 Reward: 71.0 Epsilon 0.4509999999999995 mean q 13.075557\n",
      "Episode:  549 Reward: 96.0 Epsilon 0.4499999999999995 mean q 13.177864\n",
      "Episode:  550 Reward: 32.0 Epsilon 0.4489999999999995 mean q 13.560018\n",
      "Episode:  551 Reward: 88.0 Epsilon 0.4479999999999995 mean q 13.54245\n",
      "Episode:  552 Reward: 48.0 Epsilon 0.4469999999999995 mean q 13.243672\n",
      "Episode:  553 Reward: 54.0 Epsilon 0.4459999999999995 mean q 13.525103\n",
      "Episode:  554 Reward: 48.0 Epsilon 0.4449999999999995 mean q 13.545398\n",
      "Episode:  555 Reward: 52.0 Epsilon 0.4439999999999995 mean q 13.375162\n",
      "Episode:  556 Reward: 48.0 Epsilon 0.4429999999999995 mean q 13.455657\n",
      "Episode:  557 Reward: 106.0 Epsilon 0.4419999999999995 mean q 16.250431\n",
      "Episode:  558 Reward: 36.0 Epsilon 0.4409999999999995 mean q 13.6423\n",
      "Episode:  559 Reward: 57.0 Epsilon 0.4399999999999995 mean q 14.821122\n",
      "Episode:  560 Reward: 38.0 Epsilon 0.4389999999999995 mean q 15.259411\n",
      "Episode:  561 Reward: 84.0 Epsilon 0.4379999999999995 mean q 14.221932\n",
      "Episode:  562 Reward: 112.0 Epsilon 0.4369999999999995 mean q 14.503228\n",
      "Episode:  563 Reward: 122.0 Epsilon 0.4359999999999995 mean q 15.267661\n",
      "Episode:  564 Reward: 68.0 Epsilon 0.4349999999999995 mean q 16.205545\n",
      "Episode:  565 Reward: 55.0 Epsilon 0.4339999999999995 mean q 15.367068\n",
      "Episode:  566 Reward: 33.0 Epsilon 0.4329999999999995 mean q 13.919575\n",
      "Episode:  567 Reward: 109.0 Epsilon 0.4319999999999995 mean q 15.132374\n",
      "Episode:  568 Reward: 11.0 Epsilon 0.4309999999999995 mean q 12.541366\n",
      "Episode:  569 Reward: 74.0 Epsilon 0.4299999999999995 mean q 14.392771\n",
      "Episode:  570 Reward: 99.0 Epsilon 0.4289999999999995 mean q 14.621624\n",
      "Episode:  571 Reward: 64.0 Epsilon 0.4279999999999995 mean q 15.557705\n",
      "Episode:  572 Reward: 57.0 Epsilon 0.4269999999999995 mean q 15.986854\n",
      "Episode:  573 Reward: 27.0 Epsilon 0.4259999999999995 mean q 14.932092\n",
      "Episode:  574 Reward: 45.0 Epsilon 0.4249999999999995 mean q 14.59076\n",
      "Episode:  575 Reward: 65.0 Epsilon 0.4239999999999995 mean q 16.439634\n",
      "Episode:  576 Reward: 42.0 Epsilon 0.4229999999999995 mean q 15.622098\n",
      "Episode:  577 Reward: 53.0 Epsilon 0.4219999999999995 mean q 14.418267\n",
      "Episode:  578 Reward: 95.0 Epsilon 0.4209999999999995 mean q 14.967617\n",
      "Episode:  579 Reward: 110.0 Epsilon 0.4199999999999995 mean q 14.963859\n",
      "Episode:  580 Reward: 65.0 Epsilon 0.4189999999999995 mean q 15.605891\n",
      "Episode:  581 Reward: 77.0 Epsilon 0.4179999999999995 mean q 14.273466\n",
      "Episode:  582 Reward: 51.0 Epsilon 0.4169999999999995 mean q 14.904782\n",
      "Episode:  583 Reward: 61.0 Epsilon 0.4159999999999995 mean q 14.761962\n",
      "Episode:  584 Reward: 26.0 Epsilon 0.4149999999999995 mean q 15.239097\n",
      "Episode:  585 Reward: 97.0 Epsilon 0.4139999999999995 mean q 15.228387\n",
      "Episode:  586 Reward: 72.0 Epsilon 0.4129999999999995 mean q 15.077343\n",
      "Episode:  587 Reward: 78.0 Epsilon 0.4119999999999995 mean q 17.241964\n",
      "Episode:  588 Reward: 68.0 Epsilon 0.4109999999999995 mean q 16.003056\n",
      "Episode:  589 Reward: 111.0 Epsilon 0.4099999999999995 mean q 15.446848\n",
      "Episode:  590 Reward: 127.0 Epsilon 0.4089999999999995 mean q 16.23026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  591 Reward: 155.0 Epsilon 0.4079999999999995 mean q 15.661031\n",
      "Episode:  592 Reward: 91.0 Epsilon 0.4069999999999995 mean q 17.94827\n",
      "Episode:  593 Reward: 103.0 Epsilon 0.4059999999999995 mean q 15.376056\n",
      "Episode:  594 Reward: 45.0 Epsilon 0.40499999999999947 mean q 16.000088\n",
      "Episode:  595 Reward: 74.0 Epsilon 0.40399999999999947 mean q 15.198582\n",
      "Episode:  596 Reward: 106.0 Epsilon 0.40299999999999947 mean q 15.356462\n",
      "Episode:  597 Reward: 64.0 Epsilon 0.40199999999999947 mean q 15.292168\n",
      "Episode:  598 Reward: 68.0 Epsilon 0.40099999999999947 mean q 16.418564\n",
      "Episode:  599 Reward: 52.0 Epsilon 0.39999999999999947 mean q 15.881662\n",
      "Episode:  600 Reward: 32.0 Epsilon 0.39899999999999947 mean q 14.802605\n",
      "Episode:  601 Reward: 66.0 Epsilon 0.39799999999999947 mean q 15.219234\n",
      "Episode:  602 Reward: 52.0 Epsilon 0.39699999999999946 mean q 16.400398\n",
      "Episode:  603 Reward: 177.0 Epsilon 0.39599999999999946 mean q 15.343308\n",
      "Episode:  604 Reward: 73.0 Epsilon 0.39499999999999946 mean q 16.486666\n",
      "Episode:  605 Reward: 63.0 Epsilon 0.39399999999999946 mean q 16.35357\n",
      "Episode:  606 Reward: 106.0 Epsilon 0.39299999999999946 mean q 15.715861\n",
      "Episode:  607 Reward: 31.0 Epsilon 0.39199999999999946 mean q 16.104647\n",
      "Episode:  608 Reward: 120.0 Epsilon 0.39099999999999946 mean q 15.803888\n",
      "Episode:  609 Reward: 115.0 Epsilon 0.38999999999999946 mean q 16.22616\n",
      "Episode:  610 Reward: 87.0 Epsilon 0.38899999999999946 mean q 15.345957\n",
      "Episode:  611 Reward: 69.0 Epsilon 0.38799999999999946 mean q 16.886456\n",
      "Episode:  612 Reward: 96.0 Epsilon 0.38699999999999946 mean q 16.38985\n",
      "Episode:  613 Reward: 175.0 Epsilon 0.38599999999999945 mean q 16.099762\n",
      "Episode:  614 Reward: 61.0 Epsilon 0.38499999999999945 mean q 16.724194\n",
      "Episode:  615 Reward: 47.0 Epsilon 0.38399999999999945 mean q 15.331759\n",
      "Episode:  616 Reward: 72.0 Epsilon 0.38299999999999945 mean q 15.321835\n",
      "Episode:  617 Reward: 127.0 Epsilon 0.38199999999999945 mean q 15.859153\n",
      "Episode:  618 Reward: 73.0 Epsilon 0.38099999999999945 mean q 15.513286\n",
      "Episode:  619 Reward: 53.0 Epsilon 0.37999999999999945 mean q 16.596739\n",
      "Episode:  620 Reward: 62.0 Epsilon 0.37899999999999945 mean q 15.658076\n",
      "Episode:  621 Reward: 92.0 Epsilon 0.37799999999999945 mean q 15.619146\n",
      "Episode:  622 Reward: 23.0 Epsilon 0.37699999999999945 mean q 14.840671\n",
      "Episode:  623 Reward: 39.0 Epsilon 0.37599999999999945 mean q 14.883399\n",
      "Episode:  624 Reward: 88.0 Epsilon 0.37499999999999944 mean q 15.59646\n",
      "Episode:  625 Reward: 61.0 Epsilon 0.37399999999999944 mean q 15.694459\n",
      "Episode:  626 Reward: 108.0 Epsilon 0.37299999999999944 mean q 16.643892\n",
      "Episode:  627 Reward: 14.0 Epsilon 0.37199999999999944 mean q 13.745127\n",
      "Episode:  628 Reward: 68.0 Epsilon 0.37099999999999944 mean q 15.735722\n",
      "Episode:  629 Reward: 105.0 Epsilon 0.36999999999999944 mean q 17.109522\n",
      "Episode:  630 Reward: 78.0 Epsilon 0.36899999999999944 mean q 16.957857\n",
      "Episode:  631 Reward: 75.0 Epsilon 0.36799999999999944 mean q 16.318726\n",
      "Episode:  632 Reward: 68.0 Epsilon 0.36699999999999944 mean q 15.5033045\n",
      "Episode:  633 Reward: 200.0 Epsilon 0.36599999999999944 mean q 16.30189\n",
      "Episode:  634 Reward: 60.0 Epsilon 0.36499999999999944 mean q 15.654388\n",
      "Episode:  635 Reward: 154.0 Epsilon 0.36399999999999944 mean q 16.65639\n",
      "Episode:  636 Reward: 49.0 Epsilon 0.36299999999999943 mean q 16.4676\n",
      "Episode:  637 Reward: 87.0 Epsilon 0.36199999999999943 mean q 17.252758\n",
      "Episode:  638 Reward: 96.0 Epsilon 0.36099999999999943 mean q 15.584989\n",
      "Episode:  639 Reward: 89.0 Epsilon 0.35999999999999943 mean q 16.71957\n",
      "Episode:  640 Reward: 54.0 Epsilon 0.35899999999999943 mean q 16.772997\n",
      "Episode:  641 Reward: 69.0 Epsilon 0.35799999999999943 mean q 15.640542\n",
      "Episode:  642 Reward: 97.0 Epsilon 0.35699999999999943 mean q 15.370523\n",
      "Episode:  643 Reward: 115.0 Epsilon 0.35599999999999943 mean q 15.309118\n",
      "Episode:  644 Reward: 61.0 Epsilon 0.3549999999999994 mean q 17.168455\n",
      "Episode:  645 Reward: 53.0 Epsilon 0.3539999999999994 mean q 16.913198\n",
      "Episode:  646 Reward: 173.0 Epsilon 0.3529999999999994 mean q 17.058891\n",
      "Episode:  647 Reward: 136.0 Epsilon 0.3519999999999994 mean q 16.787922\n",
      "Episode:  648 Reward: 106.0 Epsilon 0.3509999999999994 mean q 17.283766\n",
      "Episode:  649 Reward: 72.0 Epsilon 0.3499999999999994 mean q 17.107113\n",
      "Episode:  650 Reward: 79.0 Epsilon 0.3489999999999994 mean q 15.280418\n",
      "Episode:  651 Reward: 48.0 Epsilon 0.3479999999999994 mean q 16.298918\n",
      "Episode:  652 Reward: 59.0 Epsilon 0.3469999999999994 mean q 15.284135\n",
      "Episode:  653 Reward: 89.0 Epsilon 0.3459999999999994 mean q 16.568806\n",
      "Episode:  654 Reward: 192.0 Epsilon 0.3449999999999994 mean q 16.081314\n",
      "Episode:  655 Reward: 35.0 Epsilon 0.3439999999999994 mean q 15.099376\n",
      "Episode:  656 Reward: 106.0 Epsilon 0.3429999999999994 mean q 15.614665\n",
      "Episode:  657 Reward: 111.0 Epsilon 0.3419999999999994 mean q 15.740105\n",
      "Episode:  658 Reward: 200.0 Epsilon 0.3409999999999994 mean q 16.155607\n",
      "Episode:  659 Reward: 63.0 Epsilon 0.3399999999999994 mean q 16.1508\n",
      "Episode:  660 Reward: 14.0 Epsilon 0.3389999999999994 mean q 13.642646\n",
      "Episode:  661 Reward: 133.0 Epsilon 0.3379999999999994 mean q 16.566204\n",
      "Episode:  662 Reward: 68.0 Epsilon 0.3369999999999994 mean q 16.619356\n",
      "Episode:  663 Reward: 77.0 Epsilon 0.3359999999999994 mean q 15.51384\n",
      "Episode:  664 Reward: 197.0 Epsilon 0.3349999999999994 mean q 16.272766\n",
      "Episode:  665 Reward: 51.0 Epsilon 0.3339999999999994 mean q 16.020521\n",
      "Episode:  666 Reward: 113.0 Epsilon 0.3329999999999994 mean q 16.474947\n",
      "Episode:  667 Reward: 112.0 Epsilon 0.3319999999999994 mean q 16.18073\n",
      "Episode:  668 Reward: 94.0 Epsilon 0.3309999999999994 mean q 16.514162\n",
      "Episode:  669 Reward: 81.0 Epsilon 0.3299999999999994 mean q 16.16503\n",
      "Episode:  670 Reward: 63.0 Epsilon 0.3289999999999994 mean q 16.380713\n",
      "Episode:  671 Reward: 78.0 Epsilon 0.3279999999999994 mean q 16.533556\n",
      "Episode:  672 Reward: 40.0 Epsilon 0.3269999999999994 mean q 16.010227\n",
      "Episode:  673 Reward: 90.0 Epsilon 0.3259999999999994 mean q 15.821366\n",
      "Episode:  674 Reward: 41.0 Epsilon 0.3249999999999994 mean q 16.057838\n",
      "Episode:  675 Reward: 186.0 Epsilon 0.3239999999999994 mean q 16.575935\n",
      "Episode:  676 Reward: 107.0 Epsilon 0.3229999999999994 mean q 15.714594\n",
      "Episode:  677 Reward: 78.0 Epsilon 0.3219999999999994 mean q 15.824477\n",
      "Episode:  678 Reward: 106.0 Epsilon 0.3209999999999994 mean q 16.221659\n",
      "Episode:  679 Reward: 104.0 Epsilon 0.3199999999999994 mean q 15.701162\n",
      "Episode:  680 Reward: 44.0 Epsilon 0.3189999999999994 mean q 14.955593\n",
      "Episode:  681 Reward: 41.0 Epsilon 0.3179999999999994 mean q 15.545879\n",
      "Episode:  682 Reward: 105.0 Epsilon 0.3169999999999994 mean q 15.6528015\n",
      "Episode:  683 Reward: 173.0 Epsilon 0.3159999999999994 mean q 16.146563\n",
      "Episode:  684 Reward: 127.0 Epsilon 0.3149999999999994 mean q 16.233202\n",
      "Episode:  685 Reward: 118.0 Epsilon 0.3139999999999994 mean q 16.445868\n",
      "Episode:  686 Reward: 97.0 Epsilon 0.3129999999999994 mean q 16.09834\n",
      "Episode:  687 Reward: 57.0 Epsilon 0.3119999999999994 mean q 15.922502\n",
      "Episode:  688 Reward: 89.0 Epsilon 0.3109999999999994 mean q 16.248602\n",
      "Episode:  689 Reward: 129.0 Epsilon 0.3099999999999994 mean q 16.39857\n",
      "Episode:  690 Reward: 103.0 Epsilon 0.3089999999999994 mean q 16.106852\n",
      "Episode:  691 Reward: 139.0 Epsilon 0.3079999999999994 mean q 15.900787\n",
      "Episode:  692 Reward: 60.0 Epsilon 0.3069999999999994 mean q 15.950782\n",
      "Episode:  693 Reward: 93.0 Epsilon 0.3059999999999994 mean q 16.011055\n",
      "Episode:  694 Reward: 106.0 Epsilon 0.3049999999999994 mean q 15.830859\n",
      "Episode:  695 Reward: 110.0 Epsilon 0.3039999999999994 mean q 15.704499\n",
      "Episode:  696 Reward: 64.0 Epsilon 0.3029999999999994 mean q 15.9645195\n",
      "Episode:  697 Reward: 130.0 Epsilon 0.3019999999999994 mean q 16.255987\n",
      "Episode:  698 Reward: 85.0 Epsilon 0.3009999999999994 mean q 15.7277\n",
      "Episode:  699 Reward: 95.0 Epsilon 0.2999999999999994 mean q 15.519092\n",
      "Episode:  700 Reward: 42.0 Epsilon 0.2989999999999994 mean q 15.679646\n",
      "Episode:  701 Reward: 114.0 Epsilon 0.2979999999999994 mean q 15.768627\n",
      "Episode:  702 Reward: 200.0 Epsilon 0.2969999999999994 mean q 16.56419\n",
      "Episode:  703 Reward: 167.0 Epsilon 0.2959999999999994 mean q 15.5030365\n",
      "Episode:  704 Reward: 170.0 Epsilon 0.2949999999999994 mean q 16.12948\n",
      "Episode:  705 Reward: 200.0 Epsilon 0.2939999999999994 mean q 16.01089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  706 Reward: 200.0 Epsilon 0.29299999999999937 mean q 16.439112\n",
      "Episode:  707 Reward: 200.0 Epsilon 0.29199999999999937 mean q 15.936366\n",
      "Episode:  708 Reward: 123.0 Epsilon 0.29099999999999937 mean q 14.83167\n",
      "Episode:  709 Reward: 145.0 Epsilon 0.28999999999999937 mean q 15.964675\n",
      "Episode:  710 Reward: 140.0 Epsilon 0.28899999999999937 mean q 15.330998\n",
      "Episode:  711 Reward: 134.0 Epsilon 0.28799999999999937 mean q 15.863842\n",
      "Episode:  712 Reward: 170.0 Epsilon 0.28699999999999937 mean q 16.398941\n",
      "Episode:  713 Reward: 108.0 Epsilon 0.28599999999999937 mean q 15.410702\n",
      "Episode:  714 Reward: 168.0 Epsilon 0.28499999999999936 mean q 16.63298\n",
      "Episode:  715 Reward: 95.0 Epsilon 0.28399999999999936 mean q 16.389397\n",
      "Episode:  716 Reward: 200.0 Epsilon 0.28299999999999936 mean q 15.558119\n",
      "Episode:  717 Reward: 141.0 Epsilon 0.28199999999999936 mean q 15.719413\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "# Initializations\n",
    "num_actions = env.action_space.n\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "print(env.observation_space)\n",
    "# Our Neural Netork model used to estimate the Q-values\n",
    "model = DoubleQLearningModel(state_dim=obs_dim, action_dim=num_actions, learning_rate=1e-4)\n",
    "\n",
    "# Create replay buffer, where experience in form of tuples <s,a,r,s',t>, gathered from the environment is stored \n",
    "# for training\n",
    "replay_buffer = ExperienceReplay(state_size=obs_dim)\n",
    "\n",
    "# Train\n",
    "num_episodes = 1200 \n",
    "batch_size = 128 \n",
    "R, R_avg = train_loop_ddqn(model, env, num_episodes, batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ccfca43f389c569bcbffc990f47b4193",
     "grade": false,
     "grade_id": "cell-4757be1a3ec18b56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# close window (if you used env.render())\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6c25e0e7133fd3583dcac959c1daede9",
     "grade": false,
     "grade_id": "cell-8f1ad36de733ed92",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "According to the code above, and the code in the provided .py file, answer the following questions:\n",
    "    \n",
    "What is the state for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2f28740b9ccf7bf2fa7f166c9fbde003",
     "grade": true,
     "grade_id": "cell-0a780f1afdcd6b1a",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d24bef4443fea27ffd50ac2afa03e864",
     "grade": false,
     "grade_id": "cell-50a080269bf6f296",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "When do we switch the networks (i.e. when does the online network become the fixed one, and vice-versa)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ec6fb2c4cdc4df93cd1669b0e4696410",
     "grade": true,
     "grade_id": "cell-099530ded38d7038",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** On every network update, there is a $50\\%$ probability for a switch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f182ff445a4e8d3848403742faa6a1cd",
     "grade": false,
     "grade_id": "cell-0836fc1b783d1158",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run the cell below to visualize your final policy in an episode from this environment.\n",
    "\n",
    "**Note:** In order to visualize, the env.render() command needs to work out on your system (see comment a few cells above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4ff19e83fbc6ba870e1b638fc7801f37",
     "grade": false,
     "grade_id": "cell-1e8a9b49909882ac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_episodes = 1\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "for i in range(num_episodes):\n",
    "        state = env.reset() #reset to initial state\n",
    "        state = np.expand_dims(state, axis=0)/2\n",
    "        terminal = False # reset terminal flag\n",
    "        while not terminal:\n",
    "            env.render()\n",
    "            time.sleep(.05)\n",
    "            q_values = model.get_q_values(state)\n",
    "            policy = eps_greedy_policy(q_values.squeeze(), .1) # greedy policy\n",
    "            action = np.random.choice(num_actions, p=policy)\n",
    "            state, reward, terminal, _ = env.step(action) # take one step in the evironment\n",
    "            state = np.expand_dims(state, axis=0)/2\n",
    "# close window\n",
    "env.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "91c95cdee8f1715e789b8bdf2a4e2ff8",
     "grade": false,
     "grade_id": "cell-0bb5d237ca6839d6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Plot the episodic rewards obtained throughout the optimization, together with a moving average of it (since the episodic reward is usually very noisy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a49cda53e12c1b8a976338c0f8bff7b9",
     "grade": false,
     "grade_id": "cell-a3c72b1dbffd2db4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbsAAAEKCAYAAACL//vOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsvXd4ZFeVt/vuCsqlnNVS55Y6ubPbOds4YGyCbWyTZgDjAQZmhkuaAAz3m+96ZhjPxXyAMXHmjo0xGOOIjW0aJ+zOwZ1b3a1WaOUslaRK+/5RQZWz8nqfR4+qdu1zzqqqU+d31t5rr6W01giCIAjCfMYw0wYIgiAIwlQjYicIgiDMe0TsBEEQhHmPiJ0gCIIw7xGxEwRBEOY9InaCIAjCvEfEThAEQZj3iNgJgiAI8x4RO0EQBGHeY5ppAwBKS0v1kiVLZtoMQRCEOcXevXt7tNZlnsflJpPpJ8A6Fp4j4wIOOxyOT23ZsqUrXIdZIXZLlixhz549M22GIAjCnEIpdc772GQy/aSysnJ1WVlZv8FgWFB5IF0ul+ru7l7T0dHxE+B94fosNPUXBEGYr6wrKysbWmhCB2AwGHRZWdkgbq82fJ9ptEcQBEGYOgwLUei8eN57RE0TsRMEQRDmPbNizk4QBEGY+xiNxi0rV64cczqdqra2duKJJ544W1pa6pxpu0A8O0EQBCFNZGZmuo4fP3701KlTRwoLCx3//u//XjbTNnmJKXZKqVql1A6l1FGl1BGl1Bc97cVKqZeVUqc8/4s87Uop9ZBSqlEpdUgptXmq34QgCIIwu7joootG29raMmbaDi/xDGM6gC9prfcppSzAXqXUy8AngFe11g8opb4GfA34KnATsNLztx34oee/IAiCMA28cao7t2/UltZpquLcDMflK8tG4+nrcDjYsWOH5ZOf/GRPOm1IhZgfhta6HWj3PB5WSh0DaoDbgKs83f4L+BNusbsN+G+ttQbeUUoVKqWqPPsRBEGY02itcboCgx6NBoXWoD2vJ4JBKQwGlUYLZ46JiQlDQ0PDms7OTvPy5cvHb7/99qGZtslLQsqvlFoCbAJ2AhV+AtYBVHge1wAtfpu1etpE7ARBmPXsb+7nWPsw92yvC2g/1TnM7qZ+CnPMDFjtaTve4pIcLl1Rmrb9AcTrgaUb75zd8PCw4aqrrlr5wAMPlP/jP/5j2Iwm003cYqeUygOeBP5Gaz2k1OSdiNZaK6USup1RSt0H3AdQV1cXo7cgCML0cKx9OGz70Xa3kzJgtVOal0FNUTYAZ3tGGRpz+PptqC1I6Hj5WeYkLZ29WCwW10MPPdR8xx13rPjqV7/aZTbP/HuMS+yUUmbcQveo1vq3nuZO7/CkUqoK8Kp3G1Drt/kiT1sAWutHgEcAtm7dumAXQgqCMPcoyctgbbVb1HpHbAyNOVhSmkNDZT7FubMmJmNGufTSS8caGhrGHnnkkeLPfe5zfTNtT0yxU24X7qfAMa31g34vPQN8HHjA8/9pv/bPK6Uexx2YMijzdYIgzC9C59gWFeYseKGzWq37/Z//8Y9/bJwpW4KJx7O7FPgo8K5S6oCn7e9xi9wTSqlPAueAOz2vvQDcDDQCVuAv0mqxIAhCGjjcNkjfqI0rViW+FMxvFodMk3sFl9GYRJCJtQ9cTsibNcvR5i3xRGO+SbjbGDfXhumvgc+laJcgCMKUcqh1MOltDX5qt6muiLwsE9UFWYnt5Owb8OQnYdE2+PCjSdsixIdkUBEEQYgD/6A8/7v/DJOBtdUFAa/H5J2H4b9vg8x8uPIr6TNSiIjkxhQEQQiDy6Ujrn9LRNcC0Br+9AC89gA0vBdu/yFk5SdvpBA3InaCIAgJYkhW7f78kFvoNn4E3vcQGIzpNUyIiIidIAhCGILXQ6Wc4+TYs/DyN2HtB+B93wODzCJNJ/JpC4IghCFa2q+EHbv+c/DUX0HNFrj9ByJ0CfB3f/d31eXl5Rc0NDSsWb58+dof/ehHxcnsRz5xQRCEMETLdKES8fNcTvjdX7kff+hnYM5Oya6FyP333995/Pjxo7/73e8av/SlLy2emJhI2NEWsRMEQQhDsGPn780l5Nnt/Tmcewtu+lcoWpwW22Yr11133fK1a9euXrFixdrvfOc7pQD/9m//VvaZz3xmkbfPQw89VPKxj32sDuDLX/5y1ZIlS9Zt2bKl/tZbb136jW98oyLSvgHWr18/kZWV5erp6Ul4slPm7ARBEMKgo/h2cQeojA3Ajv8Niy+DjfekybI4+N3nauk6mpPWfZavsXL791uidXn00UebKioqnCMjI2rTpk1rPvKRj/R/5CMf6b/ooosacBcF4De/+U3xP/zDP7S/9tprOc8++2zR0aNHj0xMTKiNGzeu2bRpkzXa/t98882cxYsXj9fU1Dii9QuHeHaCICRF78gEXUPjM23GlBGtUk/cnt0b33FnSbnxf6ewXmHu8K//+q8V9fX1a7Zs2bK6o6PDfOTIkazq6mpHbW3txKuvvprb0dFhPH36dNb1118/8tprr+XddNNNAzk5ObqoqMh1/fXXD0Ta78MPP1yxYsWKtVdddVXD17/+9aTST4pnJwhCUrx0pBMgpBTOQiAu2Rrphl0/hg0fhqoNU21SIDE8sKngueees7z22muWPXv2HLdYLK4LL7ywfmxszABwxx139P3yl78samhoGL/pppv6DQkG6Nx///2d3/72tzsfffTRgs9+9rNLbr755ndzcnISKiAgnp0gCEIExu1O2gfHgMCglLictF2PgGMCLv/SFFk3uxgYGDAWFBQ4LRaLa//+/VkHDx7M9b527733Drz00kuFv/71r4vvvffePoArr7xy5KWXXiqwWq1qcHDQ8MorrxTGOsa99947uH79+tHvf//7JYnaJ2InCIIQBq3h1WNd7DjeHWYZQgy1mxhxi13DLVC6cspsnE188IMfHHQ4HGrZsmVrv/zlL9ds2LDBV0C2rKzMuWLFivG2trbMq6++2gpw5ZVXWm+88cbBNWvWrL3mmmtW1tfXjxUUFDhjHedb3/pW+/e///1KpzNm1wBkGFMQBCEMGs3gWPiK5BGyiE1y6FcwPgCXfCH9hs1SsrOz9euvv34q0us7duwIKffzzW9+s+PBBx88Pzw8bLj44ovrt2/fHhKg8uCDD573f3755Zdbm5qaDidqn4idIAhCGMZsk56D1sFLD2Ko3YFHoWId1F44RdbNDz7ykY8sPnXqVPbExIT68Ic/3HvZZZdFjcZMBRE7QRCEMHgDcMIRVeq6jkPbXnjPwojATIVnn3327HQdS8ROEIQFhd3pwuZwpbSPqBp28DEwmGD9nVE6TQkul8ulDAZDQlGK8wWXy6WAiF+siJ0gCAuKV4910TdqS2kfEdOFuVxw6AlYecNMVB8/3N3dvaasrGxwoQmey+VS3d3dBUDEubyYYqeU+hnwXqBLa73O0/YroN7TpRAY0FpvVEotAY4BJzyvvaO1vj/pdyAIgpBmkhE6TeDQZUTPrn0/DLfDmn9OxrSUcDgcn+ro6PhJR0fHOhZepL0LOOxwOD4VqUM8nt0vgP8D/Le3QWt9l/exUuo/AP/69qe11hsTNlUQBGGOEFHsjr8Ayggrr59WewC2bNnSBbxv2g88R4gpdlrr1z0eWwjKHZJ0J3BNes0SBEGYPWit44vGPPF7WHwJ5CRVhUaYQlJ1dS8HOrXW/msrliql9iulXlNKXZ7i/gVBEGYdYdfZ9TdB1xGov2m6zRHiINUAlbuBX/o9bwfqtNa9SqktwO+UUmu11kPBGyql7gPuA6irW3i59QRBmLuEDVA5+Qf3/1U3Tq8xQlwk7dkppUzAB4Bfedu01hNa617P473AaWBVuO211o9orbdqrbeWlU171JIgCELShB3FbHoDCuqgZPm02yPEJpVhzOuA41rrVm+DUqpMKWX0PF4GrATOpGaiIAjCzBIzM6bWcO7PsOTSabJISJSYYqeU+iXwNlCvlGpVSn3S89KHCRzCBLgCOKSUOgD8Brhfa92XToMFQRBmBhX2IQA9p8Da4w5OEWYl8URj3h2h/RNh2p4EnkzdLEEQhOSw2hz8bv95rltTTrklK65tDrQM0Nxn5X0bqsO+Hlz0IKRS+bm33P8Xi2c3W1loCw8FQZjndA5NANDYNRL3NkfPDzEy7ojaR0Vx7Dj3FuRVQPGyuI8pTC8idoIgzCtCa8+ln6KcDP8DQtNbbq9OEj/PWkTsBEEQEsTgv9Bu4BwMn5f5ulmOiJ0gCPOKmLXmkkCHxGP60STzdXMBETtBEIQ4iCih5/4M2UVQ1jCd5ggJImInCMKCJp45vqhdzu+DRdvAIJfT2Yx8O4IgCB5crsiqFnZ41DEBPSehcv0UWiWkAxE7QRDmFYlGY/p3dyUaydl9HFwOqFiX2HbCtCNiJwiC4CEeqQtw8Dredf8Xz27WI2InCILgIR7Pzuivdh2HwZQti8nnACJ2giAsaPzlLZrWeSUuwLPrPAwVa8FgnALLhHQiYicIwoLGf44vkthpPSmKvryYWruHMStlvm4uIGInCILgIdowptMTqelbYTDYCuMDEpwyRxCxEwRB8BBN7DJN7svlhkWF7oauY+7/FWun2iwhDYjYCYKwoPGXN5cGkyF8rhSDQVGUY2ZZWZ67obfR/b901dQaKKQFETtBEAQvOnweTI1Gax0YnNJ7CrIKIadk+uwTkkbEThCEBU3Si8p7G6FkhZT1mSPEFDul1M+UUl1KqcN+bd9SSrUppQ54/m72e+3rSqlGpdQJpdR7pspwQRCEdOPSOmxE5uCYHbtTE5AOuvc0lK6cNtuE1IjHs/sFcGOY9v/UWm/0/L0AoJRaA3wYWOvZ5gdKKVmAIgjCrMV/2DKSX7fjeDfdwxOTTpxtFIbaoGT5lNsnpIeYYqe1fh3oi3N/twGPa60ntNZngUbgwhTsEwRBmDZcOmrlukl6T7v/l4hnN1dIZc7u80qpQ55hziJPWw3Q4ten1dMWglLqPqXUHqXUnu7u7hTMEARBCEVFrkAXgP+wZdxTdr2n3P9LViRmlDBjJCt2PwSWAxuBduA/Et2B1voRrfVWrfXWsrKyJM0QBEFIH5Hm7Lz45NPn2ckw5lwhKbHTWndqrZ1aaxfwYyaHKtuAWr+uizxtgiAIs54o5ewAv5p2PaegoBbM2VNvlJAWkhI7pVSV39P3A95IzWeADyulMpVSS4GVwK7UTBQEQZg6Ei1hB0DfGfHq5himWB2UUr8ErgJKlVKtwDeBq5RSG3EHLzUBnwHQWh9RSj0BHAUcwOe01s6pMV0QBCG9xCr86hvGHGiG+nBB6sJsJabYaa3vDtP80yj9/wX4l1SMEgRBmC5ccVQ9CMA+BqNdUFg3dUYJaUcyqAiCsKDx17c3TvVE7asU7moHAAUidnMJETtBEBY0sYYuQxhodv8vrI3eT5hViNgJgrCgSUTqlMJP7MSzm0uI2AmCsKBJxLFTKBhsAYMJLFWxNxBmDSJ2giAsbBJdejDQAvnVYJC0v3MJETtBEBY0cWbDdOMdxixcPGX2CFODiJ0gCAuahBeVD7a4s6cIcwoRO0EQFjSJaJ3BaYPhdonEnIOI2AmCsKBJZOlB5lgHaJdEYs5BROwEQVjQJOLZZVvPux/IMOacQ8ROEIR5id3pYu+5PhxOV9R+iczZ5fafcD8oq0/BMmEmiJkbUxAEYS7S2j8GgNFgQAEXLCqYLNHjRyLRmJa+w+71dZbKdJkpTBMidoIgzCuCpevo+SEAKguyqMjPCu2fgGdn6T8MVRtTsE6YKWQYUxCEBUFSdev8qMycIHvwNFSL2M1FROwEYYExYLXRNjA202ZMGaEDldFxxaGCZqPimswTKDQsuSw5w4QZRcROEBYYL7zbwWsnumfajGknoUwpQSiloOuY+0nN1jRZJEwnInaCIKREwiVyZhmueM0fbofsYjCHzvsJs5+YYqeU+plSqkspddiv7d+VUseVUoeUUk8ppQo97UuUUmNKqQOev4en0nhBEIRUiVushzuk0sEcJh7P7hfAjUFtLwPrtNYXACeBr/u9dlprvdHzd396zBQEYbYy2xy7RM2Jx36jYwy6j4GlIimbhJkn5tIDrfXrSqklQW1/8Hv6DvCh9JolCIIw8+Ra2yjv28Oy9uehvwmu/cZMmyQkSTrW2f0l8Cu/50uVUvuBIeAftdZvhNtIKXUfcB9AXZ3kmROEmWDC4WTc7qIg2zzTpswY0Ty7q/fcT/5ok/vJtd+Ate+fFpuE9JNSgIpS6h8AB/Cop6kdqNNabwL+DnhMKZUfblut9SNa661a661lZWWpmCEIQpK8eLiD5w+1z9jx7U4Xw+P2GTs+RI/SzLW2Tj5Zfds0WCNMFUmLnVLqE8B7gXu1Z4ZXaz2hte71PN4LnAZWpcFOQRCmgNEJZ8r7SGXK7o/Hu3j24MyJLcSYszP4DX6VrphyW4SpIymxU0rdCHwFeJ/W2urXXqaUMnoeLwNWAmfSYaggCPOP3hHbtB0rkqhZbZEFX5uyAXjlyt9OhUnCNBJzzk4p9UvgKqBUKdUKfBN39GUm8LInseo7nsjLK4BvK6XsgAu4X2vdN0W2C4IwC3AP7CSat2T2cKBlIGx7hm0Q00Q/++q/xFCBVDmY68QTjXl3mOafRuj7JPBkqkYJgiCkG2fcq8fdLG91e3ODFhm+nA9IBhVBEGYEV4LikypvnOpJqH9F3y7sOeW0l15CmMpAwhxDSvwIgpASyUiWzeHiN3tbY3dMMy191tidPOSMdTBWthGU+ATzAfkWBUGYdiYcqUeBJoO3oGs85Ix3Ys+tnkJrhOlExE4QhJSYiXRhJzuHeWxnM3anK6Ht4q18kGEbJMMxjD1/UTLmCbMQETtBEOYcxzuGARizh3qI0cQ3XmG+dtcnAZgoXJ6wbcLsRMROEIQABq12HtvZTP/o9K2BSxRvvEiiXmW8EZlFwycAsBU1eI4nESpzHRE7QRACaOl3B3E0JxDMkSqJ1sTzRke+crQzoe3iETuz3e01tpVdjt0iw5jzBRE7QRBSIpUK4Imyu6mPtxonlxBMOFx0Do3zm72t2Bze+bvI9sQjdt7Ez421H5IlB/MIETtBEKadYMmJ17E71TnCuV5rwLDiu62D2BwuBqyxh12dcRzI4hG74dwlvjYRvbmPiJ0gCCkxE9GY0cQnmj3xeXZncSkjIzm1SVgmzFZE7ARBmBfEo7nxiF3WRC/jGcW4DGbx6OYRInaCIMw40+UcxiN2mfYBJjIKp8EaYToRsRMEIeFoyJk+/oA1uYKv0cr5eMm0DTBhLkpq/8LsRcROEIQZmXebKlJ9K5m2fp9nJ+vr5g8idoIghCXe+apkhDLaNj0jE5zqHE58p2lg8fnnKRg9y0SGeHbzDal6IAjCNK6Ui338PxxxLxRfWWFJbl9Jvpm80RYuPfg1AKxZFcntRJi1iGcnCIIAFA8d8T22ZlUCk96tkrDMOU9cYqeU+plSqkspddivrVgp9bJS6pTnf5GnXSmlHlJKNSqlDimlNk+V8YIgpIeZD1BJftt06VBp/0HfY4nGnH/E69n9ArgxqO1rwKta65XAq57nADcBKz1/9wE/TN1MQRDSTboELql0YWnU1uC3kYw9ltFzNJz7HwD2NfxfdJRcnA7ThFlEXGKntX4d6Atqvg34L8/j/wJu92v/b+3mHaBQKVWVDmMFQZgaptuvCxak6cyvGY7C4ZMAnKq9g+NLP442uMMZZPBy/pDKnF2F1rrd87gD8M7o1gAtfv1aPW0BKKXuU0rtUUrt6e7uTsEMQRCSIV0jl7Nt2UIy9uSOnQfgQP0Xw74uojf3SUuAinaPhyR0immtH9Fab9Vaby0rK0uHGYIgJMl0C1bI0OMMz9nljrVjN+ZgN+UDUFecA0BelgSszxdSEbtO7/Ck53+Xp70N8M+gusjTJgjCDKG1pnNofKbN8DFV2jo64WB43JHwdjlj5xnNrvYp57KyXO7ZXkeGUQLW5wupfJPPAB/3PP448LRf+8c8UZkXAYN+w52CIMwAxzuGefVYF20DY742f8GJZ85scMzOuD003dZsGcUcGrPz9IHzNHaNJLxt7lg7o9mhoQXeJQey8mDuE+/Sg18CbwP1SqlWpdQngQeA65VSp4DrPM8BXgDOAI3Aj4HPpt1qQRASwuvtWCcmvR7/aMx4hhGfP9TOC++m5751KpY67G7qT3rb3HGPZ+dBxG3+EdeAtNb67ggvXRumrwY+l4pRgiDMHNF0aNzuCmlLh3DNZJCLyTFKpn2I0SwJGp/PyIC0IAjTzmwZ+oTJSExrmGFMYf4gYicIC4Bww3KzSXBmiprOHdzy5gcAAocxPYsNZDRz/iBiJwhCSsOIyWwaT9aTqU5hVtX9Jlfu+wIAPQUXsGnrpRH7SqmfuY+IXQq4XHrGcwoKQiIERGAmcOq6YlT41lrH7BNoR1AGlRn4GS3q/CMAw9mL+MMlj2LOsfglfg78L8x9ROxS4PHdLbxxqmemzRCElIm19MAVQ41eOtLJ47tbovZJlKkSQINzgqyJHrInunEqE3+42J0T05GAWAtzD0kPkCKt/WOxOwnCLCSRfJTRdEBr6Bu1JXrwdHRJiKIcM/1WO2vP/IT1jQ/jMGTRU7SRicwSILr3Kh7e3Ec8O0FYAMS6VofzovznqWJ5duFoHxzjsZ3NDI7Z6R6e4LGdzfSOTLiPF3z8hPeeONesLgegdOAQACbXODZzvu91o2Hy/Yq2zT9E7ARhAXG2Z9T3OJZ+vds2yHOH3GH5yYhdc68VgO7hCc57Mre0D8afssw7H/7i4XZePtqZ8PH9MRsVmSaje79+Umbz5MK8sr6MkrzMyQ1E7eYdInaCMM/oH7Xx2M5mBqyhQ4u9I+GHGyNJ2dCYO+OKM+o4Zvhmg8dT0lqHDAOGJoIOE43p+d836vYM04FltInqnrd8z72eXU1hdtj+En82fxCxE4R5xrk+t0eVzvnkZGI3vPrmv+1MiYdSCrqOcevrtwa0B1ckF4du/iIBKoKwAIgVYBFrCU201yMFung9O5fWIevUQou3hjtmVJMSZ///+B4O5K1gLKuc04s+ELZrsL0ignMfETtBWKBEEpNw4pWMZ2dQk2IXvO94hCzt1ctP/QGAY0s+xoH6v/VVI49ugzBfkGFMQZinJBIuH+uiHnXOzo++URsvHm7H7nThDW7UOrYtpzqHeft0b1zHCCYe4cwbbYGek+xt+Ar7V385ptDJUoP5h4idIAgxBSPaMKa/EO5v7qdv1E7PyER4z87zMHhvJzpGAiJF47EpESq7XgfgfPkVUfv5Lz/wR8Rv7iNiJwgLlESGCZ1+ymNzuHj9ZHfY13xi5ufNJZuYJFj8IhHP7kt790JBHcO5i6P2yzQb4zqmMPcQsROEBUoinpN/38aukYBIT3/PrstviUD4OTvv/mIffH/zQPwGxqBg6ARUXRCzX4ZRLonzlaQDVJRS9cCv/JqWAd8ACoFPA95bv7/XWr+QtIWCICREeCGJFY4Z/8vBQ3oOZ/g1cl6xi2edXSpEW4NndI5T0/UnLKNNsOgvYu4r0+QWO5vDXaRWEr3PH5IWO631CWAjgFLKCLQBTwF/Afyn1vo7abFQEIQpJ9qQ5r7mfgqzzRFfjxW8ErjOLjHxONU5nFD/YC45+FVqPdUN2PRROBx9aDQjSOwmkUm7uU66lh5cC5zWWp9TMpMrCHOCcLLT0mf1pfbycrx92OfxQBjPLozYHWwZoK44B3AnWPauW4sldcFiuLupP8YWoRicNjadeJCzNbdOCh1AbgkQXew21BYy4XBS7cmoIn7d/CFdYvdh4Jd+zz+vlPoYsAf4ktY68TNWEISUiFVwVIcJLIlUsmoixNOZJFzezAGrnQHroOf1cMeOZFPEw8RNyeC71J97lPpzjya8bV6miWsaKlI3Qph1pDwbq5TKAN4H/NrT9ENgOe4hznbgPyJsd59Sao9Sak93d3e4LrMaGcsXZivJnpkOZ2RB8ydYRMPN2YVsE+eAz5k4IzCjYXaE7mPP5gdS3q8wt0lH6NFNwD6tdSeA1rpTa+3UWruAHwMXhttIa/2I1nqr1nprWVlZGsyYXkTrhLnA4JidtoGx2OnCAKvdmdQxYs3Z+R97cp1d+G12ne2LuJ/2wfhyfWaPB1ZIePyGPbTU3hqhd3zI7MzcJx3DmHfjN4SplKrSWrd7nr4fOJyGYwiCkCBKwfOH3D/FhipLyOshNeXivIELnbOL7RFObpP8XeKO47FHgBaf/z3bj3w7oM1lzIzQW1hIpCR2Sqlc4HrgM37N/6aU2oj7rG4Kek0QhFmI1hp0cu5LMrXu0jEykjN2HrNjhEHLKl/b+sYf+B6/vun/JWe8A4g+f7myIm9K7RRmBymJndZ6FCgJavtoShbNEeQ3IMxWwl2gu4ZCi6aG1JSL86wOlo1YGVK0jh0skwy3vPEBzM5Rnrj+Hcr691Mw3Ej+aBMALRXX0lp5bcx9XLe6nPL8rIivW7Lcl8j6ilDPWJhbSNWDJJEAFWEu0Tdqj/p6KmezK4ba+YtopNyYyWB2ugNR7nz5ooD23131Etbs6oC2iHNuMTQ4y2zknu11yZoozCIkN44gLFB6RwIzj8R7/xYy1xfHBl6xSSRdWDSyJtxLJJyGjID2V7c9EiJ00ZgKj1OYnYjYCcI8JVYE4TtnJiMftY7f2wrWqVhzdlMxBlLX/hIAL1z6G1/b7y95nM7SixPaj0RZLhxkGDNJZBBTmL0kETCCTsCzC6oyHtecnZuRcYdnH6lRNnAAm8nCcO4Snrvsd6AUQ3nLEt6PaN3CQcQuSWTKTphvTJ1nN5kIun1wHK3jF9ZwWEbOsrj9RfcTpRiyLE96X5LecOEgw5iCIAAJzNkFR3HG4dklc5xIlAy6l+6eqr0j5DWzMVLx1QjtqZkizCFE7ARhnpJQ8IWOf+lBsCeX6Jydu3+Siqc1604/glOZ2LPm6yEv37C2MqHdiWO3cJBhzCRJpMqzIMwE8WQ28aKJ38vxipvJYeWKfV9gaPH1nK+4K6CPcjkAzdajDzC+5Gp0wWS6Lk1i3t2Wow9QPHiYI8s/TXX3G+SPNtG46APvbXh3AAAgAElEQVRoQ2jZoUSLr0o05sJBxE4Q5ikHWwYT2yBOAfLmwlzW+hSVvTup7N1J29YarFnlXLXns+R6clOOZlWRO96Obvk1jesmxc6l47xV1JrSgYO+6gVX7f2876X9DV8Ku0nCnppo3YJBxC5JJEBFmE/oBFw77xryqp63Gc2qwqhcXL3nr0L65Y6783IqNJbjT0DW9QC8eaqHzqHI1cVzrW1cse+vKRo+5WvrzV9DydBRAJqqbsZuzo/PWA8R15SL2C0YROwEYZ6RzI3Yn050xUz75cU7jGl2DDGcW4e9YAm1Z37le/3o0k8wYFlFZe87jGWWUjN0kNKdD2C4/CpcBnNUoQO47MCXAoTuzxf8PzRXvYey/n1cu+tTKEvkenOJipdo3cJBxE4QhLiFDuBU5wgAGfZhhnMX01l9HbVnfsWxJR9zDy8q97xZU4176NIx/BYb3ryfCw9/i/bSSzlXfTPg9uCsWeUYXHacphzf/r316J6+8veMZtf4FKyzZDs7tj5M+dorocsR1rZE5+Bk6cHCQcROEISkMDtGsZty6a64nOcve4rh3MU+ofOnp+IyAJa1PcOytmcYya5hKG8pt712o6/Pc5c/TZ61hS3H/g2LtZmTdXcxmrMoZF/tZZdSlpELhJ+PjKRdEdujv0VhHiFilyTzYc7O5nDxm72tXLGqlEVFObE3EAQ/zI4R7CYL/VY7WFZE7OcyBuavXHf6Rxxc9YWAtve+cVvA857CDUnZlHB8iqjdgkHEbgEzPO7OhH+4bUjEbh4xVfdh1V2vs/b0j9m3+iuYHcNkOIZxGCOXx/HZozVt1zxE/7nDOIxZbDz5EDXdb4Tt++bGf6eu4w+0VlyTlI2JDkvK0oOFg4hdksyHdXZGg/uHnkzxTWHhccnBr5LhGOGGt+9Fec7/wuHGmNtpYGjl+zmUeTVG5zhl/fsDxM6aWU7ORBenF72f5qobaa66MfLOPFzTUM6prmFa+sYC2sWzEyIhYreA8d4Fi9gJsTDZR8hwuANTlN+N3rGlH4+5rdaTw/5OYxavbf0BizpeIWe8k6qet2iuupH2kouZyCiMyxaloLIgi56RiVCxizg3537hujXl2J2a1050A2AQtVswpCx2SqkmYBhwAg6t9ValVDHwK2AJ0ATcqbXuT/VYs4n5oA/e37kzkVA8YUFSOOL24Hau+yYbTjxEX8Ea/rTt4Ti31iEjIa2V1wFwcsm9MbdeX1PAu23xLZCPNYxZbgkcdhWtWziky7O7Wmvd4/f8a8CrWusHlFJf8zz/apqOlRCH2wbJzjCyvCxvJg6fNGM2JzvP9nLJ8lIyTFOTwtQr2OLZCcEYnBNYrOcwOSdwKRM3vPNRANrKruR07YcS2lffqJ0Jj1cYjQyTAZsjNMVZljnw/Pd6aek4bcWzWzhM1TDmbcBVnsf/BfyJGRK7Q63uO8J0i91Uy8OR84OcHxjnbM8o9ZWWKT1WAikUhQVAwfBJbnnzgyHtTkMG41llSe1zdMIZV7/iXDN9o/aofSarnsf/K4ykaQbRugVDOlwGDfxBKbVXKXWfp61Ca93uedwBRE55IATQNTzO0fND03Mw7zyKeHbzilS+zvzh0yw5//uwrz1zZWi7KUJJneSJf3/pGH2XReULh3R4dpdprduUUuXAy0qp4/4vaq21UirktPQI430AdXV1aTBjetFTJBCvHO0CYFWF2xM93jE0ZZ6d9854qt5LunC5NAdaB1hTlU+W2TjT5swbDAosQ41csfevsYy10m+pp2j4RECfjuILsZstvLnx38NWGSi3ZHJ+YDykPTfTGLc354+/9lQXZmEyGFhSmsvupv6QPrP9vBVmFymLnda6zfO/Syn1FHAh0KmUqtJatyulqoCuMNs9AjwCsHXr1ll91jqcLg6fH2J9TYEvXH+6SOaCES++CLlZPox5fnCM4+3DWCecXLaydKbNoWNwHJvDRV3J3F2bmGEyYDYq6pv+B8tYK0CI0D1246GYERzp/uH6Hy3bbGT7spJpO7Ywv0lpGFMplauUsngfAzcAh4FnAG9M8seBp1M5zkxztH2Io+eHONU17Gvz/6Eda0//sON0jK7MlYvFbAuk+ePxLt5s7IndcRbj9YqyJ7rpt9Szt+ErvtdaKq7l8PL74jsJ0/yV+A8rrqkOX9kgmQAVGawUUvXsKoCnPCeoCXhMa/2iUmo38IRS6pPAOeDOFI8zo3hD8yOF6O9vHqCqIIvCnIywr89WZBhofhLv96qUImuih7GsMk4s/SgTGYUsa3uaNzY9GDbHZdhjTdEt03Wry7FkhQ6b+rOyIo/WfmvI6EdFfiYV+Vm+4DRBgBTFTmt9BghJYqe17gWuTWXfs53g68lULlVzuTSGKMOng2N2RiYc1BRmJ7TfuSZ1EkuQXgwKsid6GLCsAtxVCryVCsJhMigccZ7oydxHxS/S7v/5WWZu21jDYzubA16/dnUF43ZngNjJuSNMzQKuecZMR2zFugQ8f6jdlxEiof0mcEE63T0yY4vPxQFNP1prGg5/h5yJLqzZVXFtc/2aCsotmUH7Sa9d3l+afOVCuhGxS4CAH/Y0/hqnargx3iGo5l4rO8/0cTjOLBbC7Kd44DArTv4UgM7ibXFtE+6eT+vwa9WSHd6M574ynltP8eSEYETs0sRUzn/N9F3uhMPp+T/LwzYFIL7zZVH7HwDYu/qrdBVvTel46RSWyWUFKe4nRBJF/RY6C1bsXC5N++BY7I6E/5lMddUD/x/7lOlogvsNd1HrGhrHMU1rF6QcS3zEOl8sI2dZfu5xOmpu4MSSj7ChLs4EzH6fv3ftp/Zrv7I+uewq4Y4R7fcVbf5aECIxr8VuwGqL+Nq7bYPsON5N15B7Qeyg1U7vyASjE46kjpVuPQocMU18732jNuwxRCjevfr3835e4K6H98qxLnY19QHufJ5D49FTPcVicMzOuH3q1hYuBGKdL2vO/hyUgWMb/gFIID+kX7dwmxiUezF5ToYxouDmZ5soC5r3qyoIrYkXTbDjSSwQrIcyrCnMa7F74d2OiK8Nj7tFbdzuFoTn323npSOdPH3gfEjfSHMVU0kkz87mcMUUFIfTxYuHO3jzVPS1YPG+B2+/U50jvHKsi9Z+KwB2p/uFQavbnqf2t/Hcwfaw+4iX5w+180zQdzBbawf2jdpm5/KNGCZlj3cxlLsUW24lEL/Y+XfzbqO19rUblOK2jTXcvqkmYi7aW9ZXcf2awOyBZqPfZciX9zIyWRESo6+smDym175gYRUWLvNa7OIhkQtpOq9rQ+P2qNGNkS6ifzjaEVNQ+j3i0z0yEbHPhMPJqC05L9Zqm1rPK97w9pnmxcMdHJmuPKYJEOvTy7QPYMso8jlq8Y4K+nczhBElfzHcUFvIXdtqQ/cRRlj9jx+PKZkRPLuti4sm92lQ3LWtlo218Q3RCvOfeSt2rhgXzFQnwoM3S2Q/Ew4nzx1sZ9fZvrj277/vobHoAtUzMsHLRzvDG+nHcwfb2Xkm8vEDbZkb4jMT9I1GHiqfKWKdi5m2ASYyCn3CE+/SGv9+hjCPg+dUjQZFdWHoEGUw3jk47XeM4Ju9wpzJBeaRPLvg9zHdqf2E2c28rVQeyztI5GcQz6R5IoLg8Az/dQ6FJtD17c9/GDOBfY+Mx+etJRJZOdMjdTN9/LlGtLRq2WMd5I21cd58VUrhPv43i5PDmKH9rlhZxoTDxVP72yLuy1+UKvIzaesfIy8z8NL0nrWVOFwutAaTMfF7dJE9Yf56dhF+8E6XDgjciHYddbm0L+w+mOA7z2QuyDaHC4fTFTaa0V/gwu07kl1TQfDxZ0p8JMggPqJ9PUvaXwBg0LI84c/T/5xXfsu/vfsJO0RpUGRnhA47fnBLDfnZbkHz9xIbKvO5bWN1SOo9o0GRaTImXPVCRiUEL/NW7MJFIrpcmpeOdPDrPa2TE+FRrtw7TnTx5N62+PLhJvGbcrg0T+xpDX/X67e/cML95N62kKjFqQiWcDhdOCJUd/XatZBFaDZeSqN5dnnWFsbNhZyuvSOlKt0qYJ7N/SSRUcNMkxGTZ4Pg4cbczHk74CTMIPP2rHo2TBDHr/e2JFTOpnPIHeARLpAkZM4uwmXPO3fovzYo+GLkjWqMtv9wTNhdAXe6IR6Y315i5dcMx5jNGXX4abZUIRCCiPS1aI1ltJmRnNDAkUR3G24YM9G0et6flWHSSZwygm17/6aaBX2TthCZt55dOPyFLpEFyl4PKtq1PdwU4fC4ncd3t/D47hb2NfdH7RuMDvDsIvQJujpEEp++URuP727h/EDkRfQ7z/SGtFljRGtOl9b5PMjpOVxCzMalB+HOA7N9kPe+8T4q+3bRW7geiFwE9Ya1FcGbhzA5j+3XlvCwqPt/Kh5msmRnJD4kKsxtFpTYhUMT+4I1HiaYI3QeK3QfA9bJ9XCNnSNR+8Y0Molu3sP0epYgtPZHFrvT3aM8trM5oWwo0+XZzT45md2E+1qqet4mf7QJgKbqWyjKzYjoiZXmZXLLBVUsL8sF3IVewV31IHgTt2eXnFh5z58pjZqUk0fwMG+HMWPhPwwTy9PyeXZR+iRy3Y/Hs/MXkkhDpLECR1waHtvZ7MtQ0dg1QlGOmROdw0TiiT3uqtWXryyNOXeS7uVwkW4CZqHzNCXsaerjZOcI92yvS2k/4T6unHH3cpRfX/cWDUtqWVWZx+E29xrBcB5OQbaZbUuKqS3OocySSd+ojZyMyfPBZHT/gCxZJgbH3Dd1yd7DyRIBYTpYsJ6d/88rlqflnXc7en7It4YtWIBi/tD9DhjOI3r6QOS5sUj7/v3hwAwxkUSxfXByicPxjuGYa/UA9p7r58XDkTPQQOy1jIkS6X3OxqHCeBmw2nhsZ3Nc6/FO+nn/qRB8fimXnc3HvwOA3WShoiCTTJORjbWFXL6ylNriHK5uCM1raTAoqguzMRsNVOS7b5i8u87LNHFVfRkXLSvBkuWNqkzMTm//VLXu5vWV3LI+fJki7ychcirMec/upSMdFGSbuWhZia/thXfjT1m162wfdcU5Ie3+F3L/S0f38AQ2h4tXjnYF9A8WmrdP93K2Z9T33P/HFk7sgqst6wiPoxGPJsQ74hRPlhT/453rHY3cMU4ixlV4H8zCK1asj9w7dNzab6U4d3oq2QefB/mjZyefKIXZ4L7HNRoUtZ5zv6ogscK/ANWeYsGXLC+lc2g8ZmXxYEweO1KdswtepiAI4Ujas1NK1Sqldiiljiqljiilvuhp/5ZSqk0pdcDzd3P6zA2ld8TGme7AC63/XFk8hAR6uAJbgsWpJ0warmAnx1/oQo4X4QoZILA6/ONg/tzY49cvYjcf6awc4P+5+FeFTtYTizQHON2O3d5z/bx2MvFiuOlif3M/rx7rTGEPgR/YmjO/AOCd9d8GwGhM711DhsngE81E8C49mIkAFWHhkYpn5wC+pLXep5SyAHuVUi97XvtPrfV3Ujcvfn63v40b11UmFWEVfDFt6h0NuHgHLz3wzlEE7iP6Fdl/Ej/igvcAgfPbd5T9NvVa/frFVoV0XleiiVMyx4l4E5CA2jX3WjnUNsAt66uSDpw40RF5TjOEKKZ1DY0HnEfxcqw9geOHwf90NduHqe18Bbsxl7PV7wUmRSYZ0nn+eEV3OgKdRE+FpMVOa90OtHseDyuljgE16TIsUaw2Jx2D4ywpzQ37erQow+Df2jtBOSND18WFWbAe4/caOIwZvo8zYOg0vPBFI55+6YgF8NoW6X24tMYQ5EF2DY2zr7mfnAwTlQVZGJR7LvHylWUB24U9XgLXwnfO9uJwauxOTYYptTfrdOmUgicOtAz4Hk9lLb53zvSSn2VmTXU+EPh5Xd/3KCbnGK9c+DO0wT3MOFsCQrzDqd7vfSqynXhFLpkUY8L8Ii1ngFJqCbAJ2Olp+rxS6pBS6mdKqaKIG6YZc4QEsRCaK9P/aaQMIb6+QS97o9gCr8Lux2819tDSZyUcg2N2Xj7aiS1CXkp/EfXX03gvApp47pLTd6GL5M0+e+g8h9sCPZpdTX30jdpp7R9jT1M/u87209IXX/Fc7/uPJBit/VZfOSPvkFikihIul+aPxzvDDkUHE2udoZc9TX3sa+7n5aOdAd+hv2f5btugbwlIvMQbAHSmezRAWP3PgcL+w1C5nq6Sbb42r8gkgzcxQTrOIu+Shql07MotWVywqIDtS4un7iDCnCBlsVNK5QFPAn+jtR4CfggsBzbi9vz+I8J29yml9iil9nR3p2d+xKAiX4CDL37+c2pvNUav++aMsM8b3r6XG/58Lxe++y2MQ+6Q/XO9Vt6IUEfuQMsA3cMTtEdY3O0vgi6tyR7voqr7DXae6YuaNNqL1rFlMXg4J2fsPJuP/ivVXa9T07kjriuPt4v3I7U7ta8+IMCYzZXU8F3kaMzo271+sodmzw2G9+3ZI9zADI876Bic4J0wi+iDiXRTEszJzhGOtw/TPTxBh1/ka7Ag7G6aHDFwujSvn+yOWpsw0nsA97kU6abKF9LvHIdzf4byNQGvp1Lp+6KlJaytzk9LnbiNtYWsrrJQV5L4fF8irKspkAXkQmrRmEopM26he1Rr/VsArXWn3+s/Bp4Lt63W+hHgEYCtW7em5d5uf/MAN/gVhjQZlM+jc4RJyeWlbzR6QEu4O2yD00bp4LsAlA4ewvpKC66lL0bch1KTF79IN+z+acO01ly9+zMUjjSyg4d5dfzSmOuvXDqOucOg59fu+jQWazMN5/4HgM7ibZxYci/ny67A5Rn2MjmsbDzxIEeXfRJrdpXPc/D+H46z0kJYm/3SmKU6jOl0abxOS6Tv+3hH/PXnotUb9BJtCUroPNFkQ+fQOK39Yzi15ur68rD7tjlcZJrCX6SPeurohTsnvOfAzbbfg8sO9TeDZ1VDtPpuWxYXUZQTPaIyO8PIhjTViMswGdhUV5RQIgNBSJakxU65x2h+ChzTWj/o117lmc8DeD9wODUT42fAag+cnDcpHDZ3gy2OH1T+yBnqOv6AyTFKb8E6BiyruPTAVzi6/JNUd79B7lg756pu5EzN7Sxv/W3Atjkdu3A9dR8s+kbY2XD/puagO3KzfZAs2wA2Ryl17S+yqPOPNFXfQuFIIwBX77mfneu+Bdv/Nqr9LX1WXxXxSPT6rffKHu/CYm1mMHcZ56puZGXLE1T07aaibzd9+avZvfYfmTAXsuXYA9R0v8Gizh2cXHw3htJPsqfJGXNd2M4zvZTkZQI6omDZXS4yDe4Lergu43Yn73qGRGP5rQ6XyzeM6R2a3tfcz7LSXF9B29OeyN14RgiTKSLrb2O0KEMd8iCUcDlTIfCGJmzeVg3LSrKw/OFxt1e39nbY2Qzgm9cLR32lJbIxKXJlfVnE8lOTNeym7PCCkJJndynwUeBdpdQBT9vfA3crpTbi/hk3AZ9JycIohPO4/OdMzEYDjHeQYR9k3F4a0rdo8AgFI2foLtrIxYf+kfL+fWGPc9mBL/seV/Tt5sIj/7fv+Y6tP6S99FJu6PgRpQe+zxVdPRyo/1uG8pbF9R4qu//MtqP/C4u1hf7hz7Pp+JPkjrdT3f0GAG9f8C9sPP4g2w9/C5aVoFyXkmkfZPH5Fyjv38vh5Z+heOgoFb27OTD2RazZ1QAUDDdisZ6jo3g7DlMuoFnW+js6Si/Bml2J0WHl8n1/A8DO9f9MT9FGji37BBtOfo/y3t0UDx3jPW/fG2BrzkQXG09+l+GBt3hu0yOgjKxvfJj+/HpaK64l19pGRd8uWsuvxpZRyOnuUZ+4eBceB+NwaryJWsJ5pe/6z/3FuBg6Xdp34XQ4NeN2J8fbhznbPRpSvy+e5RFxeXY6yvMgrUs0IjBcIBQE1iIM10ejyR04AV1H4dbvJnbQKaKmMPF1fIKQTlKJxnyT8PPULyRvTmKEG/byvxBkKCeXeYYChztuY6OzmFXNj2M3ZpNtC1+le/eav8dhyqXh7C8oGj7FkWWfYkXLrwHN65u/S1n/AZacf55MWx9Ztn4G81aAUnRu+zJF4y0sOv4Mi7r+BEB76SV0FW2mpvt1mpbdw9jqD/mOo1x2Npz8HmvO/hyXMZPB3KUU7f8/ANhMFgYsK+jPX8PZmvdxvvQyrtj3Bcqe+WvuDrK3tvOPvsdL2l+gq2hziGh3Fm+jaOg4GY5h7MYcrFnlFHjyJAL059cD4DRms2/1VwBYce5XrD3zE3LHO9i/6m84tuwv2HDye6w++wssXXu4+6XN2I25mJ3h1xOeXvR+tzeq3OOKweWIvPh7T+G0Jd4lGOAZxvSckQ7npDcZrVDtgZYB8jKNrCgP9Wr2nutHa7eXuKwsL+z23soYXvzPyWjadrprJGanSHOGscTO5YLcwZPuJ7Xbo1ghCAuHOZ1BJVzgiLeoqXLZufqZqzDb3XMblsan8U7Tm5yTASK71v4T2eNdGLSTk3V3MZZVAUrRXHEdVT1v01ZxFUeWfxqjc5yJzGK6i7dydPmn3MfQTrRyD8Gd7R3Dcs1DNGVfQ8HIaTac+h5VPX+mqufPAJTuO0Sr9QRkraO14hre8/a9FA8dw2HIpO3Ol3irv5jLRl/EceZN9q7+CnZzweR7yizm1e0/5/amfybrxNMA9FkaOFV3J4u6dlAy8C6n6u6ieOgoNR6PEKDfUk/R8Akq+nbjwkBzxfVUd7/hE7r2kot554L/hdMYetfduPguGhffFbBo7mD9FzlY/0UWd73KyjP/RXn/fsbNRbRWXMOK1ifd34kyo3CxvPUpFnW+yp+2/pDewgsiDsk5AsNOoxLLGXO6tC9i0+GKXIcP3KJkc7h8c1/hxM5qc/KmJ3gpO8OIS8f2UPwFO3idn/+zaEm5vYQberfaHAGRlwdbQgOBtNYUNf0eMvKgZEXM48w0RoOiqjCL+oqpG0YVhDktduGuZd6LSF3HKz6he+HS31AwcprcsTYG81bQVbyZgpEzGFyOgJBsf5ymHForrwXAYcrBYQqNGPMKHcDQmIM3zw5D5bW0ci3Hlv0F1V2vUdP9Oi0V11Hf9hsWHf85iwAXBgy46LM08Mr2n7O9dDEM9NKx7A4a824K/14NZn679NuUFn2QgbyV7qFJpThdd0dAv7zRZvKsrYzkLGIk1x28UNa3F4Du4i0o7aSsby8jOYuwZlX6PK+IeC7YmSaDz6M4V34t58qvRbnsKI9te9b8PQqnTzgbzvyCzSf+g/e8fS9jGSUcW/YXjGWW0Vz1noDPLdCzC1Sz0QkHjV1+1SJiztn5eXYuHXUY0uuxeTnRMUx9pSViuP+O4+6I4bsvDFMLTmtAgzJE9eyiLXIP56F52871jmK1OVldlc/OM30BuU6D538Bivv2UdTyMlz8eTAmlsJrpogUpCMI6WJui12YW/1TnSMol53tZ7/HaFEDz174GC6DmQHPUJ2XnqJNU2ubwUxr5XW0Vl4HQEfFFRT3HWBd48NU97xFZ/FW/rT1hziNWWRnuC/+4TKzBKAMMe0eya3ziZyX7uIt5GYaKTYZ6BuFrpILE34/4ZZmaYPZJz8uY2B+wuPLPkFL5fVsPv5vVHW/5UtEfOnBr9JechGNtXdgdo7iqL6NFkc5+dnmACk71zvK26fdywOUy87a0z9BL74YVtyKzak52zPKqoq8AAHZ3zzAqCenp93pihpg4tKTEY3gHrJcUZ4Xc57OmzM009bPtTv/EoCCkdMoNF1FmxjTfwMVtzM8bo/ovfkLuL/twdgd3rWb7s9heVleXEEzuaMt7gdb/zJmX0FYKMwLsVMuOw1N/x951hasWZUsbv89ppEWTl/7U1/4fLxUFWbRPhB7TVvitkJP0Ub+tO1hzPYh7ObJqLiinAyUcieZ9ic7w8CYLT1h2TkZpoih/Tetq+Tlo51RL6TJZAAZzanhjc3fxeiwUtv5Ryp732ZZ2zNU9b5DVe87ALiOPcCuhq+xq+oartqwirr2F8m0DXDAejmu7GpQivL+fVzQ+ANo/AGcvYpdBbfiMGRSfvUdKD8V9v/8HM7onp3N4QqMJtWatv4xSvIyUNpJdddrVPbuYiyzhKHcZT4v/+kD52k4+18+8baZ8hjKXUzuWDvl/fvhxY/D+Q/zp/LPgLkU5XKw5PzzlPXvw5hXgs10M7v6loV41N7h9wAbnYFtTpf2ldaJRrannA/51TH7CsJCYW6LnQsyJ/rYcPK7rAhaCjB25T8xUncNdCRWNmVzXRHPD8RfNSEZ7OZ8NtQW+OZbzEZD2Pmoa+oreD6BCg7RyDYbGYsQJFKQbeYDm2t8tezCkUpuQacph6aa99JU817eueBfMNsHaWj6H4Zz6tjY8t9cdPgbjJ38LgM9H+OyA//p2240qwqXwYzF6g6bP7DqC1xw5sdc5vgTALbuJ3il9gsYcpdS3r8Hg8tB6cABlrU+jbX2CpyXfxmTw+15WTPLqO5+g6LhE9R2vExX8TaG8paRNdFDed9e8sZa6XtnDc5L7ueCk7tZe+anuJQRg3Z/Zl1FmxnOqaO7eLNP6M5W38rbF/yLu5KAfRCTc5yLen9L1ZGfcPPh3+I0ZJDhCDr/jv+YD5ksjGZXYRlt5tTWb8Gq+wO+//Le3Wx/9xvYytbDzf8AuOdvHS4XRs8XUdp/gJzxDqxZlVT2voNLmbBe8DV6rJA11oUjowCTWSIgBcGLmg21wrZu3ar37NmT8HZ9QyNk/PBC8sbaaC+5mDc2PUimvZ8CwxhXXXEt+1oGOB5HUt3cTKOvxM5tG6t55VhnSMmdRLhgUUHMDCJbFhdhc7h4t22Qe7bX0dg1wq6zgRGit1xQxfOH0iN29ZUW+kZtId4juOehlFI85lmLFUxOhhGlQssQpYOqXDCefpX1jT+kaPgEAIdWfBabOZ/azlfIs7aQO97J4eWf5tCqL7C8APqaj1Iy8C7bTv4HyhE6VOgwZGHAhcEVuYacv5B1F26kr+pwpk8AABA0SURBVGAtlT1v+YJ3Oou38drmh8i29bCy+VcsbXsWk3MMo2ef++q/xPFlnwjZ79LSXC4uHODsk//E0vPPA9Cbv4Y9a/6eobylLDn/Aovbfx8YMVu5nqPLP4VuP8TStmfJmejCbsxGKQNGh5XO4m2YXOPYV93K+dzVFHb8meXHfhBy7EHLCk7V3sGylqcwZWSR/9ev+V57/WQ3g2N2bt0g3t58Qim1V2u9dabtmAvMabEbPPpHCp54P0eW/SUHV33RNzRUV5zDZStLOdAyEDAvE457ttexu6mPU54hrQ9uqSHTZIx44Y+HC5cWsetsf8w+wRGAwcd838ZqnjlwPmk7/NlUV8iJjuGwdeq8WTgivecPbK7hhXfbGbeHDqmurMjzfXYpoTVZtl6yJnoD51e1dke9GkIHITaUOHG98yMKh08wnLOYzpLtOA0ZDFpWkOkapb7xpxQON9JUfQvFg0foKt6C3Wyhp3AD4xnFmB0jZNn6uXDrNl491oXSTi4zHaOrcT9r3/s5njo6FOBxGZ3jFA8eJsM+QkfpRTiNWSE2VRdmUV9pYcfxbjInekEZmMgIkx5Wa0zOMdYP/ZHVjT+F3kbfS735a9i17puM5Czi/aO/wrbvlzgNmVjG3J63RtFbvIkzlTeTaR/AbrYwkVXG5sP/QrbNPb93Ys0Xqb/z20l+GcJcQcQufub0MGb+6qs5dtdbHBy0BIyz5We735Z3yMffcwtHbVGO74IdLUnuPdvr4hLB4CKW4QTBGOY4RTlmX6YPgIwomdrDzec1VFkierJZZmOI0GVnGHj/pkW+54tLcjjXGxrdZ1AqrNBBGquVK8V4ZinjmaUh7VqZvA/RGkrzMugZsXGw1wgrPxuyK+/nuHvdN6Me0m7Ox27OJy/TxKa6QvY3D7BTXYB92Tq25BVyywW5PHdw0rN2GrPoLg69rqyryfclBz8/MM55z5zvRGZJSF//9+Uw5dCx9EPkbfso5955kuLeA5yu/SDDuYt93Z6vuJ/Raz4NWpM7dp7iwSOUr9jMwfGykJRo58qvpWjoBAaXjdq1F0V974Kw0JjTdS+UUqxevY57LlrMPdvruGS5++LiLfPj1ZNYEXaVBVmsrMjzbOMWyFQqgpgMig9umax2FLYSehiP+qb1VdyzvQ6l3B5CRoQqDndsXcTtG2tCyvVsrivinu11rKtxB7/4z7OZDIrqwkBPJHjpxqUrQrPMQPSyQOnSOoCK/EyubigL+1ptcTZZZvfnUZIXuTL13RfWJpzoOMNkIDfDLag2h8vnzXnbYmFKoYpA++A4b5zup7nsGg40/F2A0IHf0LFSjObU0FJ1A/m1q8Of08pAf8FqMpZuZ01t+M9REBYqc1rsgllSmstd22rJ93hW3tyEOZ7Q/kVF7gn7926owmxU5PmlsNq2pJgPb5tcQxUpS3pFvjvbe7iEucvKcn3b+ntl5WEyxOdlRr6Q3rW1litXhb9YmQwKs9GAUipAaJaXTdbxu2BRIXdtq+WurbVcuNQ9hFaYY+bKVWXcta2WD2x2C3G8RTPDrQ8r9Lz/4GHwhioL25YEDtuZjSqum4f8bHPEWmuX+QlxQXZ4scvOcH8u4TKmhEtXduHSIj60ZRFmo4GqwtAhSaNB+W6gwuE9fwpiJE/2csPaitidYlBmyaSqIJvlETK6QDqLOAnC/GFOD2OGw/9i6X1cmpfJNQ0VZJgM2J0uzEYDH9i8KGRbf48gJ8MUdujz6vpyd3FSpXBpzRN7WskwGbh5fSU5GSY21xUFeGRVBVkopbhzq/t4SimcLh3Rawu2w5811fmsr5nMrLKkNIemHit3bl0UIhLe5yvKLdQV5/qOZ1SgPPc4i0vCF7oNscez6yyzgcr8LJp6rdy4thKX1pzrs/qqpZuMik21hSilqCvJ4cm9beRlmbhxbSUad3YTs1Fhc7p4cm+bbzjSS4Zx0sPaUFvAqgoLzx06z5jNhVKKCov72ME3GhtrCwOSGDdUWtjTNDlneufWRRiU4vHdLQHbleRm+j4Xs9HAh7Ys4jd7WynOndy//3KM2zZW87TfHOoly0soyDZj9ZwnZqPi9k01/DpCVGtpXiZmo4qYTcbLHVsXsaepP6AMlZdrG9yLr7ctKQq7Xg+iJ6AWhIXKnA5QiUXX8DivHO3i4uUlLI1QwTwSJzuH2dPUzw1rK7BkmTAot0cVjN3pQhG+ErLN4cJkUCnVD/OfI1xbnR9QXsXl0u6qARHKwERjwuHEbDCE2LbjRJdvneGSkhy2LCki02T0vU+DUiHHHLc7MRpUyOcQ7bOZcDjRGn67zy2II+MOLllewpLSXMbtTp9n7XC60LjFyOnSjNoc5GeZaelz1w1cX1PAupr8EO9zzObkqf1twGQAzoTDiclgwOFyD1WG895tDhcGNWlz++BYQPYUh0ujcIugd3vvsbzfz1P7W0PmU/OyTLxvQzV7z/VzomOYMktm2MjYqoIsrm4o9323b5/u9c0B1lfmsWXxZBFSh9OFzemi32rntROTNSG3LililaTeWhBIgEr8zGuxA3cuwZw4516CGZ1wkBtluHE6sDlctA+O8VZjL5etKJ3yQpdOl8budItBpilUDNPN6ISDnAx38Eyin3Ws7+exnc2YDIo7t4VJ8ZUAw+N2TAaDL9NNLFvsThcurXlybxsGBe/fXINRKUxGAy6XZsLhIsNkYNTmwGwwoJT7czd6hqj9vXSHJxOMS2uyzcawQ8pesV1cksPG2sIZP2eF6UPELn7mvdjNF4bG7b65SCE+xu1ODEpFHTKe6uMrRVKed6IMj9vJzTBN+c2JMLsQsYsfuQWcI4jQJU6kIKP5ePzg5S6CIAQyr6IxBUEQBCEcInaCIAjCvGfKxE4pdaNS6oRSqlEp9bWpOo4gCIIgxGJKxE4pZQS+D9wErAHuVkqtib6VIAiCIEwNU+XZXQg0aq3PaK1twOPAbVN0LEEQBEGIylSJXQ3gn66i1dMmCIIgCNPOjC09UErdB9zneTqilDqRwu5KgZ7UrUo7YldiiF2JIXYlzmy1LVm7FsfuIsDUiV0b4J+2YpGnzYfW+hHgkXQcTCm1ZzYurBS7EkPsSgyxK3Fmq22z1a75xFQNY+4GViqlliqlMoAPA89M0bEEQRAEISpT4tlprR1Kqc8DLwFG4Gda6yNTcSxBEARBiMWUzdlprV8AXpiq/QeRluHQKUDsSgyxKzHErsSZrbbNVrvmDbMiEbQgCIIgTCWSLkwQBEGY98xpsZvJlGRKqZ8ppbqUUof92oqVUi8rpU55/hd52pVS6iGPnYeUUpun0K5apdQOpdRRpdQRpdQXZ4NtSqkspdQupdRBj13/7GlfqpTa6Tn+rzwBTSil/v/2zjXUjuqK47+/icZroomJrcRHjUHwUQwmLTVBEVHb+qgKGkjUooX2g61QtJQ2qaWaj4r4QlBBLdra67tRIr4j+I41JsZo1Ea8tYoxWppIHxRNlx/2OrnjNTES7z0zd87/B8PZs/bcs//n7HXumr1mZu9xub8266eNhK6KvjGSVkha0jBdA5JelrRS0gtpa4KfTZJ0l6TXJK2RNKduXZIOzO+ps30k6fy6dWVbF6Tfr5bUn7+HRvhYzxARo3Kj3PjyJjAd2Al4CTiki+0fBcwCVldslwILsrwAuCTLJwIPAAJmA8tGUNdUYFaWdwXeoEzZVqu2fP8JWd4RWJbt3QHMT/t1wE+z/DPguizPB24f4f78BfAnYEnuN0XXALDHEFsT/Oxm4CdZ3gmY1ARdFX1jgHWU59Dq9v29gbeAvopv/agpPtYrW+0Ctls4zAEequwvBBZ2WcM0PhvsXgemZnkq8HqWrwfO2NJxXdB4L/DdJmkDdgFeBA6nPEg7dmifUu7knZPlsXmcRkjPPsBjwDHAkvznV7uubGOAzwe7WvsSmJj/vNUkXUO0fA94ugm6GJxRanL6zBLg+03xsV7ZRnMas4lTku0ZEe9leR2wZ5Zr0Zrpj5mUUVTt2jJVuBJYDzxCGZlviIhPttD2Zl1ZvxGYMhK6gCuBXwH/z/0pDdEFEMDDkparzDoE9ffl/sAHwO8z9XuDpPEN0FVlPtCf5Vp1RcS7wGXA28B7FJ9ZTnN8rCcYzcGu0UQ5LavtVldJE4C7gfMj4qNqXV3aImJTRBxGGUl9Bzio2xqGIukHwPqIWF63lq1wZETMoqwgcp6ko6qVNfXlWEoK/9qImAn8m5IerFsXAHnt6xTgzqF1dejKa4SnUk4S9gLGA8d3U4MZ3cFum1OS1cD7kqYC5Ov6tHdVq6QdKYHu1oi4p0naACJiA/A4JXUzSVLnec9q25t1Zf1E4B8jIOcI4BRJA5TVOY4BrmqALmDzqICIWA/8mXKSUHdfvgO8ExHLcv8uSvCrW1eHE4AXI+L93K9b13HAWxHxQUR8DNxD8btG+FivMJqDXROnJLsPOCfL51Cul3XsZ+fdX7OBjZW0yrAiScCNwJqIuLwp2iR9TdKkLPdRriOuoQS9uVvR1dE7F1iaZ+XDSkQsjIh9ImIaxYeWRsRZdesCkDRe0q6dMuU61Gpq7suIWAf8XdKBaToWeLVuXRXOYDCF2Wm/Tl1vA7Ml7ZK/z873VbuP9RR1XzT8Khvlbqo3KNd+Luxy2/2U/PvHlDPdH1Py6o8BfwUeBSbnsaIsZvsm8DLw7RHUdSQlTbMKWJnbiXVrA2YAK1LXauB3aZ8OPA+spaSdxqV959xfm/XTu9CnRzN4N2btulLDS7m90vHxuvsy2zoMeCH7czGwe0N0jaeMgiZWbE3QtQh4LX3/D8C4JvhYL22eQcUYY0zrGc1pTGOMMeZL4WBnjDGm9TjYGWOMaT0OdsYYY1qPg50xxpjW42BnWomkTUNmwP/CVTEknSvp7GFod0DSHl/1fYwxw4sfPTCtRNK/ImJCDe0OUJ7X+rDbbRtjto5HdqanyJHXpSprxD0v6YC0Xyzpl1n+ucp6gKsk3Za2yZIWp+05STPSPkXSw7lW2Q2UB5U7bf0w21gp6XpJY2r4yMYYHOxMe+kbksacV6nbGBGHAtdQVjwYygJgZkTMAM5N2yJgRdp+A9yS9ouApyLim5S5K78BIOlgYB5wRJTJrzcBZw3vRzTGfFnGbvsQY0Yl/80gsyX6K69XbKF+FXCrpMWUqbCgTMN2OkBELM0R3W6URXxPS/v9kv6Zxx8LfAv4S5kOkT4GJyA2xnQZBzvTi8RWyh1OogSxk4ELJR26HW0IuDkiFm7H3xpjhhmnMU0vMq/y+my1QtIOwL4R8Tjwa8ryKhOAJ8k0pKSjgQ+jrBP4BHBm2k+gTIgMZeLhuZK+nnWTJe03gp/JGPMFeGRn2kpfrore4cGI6Dx+sLukVcD/KMvBVBkD/FHSRMro7OqI2CDpYuCm/Lv/MLgEyyKgX9IrwDOU5VyIiFcl/ZayyvgOlNUxzgP+Ntwf1Bizbfzogekp/GiAMb2J05jGGGNaj0d2xhhjWo9HdsYYY1qPg50xxpjW42BnjDGm9TjYGWOMaT0OdsYYY1qPg50xxpjW8ynkIrwmBkgczgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rewards = plt.plot(R, alpha=.4, label='R')\n",
    "avg_rewards = plt.plot(R_avg,label='avg R')\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylim(0, 210)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "99ff38a2a4ff5f958140c9ee6019db87",
     "grade": false,
     "grade_id": "cell-293ec5dfa636ff48",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Congratulations, you have now successfully implemented the DDQN algorithm. You are encouraged to explore different problems. There are a lot of different environments ready for you to implement your algorithms in. A few of these resources are:\n",
    "* [OpenAI gym](https://github.com/openai/gym)\n",
    "* [OpenAI Universe](https://github.com/openai/universe)\n",
    "* [DeepMind Lab](https://deepmind.com/blog/open-sourcing-deepmind-lab/)\n",
    "\n",
    "The model you implemented in this lab can be extended to solve harder problems. A good starting-point is to try to solve the Acrobot-problem, by loading the environment as \n",
    "\n",
    "**gym.make(\"Acrobot-v1\")**.\n",
    "\n",
    "The problem might require some modifications to how you decay $\\epsilon$, but otherwise, the code you have written within this lab should be sufficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Box(2,)\n",
      "Episode:  0 Reward: -200.0 Epsilon 0.999 mean q 3.561487e-08\n",
      "Episode:  1 Reward: -200.0 Epsilon 0.998 mean q 3.5972764e-08\n",
      "Episode:  2 Reward: -200.0 Epsilon 0.997 mean q 3.601018e-08\n",
      "Episode:  3 Reward: -200.0 Epsilon 0.996 mean q 3.6732597e-08\n",
      "Episode:  4 Reward: -200.0 Epsilon 0.995 mean q 3.5432986e-08\n",
      "Episode:  5 Reward: -200.0 Epsilon 0.994 mean q -0.0522401\n",
      "Episode:  6 Reward: -200.0 Epsilon 0.993 mean q -0.22779271\n",
      "Episode:  7 Reward: -200.0 Epsilon 0.992 mean q -0.5302948\n",
      "Episode:  8 Reward: -200.0 Epsilon 0.991 mean q -0.98812014\n",
      "Episode:  9 Reward: -200.0 Epsilon 0.99 mean q -1.6735307\n",
      "Episode:  10 Reward: -200.0 Epsilon 0.989 mean q -2.4534392\n",
      "Episode:  11 Reward: -200.0 Epsilon 0.988 mean q -3.5384896\n",
      "Episode:  12 Reward: -200.0 Epsilon 0.987 mean q -4.813646\n",
      "Episode:  13 Reward: -200.0 Epsilon 0.986 mean q -6.4917264\n",
      "Episode:  14 Reward: -200.0 Epsilon 0.985 mean q -8.115942\n",
      "Episode:  15 Reward: -200.0 Epsilon 0.984 mean q -10.357406\n",
      "Episode:  16 Reward: -200.0 Epsilon 0.983 mean q -12.875311\n",
      "Episode:  17 Reward: -200.0 Epsilon 0.982 mean q -15.277751\n",
      "Episode:  18 Reward: -200.0 Epsilon 0.981 mean q -16.77982\n",
      "Episode:  19 Reward: -200.0 Epsilon 0.98 mean q -16.271973\n",
      "Episode:  20 Reward: -200.0 Epsilon 0.979 mean q -16.24959\n",
      "Episode:  21 Reward: -200.0 Epsilon 0.978 mean q -16.46028\n",
      "Episode:  22 Reward: -200.0 Epsilon 0.977 mean q -16.456715\n",
      "Episode:  23 Reward: -200.0 Epsilon 0.976 mean q -16.39789\n",
      "Episode:  24 Reward: -200.0 Epsilon 0.975 mean q -16.157185\n",
      "Episode:  25 Reward: -200.0 Epsilon 0.974 mean q -16.099648\n",
      "Episode:  26 Reward: -200.0 Epsilon 0.973 mean q -16.286077\n",
      "Episode:  27 Reward: -200.0 Epsilon 0.972 mean q -16.123892\n",
      "Episode:  28 Reward: -200.0 Epsilon 0.971 mean q -16.13554\n",
      "Episode:  29 Reward: -200.0 Epsilon 0.97 mean q -16.220991\n",
      "Episode:  30 Reward: -200.0 Epsilon 0.969 mean q -16.208757\n",
      "Episode:  31 Reward: -200.0 Epsilon 0.968 mean q -16.357471\n",
      "Episode:  32 Reward: -200.0 Epsilon 0.967 mean q -16.158869\n",
      "Episode:  33 Reward: -200.0 Epsilon 0.966 mean q -16.170784\n",
      "Episode:  34 Reward: -200.0 Epsilon 0.965 mean q -16.239267\n",
      "Episode:  35 Reward: -200.0 Epsilon 0.964 mean q -16.245264\n",
      "Episode:  36 Reward: -200.0 Epsilon 0.963 mean q -16.280182\n",
      "Episode:  37 Reward: -200.0 Epsilon 0.962 mean q -16.296783\n",
      "Episode:  38 Reward: -200.0 Epsilon 0.961 mean q -16.155504\n",
      "Episode:  39 Reward: -200.0 Epsilon 0.96 mean q -16.307356\n",
      "Episode:  40 Reward: -200.0 Epsilon 0.959 mean q -16.29026\n",
      "Episode:  41 Reward: -200.0 Epsilon 0.958 mean q -16.126226\n",
      "Episode:  42 Reward: -200.0 Epsilon 0.957 mean q -16.526026\n",
      "Episode:  43 Reward: -200.0 Epsilon 0.956 mean q -16.417152\n",
      "Episode:  44 Reward: -200.0 Epsilon 0.955 mean q -16.100554\n",
      "Episode:  45 Reward: -200.0 Epsilon 0.954 mean q -16.325438\n",
      "Episode:  46 Reward: -200.0 Epsilon 0.953 mean q -16.225336\n",
      "Episode:  47 Reward: -200.0 Epsilon 0.952 mean q -16.469633\n",
      "Episode:  48 Reward: -200.0 Epsilon 0.951 mean q -16.31848\n",
      "Episode:  49 Reward: -200.0 Epsilon 0.95 mean q -16.293861\n",
      "Episode:  50 Reward: -200.0 Epsilon 0.949 mean q -16.437117\n",
      "Episode:  51 Reward: -200.0 Epsilon 0.948 mean q -16.48281\n",
      "Episode:  52 Reward: -200.0 Epsilon 0.947 mean q -16.307245\n",
      "Episode:  53 Reward: -200.0 Epsilon 0.946 mean q -16.202688\n",
      "Episode:  54 Reward: -200.0 Epsilon 0.945 mean q -16.269218\n",
      "Episode:  55 Reward: -200.0 Epsilon 0.944 mean q -16.120943\n",
      "Episode:  56 Reward: -200.0 Epsilon 0.943 mean q -16.08862\n",
      "Episode:  57 Reward: -200.0 Epsilon 0.942 mean q -16.106411\n",
      "Episode:  58 Reward: -200.0 Epsilon 0.941 mean q -16.098938\n",
      "Episode:  59 Reward: -200.0 Epsilon 0.94 mean q -16.294106\n",
      "Episode:  60 Reward: -200.0 Epsilon 0.939 mean q -16.167812\n",
      "Episode:  61 Reward: -200.0 Epsilon 0.938 mean q -16.18024\n",
      "Episode:  62 Reward: -200.0 Epsilon 0.9369999999999999 mean q -16.205036\n",
      "Episode:  63 Reward: -200.0 Epsilon 0.9359999999999999 mean q -16.093435\n",
      "Episode:  64 Reward: -200.0 Epsilon 0.9349999999999999 mean q -16.324879\n",
      "Episode:  65 Reward: -200.0 Epsilon 0.9339999999999999 mean q -16.23502\n",
      "Episode:  66 Reward: -200.0 Epsilon 0.9329999999999999 mean q -16.140417\n",
      "Episode:  67 Reward: -200.0 Epsilon 0.9319999999999999 mean q -16.141918\n",
      "Episode:  68 Reward: -200.0 Epsilon 0.9309999999999999 mean q -16.186825\n",
      "Episode:  69 Reward: -200.0 Epsilon 0.9299999999999999 mean q -16.275185\n",
      "Episode:  70 Reward: -200.0 Epsilon 0.9289999999999999 mean q -16.302488\n",
      "Episode:  71 Reward: -200.0 Epsilon 0.9279999999999999 mean q -16.161327\n",
      "Episode:  72 Reward: -200.0 Epsilon 0.9269999999999999 mean q -16.088766\n",
      "Episode:  73 Reward: -200.0 Epsilon 0.9259999999999999 mean q -16.238527\n",
      "Episode:  74 Reward: -200.0 Epsilon 0.9249999999999999 mean q -16.10974\n",
      "Episode:  75 Reward: -200.0 Epsilon 0.9239999999999999 mean q -16.176579\n",
      "Episode:  76 Reward: -200.0 Epsilon 0.9229999999999999 mean q -16.287386\n",
      "Episode:  77 Reward: -200.0 Epsilon 0.9219999999999999 mean q -16.214779\n",
      "Episode:  78 Reward: -200.0 Epsilon 0.9209999999999999 mean q -16.145546\n",
      "Episode:  79 Reward: -200.0 Epsilon 0.9199999999999999 mean q -16.182526\n",
      "Episode:  80 Reward: -200.0 Epsilon 0.9189999999999999 mean q -16.111471\n",
      "Episode:  81 Reward: -200.0 Epsilon 0.9179999999999999 mean q -16.119995\n",
      "Episode:  82 Reward: -200.0 Epsilon 0.9169999999999999 mean q -16.259315\n",
      "Episode:  83 Reward: -200.0 Epsilon 0.9159999999999999 mean q -16.119755\n",
      "Episode:  84 Reward: -200.0 Epsilon 0.9149999999999999 mean q -16.096006\n",
      "Episode:  85 Reward: -200.0 Epsilon 0.9139999999999999 mean q -16.12718\n",
      "Episode:  86 Reward: -200.0 Epsilon 0.9129999999999999 mean q -16.118114\n",
      "Episode:  87 Reward: -200.0 Epsilon 0.9119999999999999 mean q -16.13839\n",
      "Episode:  88 Reward: -200.0 Epsilon 0.9109999999999999 mean q -16.234863\n",
      "Episode:  89 Reward: -200.0 Epsilon 0.9099999999999999 mean q -16.241934\n",
      "Episode:  90 Reward: -200.0 Epsilon 0.9089999999999999 mean q -16.140755\n",
      "Episode:  91 Reward: -200.0 Epsilon 0.9079999999999999 mean q -16.253975\n",
      "Episode:  92 Reward: -200.0 Epsilon 0.9069999999999999 mean q -16.200996\n",
      "Episode:  93 Reward: -200.0 Epsilon 0.9059999999999999 mean q -16.110468\n",
      "Episode:  94 Reward: -200.0 Epsilon 0.9049999999999999 mean q -16.154457\n",
      "Episode:  95 Reward: -200.0 Epsilon 0.9039999999999999 mean q -16.098488\n",
      "Episode:  96 Reward: -200.0 Epsilon 0.9029999999999999 mean q -16.131693\n",
      "Episode:  97 Reward: -200.0 Epsilon 0.9019999999999999 mean q -16.152601\n",
      "Episode:  98 Reward: -200.0 Epsilon 0.9009999999999999 mean q -16.031208\n",
      "Episode:  99 Reward: -200.0 Epsilon 0.8999999999999999 mean q -16.101543\n",
      "Episode:  100 Reward: -200.0 Epsilon 0.8989999999999999 mean q -16.143435\n",
      "Episode:  101 Reward: -200.0 Epsilon 0.8979999999999999 mean q -16.10435\n",
      "Episode:  102 Reward: -200.0 Epsilon 0.8969999999999999 mean q -16.079573\n",
      "Episode:  103 Reward: -200.0 Epsilon 0.8959999999999999 mean q -16.049994\n",
      "Episode:  104 Reward: -200.0 Epsilon 0.8949999999999999 mean q -16.001568\n",
      "Episode:  105 Reward: -200.0 Epsilon 0.8939999999999999 mean q -16.031084\n",
      "Episode:  106 Reward: -200.0 Epsilon 0.8929999999999999 mean q -16.060411\n",
      "Episode:  107 Reward: -200.0 Epsilon 0.8919999999999999 mean q -16.07571\n",
      "Episode:  108 Reward: -200.0 Epsilon 0.8909999999999999 mean q -16.057056\n",
      "Episode:  109 Reward: -200.0 Epsilon 0.8899999999999999 mean q -16.119385\n",
      "Episode:  110 Reward: -200.0 Epsilon 0.8889999999999999 mean q -16.139463\n",
      "Episode:  111 Reward: -200.0 Epsilon 0.8879999999999999 mean q -16.163473\n",
      "Episode:  112 Reward: -200.0 Epsilon 0.8869999999999999 mean q -16.138102\n",
      "Episode:  113 Reward: -200.0 Epsilon 0.8859999999999999 mean q -16.16252\n",
      "Episode:  114 Reward: -200.0 Epsilon 0.8849999999999999 mean q -16.097746\n",
      "Episode:  115 Reward: -200.0 Epsilon 0.8839999999999999 mean q -16.144892\n",
      "Episode:  116 Reward: -200.0 Epsilon 0.8829999999999999 mean q -16.138865\n",
      "Episode:  117 Reward: -200.0 Epsilon 0.8819999999999999 mean q -16.13998\n",
      "Episode:  118 Reward: -200.0 Epsilon 0.8809999999999999 mean q -16.143486\n",
      "Episode:  119 Reward: -200.0 Epsilon 0.8799999999999999 mean q -16.109623\n",
      "Episode:  120 Reward: -200.0 Epsilon 0.8789999999999999 mean q -16.151594\n",
      "Episode:  121 Reward: -200.0 Epsilon 0.8779999999999999 mean q -16.191864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  122 Reward: -200.0 Epsilon 0.8769999999999999 mean q -16.166367\n",
      "Episode:  123 Reward: -200.0 Epsilon 0.8759999999999999 mean q -16.180481\n",
      "Episode:  124 Reward: -200.0 Epsilon 0.8749999999999999 mean q -16.215384\n",
      "Episode:  125 Reward: -200.0 Epsilon 0.8739999999999999 mean q -16.187433\n",
      "Episode:  126 Reward: -200.0 Epsilon 0.8729999999999999 mean q -16.232796\n",
      "Episode:  127 Reward: -200.0 Epsilon 0.8719999999999999 mean q -16.219938\n",
      "Episode:  128 Reward: -200.0 Epsilon 0.8709999999999999 mean q -16.21859\n",
      "Episode:  129 Reward: -200.0 Epsilon 0.8699999999999999 mean q -16.198393\n",
      "Episode:  130 Reward: -200.0 Epsilon 0.8689999999999999 mean q -16.26191\n",
      "Episode:  131 Reward: -200.0 Epsilon 0.8679999999999999 mean q -16.228624\n",
      "Episode:  132 Reward: -200.0 Epsilon 0.8669999999999999 mean q -16.242487\n",
      "Episode:  133 Reward: -200.0 Epsilon 0.8659999999999999 mean q -16.267712\n",
      "Episode:  134 Reward: -200.0 Epsilon 0.8649999999999999 mean q -16.223265\n",
      "Episode:  135 Reward: -200.0 Epsilon 0.8639999999999999 mean q -16.213802\n",
      "Episode:  136 Reward: -200.0 Epsilon 0.8629999999999999 mean q -16.243528\n",
      "Episode:  137 Reward: -200.0 Epsilon 0.8619999999999999 mean q -16.271715\n",
      "Episode:  138 Reward: -200.0 Epsilon 0.8609999999999999 mean q -16.319088\n",
      "Episode:  139 Reward: -200.0 Epsilon 0.8599999999999999 mean q -16.280933\n",
      "Episode:  140 Reward: -200.0 Epsilon 0.8589999999999999 mean q -16.287931\n",
      "Episode:  141 Reward: -200.0 Epsilon 0.8579999999999999 mean q -16.241703\n",
      "Episode:  142 Reward: -200.0 Epsilon 0.8569999999999999 mean q -16.292131\n",
      "Episode:  143 Reward: -200.0 Epsilon 0.8559999999999999 mean q -16.28014\n",
      "Episode:  144 Reward: -200.0 Epsilon 0.8549999999999999 mean q -16.327078\n",
      "Episode:  145 Reward: -200.0 Epsilon 0.8539999999999999 mean q -16.289103\n",
      "Episode:  146 Reward: -200.0 Epsilon 0.8529999999999999 mean q -16.332449\n",
      "Episode:  147 Reward: -200.0 Epsilon 0.8519999999999999 mean q -16.344454\n",
      "Episode:  148 Reward: -200.0 Epsilon 0.8509999999999999 mean q -16.33905\n",
      "Episode:  149 Reward: -200.0 Epsilon 0.8499999999999999 mean q -16.3581\n",
      "Episode:  150 Reward: -200.0 Epsilon 0.8489999999999999 mean q -16.352943\n",
      "Episode:  151 Reward: -200.0 Epsilon 0.8479999999999999 mean q -16.385832\n",
      "Episode:  152 Reward: -200.0 Epsilon 0.8469999999999999 mean q -16.334423\n",
      "Episode:  153 Reward: -200.0 Epsilon 0.8459999999999999 mean q -16.311493\n",
      "Episode:  154 Reward: -200.0 Epsilon 0.8449999999999999 mean q -16.35476\n",
      "Episode:  155 Reward: -200.0 Epsilon 0.8439999999999999 mean q -16.361162\n",
      "Episode:  156 Reward: -200.0 Epsilon 0.8429999999999999 mean q -16.353577\n",
      "Episode:  157 Reward: -200.0 Epsilon 0.8419999999999999 mean q -16.404581\n",
      "Episode:  158 Reward: -200.0 Epsilon 0.8409999999999999 mean q -16.408049\n",
      "Episode:  159 Reward: -200.0 Epsilon 0.8399999999999999 mean q -16.383257\n",
      "Episode:  160 Reward: -200.0 Epsilon 0.8389999999999999 mean q -16.445417\n",
      "Episode:  161 Reward: -200.0 Epsilon 0.8379999999999999 mean q -16.430664\n",
      "Episode:  162 Reward: -200.0 Epsilon 0.8369999999999999 mean q -16.425625\n",
      "Episode:  163 Reward: -200.0 Epsilon 0.8359999999999999 mean q -16.394245\n",
      "Episode:  164 Reward: -200.0 Epsilon 0.8349999999999999 mean q -16.412382\n",
      "Episode:  165 Reward: -200.0 Epsilon 0.8339999999999999 mean q -16.446573\n",
      "Episode:  166 Reward: -200.0 Epsilon 0.8329999999999999 mean q -16.458727\n",
      "Episode:  167 Reward: -200.0 Epsilon 0.8319999999999999 mean q -16.439457\n",
      "Episode:  168 Reward: -200.0 Epsilon 0.8309999999999998 mean q -16.479742\n",
      "Episode:  169 Reward: -200.0 Epsilon 0.8299999999999998 mean q -16.439415\n",
      "Episode:  170 Reward: -200.0 Epsilon 0.8289999999999998 mean q -16.399483\n",
      "Episode:  171 Reward: -200.0 Epsilon 0.8279999999999998 mean q -16.470604\n",
      "Episode:  172 Reward: -200.0 Epsilon 0.8269999999999998 mean q -16.493742\n",
      "Episode:  173 Reward: -200.0 Epsilon 0.8259999999999998 mean q -16.44252\n",
      "Episode:  174 Reward: -200.0 Epsilon 0.8249999999999998 mean q -16.534689\n",
      "Episode:  175 Reward: -200.0 Epsilon 0.8239999999999998 mean q -16.471062\n",
      "Episode:  176 Reward: -200.0 Epsilon 0.8229999999999998 mean q -16.49393\n",
      "Episode:  177 Reward: -200.0 Epsilon 0.8219999999999998 mean q -16.478685\n",
      "Episode:  178 Reward: -200.0 Epsilon 0.8209999999999998 mean q -16.489962\n",
      "Episode:  179 Reward: -200.0 Epsilon 0.8199999999999998 mean q -16.516058\n",
      "Episode:  180 Reward: -200.0 Epsilon 0.8189999999999998 mean q -16.536064\n",
      "Episode:  181 Reward: -200.0 Epsilon 0.8179999999999998 mean q -16.531067\n",
      "Episode:  182 Reward: -200.0 Epsilon 0.8169999999999998 mean q -16.526077\n",
      "Episode:  183 Reward: -200.0 Epsilon 0.8159999999999998 mean q -16.53974\n",
      "Episode:  184 Reward: -200.0 Epsilon 0.8149999999999998 mean q -16.560764\n",
      "Episode:  185 Reward: -200.0 Epsilon 0.8139999999999998 mean q -16.545513\n",
      "Episode:  186 Reward: -200.0 Epsilon 0.8129999999999998 mean q -16.57122\n",
      "Episode:  187 Reward: -200.0 Epsilon 0.8119999999999998 mean q -16.549253\n",
      "Episode:  188 Reward: -200.0 Epsilon 0.8109999999999998 mean q -16.535555\n",
      "Episode:  189 Reward: -200.0 Epsilon 0.8099999999999998 mean q -16.576149\n",
      "Episode:  190 Reward: -200.0 Epsilon 0.8089999999999998 mean q -16.554432\n",
      "Episode:  191 Reward: -200.0 Epsilon 0.8079999999999998 mean q -16.595781\n",
      "Episode:  192 Reward: -200.0 Epsilon 0.8069999999999998 mean q -16.614363\n",
      "Episode:  193 Reward: -200.0 Epsilon 0.8059999999999998 mean q -16.572615\n",
      "Episode:  194 Reward: -200.0 Epsilon 0.8049999999999998 mean q -16.599178\n",
      "Episode:  195 Reward: -200.0 Epsilon 0.8039999999999998 mean q -16.600163\n",
      "Episode:  196 Reward: -200.0 Epsilon 0.8029999999999998 mean q -16.603277\n",
      "Episode:  197 Reward: -200.0 Epsilon 0.8019999999999998 mean q -16.60861\n",
      "Episode:  198 Reward: -200.0 Epsilon 0.8009999999999998 mean q -16.58384\n",
      "Episode:  199 Reward: -200.0 Epsilon 0.7999999999999998 mean q -16.586832\n",
      "Episode:  200 Reward: -200.0 Epsilon 0.7989999999999998 mean q -16.62056\n",
      "Episode:  201 Reward: -200.0 Epsilon 0.7979999999999998 mean q -16.626514\n",
      "Episode:  202 Reward: -200.0 Epsilon 0.7969999999999998 mean q -16.635382\n",
      "Episode:  203 Reward: -200.0 Epsilon 0.7959999999999998 mean q -16.660479\n",
      "Episode:  204 Reward: -200.0 Epsilon 0.7949999999999998 mean q -16.625824\n",
      "Episode:  205 Reward: -200.0 Epsilon 0.7939999999999998 mean q -16.645452\n",
      "Episode:  206 Reward: -200.0 Epsilon 0.7929999999999998 mean q -16.652046\n",
      "Episode:  207 Reward: -200.0 Epsilon 0.7919999999999998 mean q -16.67083\n",
      "Episode:  208 Reward: -200.0 Epsilon 0.7909999999999998 mean q -16.676184\n",
      "Episode:  209 Reward: -200.0 Epsilon 0.7899999999999998 mean q -16.667992\n",
      "Episode:  210 Reward: -200.0 Epsilon 0.7889999999999998 mean q -16.634161\n",
      "Episode:  211 Reward: -200.0 Epsilon 0.7879999999999998 mean q -16.615068\n",
      "Episode:  212 Reward: -200.0 Epsilon 0.7869999999999998 mean q -16.646044\n",
      "Episode:  213 Reward: -200.0 Epsilon 0.7859999999999998 mean q -16.640139\n",
      "Episode:  214 Reward: -200.0 Epsilon 0.7849999999999998 mean q -16.611029\n",
      "Episode:  215 Reward: -200.0 Epsilon 0.7839999999999998 mean q -16.618242\n",
      "Episode:  216 Reward: -200.0 Epsilon 0.7829999999999998 mean q -16.591143\n",
      "Episode:  217 Reward: -200.0 Epsilon 0.7819999999999998 mean q -16.584545\n",
      "Episode:  218 Reward: -200.0 Epsilon 0.7809999999999998 mean q -16.646238\n",
      "Episode:  219 Reward: -200.0 Epsilon 0.7799999999999998 mean q -16.573433\n",
      "Episode:  220 Reward: -200.0 Epsilon 0.7789999999999998 mean q -16.588343\n",
      "Episode:  221 Reward: -200.0 Epsilon 0.7779999999999998 mean q -16.549974\n",
      "Episode:  222 Reward: -200.0 Epsilon 0.7769999999999998 mean q -16.554949\n",
      "Episode:  223 Reward: -200.0 Epsilon 0.7759999999999998 mean q -16.604803\n",
      "Episode:  224 Reward: -200.0 Epsilon 0.7749999999999998 mean q -16.558067\n",
      "Episode:  225 Reward: -200.0 Epsilon 0.7739999999999998 mean q -16.578825\n",
      "Episode:  226 Reward: -200.0 Epsilon 0.7729999999999998 mean q -16.537527\n",
      "Episode:  227 Reward: -200.0 Epsilon 0.7719999999999998 mean q -16.589678\n",
      "Episode:  228 Reward: -200.0 Epsilon 0.7709999999999998 mean q -16.567085\n",
      "Episode:  229 Reward: -200.0 Epsilon 0.7699999999999998 mean q -16.565117\n",
      "Episode:  230 Reward: -200.0 Epsilon 0.7689999999999998 mean q -16.608685\n",
      "Episode:  231 Reward: -200.0 Epsilon 0.7679999999999998 mean q -16.554493\n",
      "Episode:  232 Reward: -200.0 Epsilon 0.7669999999999998 mean q -16.544323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  233 Reward: -200.0 Epsilon 0.7659999999999998 mean q -16.53808\n",
      "Episode:  234 Reward: -200.0 Epsilon 0.7649999999999998 mean q -16.552164\n",
      "Episode:  235 Reward: -200.0 Epsilon 0.7639999999999998 mean q -16.54429\n",
      "Episode:  236 Reward: -200.0 Epsilon 0.7629999999999998 mean q -16.564766\n",
      "Episode:  237 Reward: -200.0 Epsilon 0.7619999999999998 mean q -16.55366\n",
      "Episode:  238 Reward: -200.0 Epsilon 0.7609999999999998 mean q -16.5705\n",
      "Episode:  239 Reward: -200.0 Epsilon 0.7599999999999998 mean q -16.570408\n",
      "Episode:  240 Reward: -200.0 Epsilon 0.7589999999999998 mean q -16.596136\n",
      "Episode:  241 Reward: -200.0 Epsilon 0.7579999999999998 mean q -16.609375\n",
      "Episode:  242 Reward: -200.0 Epsilon 0.7569999999999998 mean q -16.588509\n",
      "Episode:  243 Reward: -200.0 Epsilon 0.7559999999999998 mean q -16.603188\n",
      "Episode:  244 Reward: -200.0 Epsilon 0.7549999999999998 mean q -16.608332\n",
      "Episode:  245 Reward: -200.0 Epsilon 0.7539999999999998 mean q -16.657915\n",
      "Episode:  246 Reward: -200.0 Epsilon 0.7529999999999998 mean q -16.605951\n",
      "Episode:  247 Reward: -200.0 Epsilon 0.7519999999999998 mean q -16.598772\n",
      "Episode:  248 Reward: -200.0 Epsilon 0.7509999999999998 mean q -16.604898\n",
      "Episode:  249 Reward: -200.0 Epsilon 0.7499999999999998 mean q -16.626116\n",
      "Episode:  250 Reward: -200.0 Epsilon 0.7489999999999998 mean q -16.644121\n",
      "Episode:  251 Reward: -200.0 Epsilon 0.7479999999999998 mean q -16.635038\n",
      "Episode:  252 Reward: -200.0 Epsilon 0.7469999999999998 mean q -16.626673\n",
      "Episode:  253 Reward: -200.0 Epsilon 0.7459999999999998 mean q -16.61524\n",
      "Episode:  254 Reward: -200.0 Epsilon 0.7449999999999998 mean q -16.615995\n",
      "Episode:  255 Reward: -200.0 Epsilon 0.7439999999999998 mean q -16.65683\n",
      "Episode:  256 Reward: -200.0 Epsilon 0.7429999999999998 mean q -16.618721\n",
      "Episode:  257 Reward: -200.0 Epsilon 0.7419999999999998 mean q -16.610355\n",
      "Episode:  258 Reward: -200.0 Epsilon 0.7409999999999998 mean q -16.628347\n",
      "Episode:  259 Reward: -200.0 Epsilon 0.7399999999999998 mean q -16.675312\n",
      "Episode:  260 Reward: -200.0 Epsilon 0.7389999999999998 mean q -16.651793\n",
      "Episode:  261 Reward: -200.0 Epsilon 0.7379999999999998 mean q -16.664862\n",
      "Episode:  262 Reward: -200.0 Epsilon 0.7369999999999998 mean q -16.686308\n",
      "Episode:  263 Reward: -200.0 Epsilon 0.7359999999999998 mean q -16.691227\n",
      "Episode:  264 Reward: -200.0 Epsilon 0.7349999999999998 mean q -16.630268\n",
      "Episode:  265 Reward: -200.0 Epsilon 0.7339999999999998 mean q -16.666084\n",
      "Episode:  266 Reward: -200.0 Epsilon 0.7329999999999998 mean q -16.663315\n",
      "Episode:  267 Reward: -200.0 Epsilon 0.7319999999999998 mean q -16.659388\n",
      "Episode:  268 Reward: -200.0 Epsilon 0.7309999999999998 mean q -16.700134\n",
      "Episode:  269 Reward: -200.0 Epsilon 0.7299999999999998 mean q -16.675007\n",
      "Episode:  270 Reward: -200.0 Epsilon 0.7289999999999998 mean q -16.662085\n",
      "Episode:  271 Reward: -200.0 Epsilon 0.7279999999999998 mean q -16.629381\n",
      "Episode:  272 Reward: -200.0 Epsilon 0.7269999999999998 mean q -16.667992\n",
      "Episode:  273 Reward: -200.0 Epsilon 0.7259999999999998 mean q -16.671898\n",
      "Episode:  274 Reward: -200.0 Epsilon 0.7249999999999998 mean q -16.649813\n",
      "Episode:  275 Reward: -200.0 Epsilon 0.7239999999999998 mean q -16.658264\n",
      "Episode:  276 Reward: -200.0 Epsilon 0.7229999999999998 mean q -16.691109\n",
      "Episode:  277 Reward: -200.0 Epsilon 0.7219999999999998 mean q -16.657152\n",
      "Episode:  278 Reward: -200.0 Epsilon 0.7209999999999998 mean q -16.659363\n",
      "Episode:  279 Reward: -200.0 Epsilon 0.7199999999999998 mean q -16.692663\n",
      "Episode:  280 Reward: -200.0 Epsilon 0.7189999999999998 mean q -16.669724\n",
      "Episode:  281 Reward: -200.0 Epsilon 0.7179999999999997 mean q -16.66736\n",
      "Episode:  282 Reward: -200.0 Epsilon 0.7169999999999997 mean q -16.707018\n",
      "Episode:  283 Reward: -200.0 Epsilon 0.7159999999999997 mean q -16.6579\n",
      "Episode:  284 Reward: -200.0 Epsilon 0.7149999999999997 mean q -16.666975\n",
      "Episode:  285 Reward: -200.0 Epsilon 0.7139999999999997 mean q -16.67772\n",
      "Episode:  286 Reward: -200.0 Epsilon 0.7129999999999997 mean q -16.663103\n",
      "Episode:  287 Reward: -200.0 Epsilon 0.7119999999999997 mean q -16.694271\n",
      "Episode:  288 Reward: -200.0 Epsilon 0.7109999999999997 mean q -16.64347\n",
      "Episode:  289 Reward: -200.0 Epsilon 0.7099999999999997 mean q -16.654291\n",
      "Episode:  290 Reward: -200.0 Epsilon 0.7089999999999997 mean q -16.649298\n",
      "Episode:  291 Reward: -200.0 Epsilon 0.7079999999999997 mean q -16.6747\n",
      "Episode:  292 Reward: -200.0 Epsilon 0.7069999999999997 mean q -16.646069\n",
      "Episode:  293 Reward: -200.0 Epsilon 0.7059999999999997 mean q -16.680502\n",
      "Episode:  294 Reward: -200.0 Epsilon 0.7049999999999997 mean q -16.683737\n",
      "Episode:  295 Reward: -200.0 Epsilon 0.7039999999999997 mean q -16.682453\n",
      "Episode:  296 Reward: -200.0 Epsilon 0.7029999999999997 mean q -16.637796\n",
      "Episode:  297 Reward: -200.0 Epsilon 0.7019999999999997 mean q -16.661713\n",
      "Episode:  298 Reward: -200.0 Epsilon 0.7009999999999997 mean q -16.663555\n",
      "Episode:  299 Reward: -200.0 Epsilon 0.6999999999999997 mean q -16.649673\n",
      "Episode:  300 Reward: -200.0 Epsilon 0.6989999999999997 mean q -16.643171\n",
      "Episode:  301 Reward: -200.0 Epsilon 0.6979999999999997 mean q -16.64561\n",
      "Episode:  302 Reward: -200.0 Epsilon 0.6969999999999997 mean q -16.655235\n",
      "Episode:  303 Reward: -200.0 Epsilon 0.6959999999999997 mean q -16.669283\n",
      "Episode:  304 Reward: -200.0 Epsilon 0.6949999999999997 mean q -16.646715\n",
      "Episode:  305 Reward: -200.0 Epsilon 0.6939999999999997 mean q -16.639389\n",
      "Episode:  306 Reward: -200.0 Epsilon 0.6929999999999997 mean q -16.682184\n",
      "Episode:  307 Reward: -200.0 Epsilon 0.6919999999999997 mean q -16.675909\n",
      "Episode:  308 Reward: -200.0 Epsilon 0.6909999999999997 mean q -16.63743\n",
      "Episode:  309 Reward: -200.0 Epsilon 0.6899999999999997 mean q -16.656445\n",
      "Episode:  310 Reward: -200.0 Epsilon 0.6889999999999997 mean q -16.660006\n",
      "Episode:  311 Reward: -200.0 Epsilon 0.6879999999999997 mean q -16.677845\n",
      "Episode:  312 Reward: -200.0 Epsilon 0.6869999999999997 mean q -16.680092\n",
      "Episode:  313 Reward: -200.0 Epsilon 0.6859999999999997 mean q -16.652317\n",
      "Episode:  314 Reward: -200.0 Epsilon 0.6849999999999997 mean q -16.67\n",
      "Episode:  315 Reward: -200.0 Epsilon 0.6839999999999997 mean q -16.673025\n",
      "Episode:  316 Reward: -200.0 Epsilon 0.6829999999999997 mean q -16.636526\n",
      "Episode:  317 Reward: -200.0 Epsilon 0.6819999999999997 mean q -16.656898\n",
      "Episode:  318 Reward: -200.0 Epsilon 0.6809999999999997 mean q -16.685627\n",
      "Episode:  319 Reward: -200.0 Epsilon 0.6799999999999997 mean q -16.668573\n",
      "Episode:  320 Reward: -200.0 Epsilon 0.6789999999999997 mean q -16.682945\n",
      "Episode:  321 Reward: -200.0 Epsilon 0.6779999999999997 mean q -16.687466\n",
      "Episode:  322 Reward: -200.0 Epsilon 0.6769999999999997 mean q -16.672062\n",
      "Episode:  323 Reward: -200.0 Epsilon 0.6759999999999997 mean q -16.666916\n",
      "Episode:  324 Reward: -200.0 Epsilon 0.6749999999999997 mean q -16.66546\n",
      "Episode:  325 Reward: -200.0 Epsilon 0.6739999999999997 mean q -16.691189\n",
      "Episode:  326 Reward: -200.0 Epsilon 0.6729999999999997 mean q -16.714598\n",
      "Episode:  327 Reward: -200.0 Epsilon 0.6719999999999997 mean q -16.678827\n",
      "Episode:  328 Reward: -200.0 Epsilon 0.6709999999999997 mean q -16.643793\n",
      "Episode:  329 Reward: -200.0 Epsilon 0.6699999999999997 mean q -16.669172\n",
      "Episode:  330 Reward: -200.0 Epsilon 0.6689999999999997 mean q -16.647171\n",
      "Episode:  331 Reward: -200.0 Epsilon 0.6679999999999997 mean q -16.641888\n",
      "Episode:  332 Reward: -200.0 Epsilon 0.6669999999999997 mean q -16.660732\n",
      "Episode:  333 Reward: -200.0 Epsilon 0.6659999999999997 mean q -16.687832\n",
      "Episode:  334 Reward: -200.0 Epsilon 0.6649999999999997 mean q -16.700108\n",
      "Episode:  335 Reward: -200.0 Epsilon 0.6639999999999997 mean q -16.672966\n",
      "Episode:  336 Reward: -200.0 Epsilon 0.6629999999999997 mean q -16.66049\n",
      "Episode:  337 Reward: -200.0 Epsilon 0.6619999999999997 mean q -16.668268\n",
      "Episode:  338 Reward: -200.0 Epsilon 0.6609999999999997 mean q -16.659592\n",
      "Episode:  339 Reward: -200.0 Epsilon 0.6599999999999997 mean q -16.675987\n",
      "Episode:  340 Reward: -200.0 Epsilon 0.6589999999999997 mean q -16.688515\n",
      "Episode:  341 Reward: -200.0 Epsilon 0.6579999999999997 mean q -16.67959\n",
      "Episode:  342 Reward: -200.0 Epsilon 0.6569999999999997 mean q -16.663847\n",
      "Episode:  343 Reward: -200.0 Epsilon 0.6559999999999997 mean q -16.657452\n",
      "Episode:  344 Reward: -200.0 Epsilon 0.6549999999999997 mean q -16.663372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  345 Reward: -200.0 Epsilon 0.6539999999999997 mean q -16.657642\n",
      "Episode:  346 Reward: -200.0 Epsilon 0.6529999999999997 mean q -16.665232\n",
      "Episode:  347 Reward: -200.0 Epsilon 0.6519999999999997 mean q -16.65525\n",
      "Episode:  348 Reward: -200.0 Epsilon 0.6509999999999997 mean q -16.640873\n",
      "Episode:  349 Reward: -200.0 Epsilon 0.6499999999999997 mean q -16.68972\n",
      "Episode:  350 Reward: -200.0 Epsilon 0.6489999999999997 mean q -16.645576\n",
      "Episode:  351 Reward: -200.0 Epsilon 0.6479999999999997 mean q -16.684132\n",
      "Episode:  352 Reward: -200.0 Epsilon 0.6469999999999997 mean q -16.635061\n",
      "Episode:  353 Reward: -200.0 Epsilon 0.6459999999999997 mean q -16.659254\n",
      "Episode:  354 Reward: -200.0 Epsilon 0.6449999999999997 mean q -16.646448\n",
      "Episode:  355 Reward: -200.0 Epsilon 0.6439999999999997 mean q -16.682024\n",
      "Episode:  356 Reward: -200.0 Epsilon 0.6429999999999997 mean q -16.712938\n",
      "Episode:  357 Reward: -200.0 Epsilon 0.6419999999999997 mean q -16.7064\n",
      "Episode:  358 Reward: -200.0 Epsilon 0.6409999999999997 mean q -16.659443\n",
      "Episode:  359 Reward: -200.0 Epsilon 0.6399999999999997 mean q -16.68416\n",
      "Episode:  360 Reward: -200.0 Epsilon 0.6389999999999997 mean q -16.678663\n",
      "Episode:  361 Reward: -200.0 Epsilon 0.6379999999999997 mean q -16.675621\n",
      "Episode:  362 Reward: -200.0 Epsilon 0.6369999999999997 mean q -16.676308\n",
      "Episode:  363 Reward: -200.0 Epsilon 0.6359999999999997 mean q -16.658121\n",
      "Episode:  364 Reward: -200.0 Epsilon 0.6349999999999997 mean q -16.628374\n",
      "Episode:  365 Reward: -200.0 Epsilon 0.6339999999999997 mean q -16.692347\n",
      "Episode:  366 Reward: -200.0 Epsilon 0.6329999999999997 mean q -16.652391\n",
      "Episode:  367 Reward: -200.0 Epsilon 0.6319999999999997 mean q -16.6484\n",
      "Episode:  368 Reward: -200.0 Epsilon 0.6309999999999997 mean q -16.705454\n",
      "Episode:  369 Reward: -200.0 Epsilon 0.6299999999999997 mean q -16.703226\n",
      "Episode:  370 Reward: -200.0 Epsilon 0.6289999999999997 mean q -16.653522\n",
      "Episode:  371 Reward: -200.0 Epsilon 0.6279999999999997 mean q -16.637087\n",
      "Episode:  372 Reward: -200.0 Epsilon 0.6269999999999997 mean q -16.647867\n",
      "Episode:  373 Reward: -200.0 Epsilon 0.6259999999999997 mean q -16.694233\n",
      "Episode:  374 Reward: -200.0 Epsilon 0.6249999999999997 mean q -16.642708\n",
      "Episode:  375 Reward: -200.0 Epsilon 0.6239999999999997 mean q -16.668428\n",
      "Episode:  376 Reward: -200.0 Epsilon 0.6229999999999997 mean q -16.675179\n",
      "Episode:  377 Reward: -200.0 Epsilon 0.6219999999999997 mean q -16.633078\n",
      "Episode:  378 Reward: -200.0 Epsilon 0.6209999999999997 mean q -16.69256\n",
      "Episode:  379 Reward: -200.0 Epsilon 0.6199999999999997 mean q -16.669088\n",
      "Episode:  380 Reward: -200.0 Epsilon 0.6189999999999997 mean q -16.703188\n",
      "Episode:  381 Reward: -200.0 Epsilon 0.6179999999999997 mean q -16.678785\n",
      "Episode:  382 Reward: -200.0 Epsilon 0.6169999999999997 mean q -16.661575\n",
      "Episode:  383 Reward: -200.0 Epsilon 0.6159999999999997 mean q -16.67325\n",
      "Episode:  384 Reward: -200.0 Epsilon 0.6149999999999997 mean q -16.667301\n",
      "Episode:  385 Reward: -200.0 Epsilon 0.6139999999999997 mean q -16.672525\n",
      "Episode:  386 Reward: -200.0 Epsilon 0.6129999999999997 mean q -16.64315\n",
      "Episode:  387 Reward: -200.0 Epsilon 0.6119999999999997 mean q -16.63588\n",
      "Episode:  388 Reward: -200.0 Epsilon 0.6109999999999997 mean q -16.669815\n",
      "Episode:  389 Reward: -200.0 Epsilon 0.6099999999999997 mean q -16.67413\n",
      "Episode:  390 Reward: -200.0 Epsilon 0.6089999999999997 mean q -16.663343\n",
      "Episode:  391 Reward: -200.0 Epsilon 0.6079999999999997 mean q -16.68919\n",
      "Episode:  392 Reward: -200.0 Epsilon 0.6069999999999997 mean q -16.671715\n",
      "Episode:  393 Reward: -200.0 Epsilon 0.6059999999999997 mean q -16.660662\n",
      "Episode:  394 Reward: -200.0 Epsilon 0.6049999999999996 mean q -16.658115\n",
      "Episode:  395 Reward: -200.0 Epsilon 0.6039999999999996 mean q -16.64376\n",
      "Episode:  396 Reward: -200.0 Epsilon 0.6029999999999996 mean q -16.633015\n",
      "Episode:  397 Reward: -200.0 Epsilon 0.6019999999999996 mean q -16.661793\n",
      "Episode:  398 Reward: -200.0 Epsilon 0.6009999999999996 mean q -16.648962\n",
      "Episode:  399 Reward: -200.0 Epsilon 0.5999999999999996 mean q -16.656876\n",
      "Episode:  400 Reward: -200.0 Epsilon 0.5989999999999996 mean q -16.69168\n",
      "Episode:  401 Reward: -200.0 Epsilon 0.5979999999999996 mean q -16.687796\n",
      "Episode:  402 Reward: -200.0 Epsilon 0.5969999999999996 mean q -16.63551\n",
      "Episode:  403 Reward: -200.0 Epsilon 0.5959999999999996 mean q -16.719728\n",
      "Episode:  404 Reward: -200.0 Epsilon 0.5949999999999996 mean q -16.639954\n",
      "Episode:  405 Reward: -200.0 Epsilon 0.5939999999999996 mean q -16.687422\n",
      "Episode:  406 Reward: -200.0 Epsilon 0.5929999999999996 mean q -16.651361\n",
      "Episode:  407 Reward: -200.0 Epsilon 0.5919999999999996 mean q -16.676731\n",
      "Episode:  408 Reward: -200.0 Epsilon 0.5909999999999996 mean q -16.675116\n",
      "Episode:  409 Reward: -200.0 Epsilon 0.5899999999999996 mean q -16.65708\n",
      "Episode:  410 Reward: -200.0 Epsilon 0.5889999999999996 mean q -16.665459\n",
      "Episode:  411 Reward: -200.0 Epsilon 0.5879999999999996 mean q -16.66274\n",
      "Episode:  412 Reward: -200.0 Epsilon 0.5869999999999996 mean q -16.653671\n",
      "Episode:  413 Reward: -200.0 Epsilon 0.5859999999999996 mean q -16.65568\n",
      "Episode:  414 Reward: -200.0 Epsilon 0.5849999999999996 mean q -16.667006\n",
      "Episode:  415 Reward: -200.0 Epsilon 0.5839999999999996 mean q -16.645771\n",
      "Episode:  416 Reward: -200.0 Epsilon 0.5829999999999996 mean q -16.673887\n",
      "Episode:  417 Reward: -200.0 Epsilon 0.5819999999999996 mean q -16.64605\n",
      "Episode:  418 Reward: -200.0 Epsilon 0.5809999999999996 mean q -16.666412\n",
      "Episode:  419 Reward: -200.0 Epsilon 0.5799999999999996 mean q -16.668596\n",
      "Episode:  420 Reward: -200.0 Epsilon 0.5789999999999996 mean q -16.636042\n",
      "Episode:  421 Reward: -200.0 Epsilon 0.5779999999999996 mean q -16.61995\n",
      "Episode:  422 Reward: -200.0 Epsilon 0.5769999999999996 mean q -16.672106\n",
      "Episode:  423 Reward: -200.0 Epsilon 0.5759999999999996 mean q -16.685114\n",
      "Episode:  424 Reward: -200.0 Epsilon 0.5749999999999996 mean q -16.672464\n",
      "Episode:  425 Reward: -200.0 Epsilon 0.5739999999999996 mean q -16.67734\n",
      "Episode:  426 Reward: -200.0 Epsilon 0.5729999999999996 mean q -16.652584\n",
      "Episode:  427 Reward: -200.0 Epsilon 0.5719999999999996 mean q -16.691784\n",
      "Episode:  428 Reward: -200.0 Epsilon 0.5709999999999996 mean q -16.662914\n",
      "Episode:  429 Reward: -200.0 Epsilon 0.5699999999999996 mean q -16.656343\n",
      "Episode:  430 Reward: -200.0 Epsilon 0.5689999999999996 mean q -16.64062\n",
      "Episode:  431 Reward: -200.0 Epsilon 0.5679999999999996 mean q -16.680004\n",
      "Episode:  432 Reward: -200.0 Epsilon 0.5669999999999996 mean q -16.693865\n",
      "Episode:  433 Reward: -200.0 Epsilon 0.5659999999999996 mean q -16.666832\n",
      "Episode:  434 Reward: -200.0 Epsilon 0.5649999999999996 mean q -16.642328\n",
      "Episode:  435 Reward: -200.0 Epsilon 0.5639999999999996 mean q -16.662981\n",
      "Episode:  436 Reward: -200.0 Epsilon 0.5629999999999996 mean q -16.650398\n",
      "Episode:  437 Reward: -200.0 Epsilon 0.5619999999999996 mean q -16.67765\n",
      "Episode:  438 Reward: -200.0 Epsilon 0.5609999999999996 mean q -16.67277\n",
      "Episode:  439 Reward: -200.0 Epsilon 0.5599999999999996 mean q -16.681694\n",
      "Episode:  440 Reward: -200.0 Epsilon 0.5589999999999996 mean q -16.65374\n",
      "Episode:  441 Reward: -200.0 Epsilon 0.5579999999999996 mean q -16.665924\n",
      "Episode:  442 Reward: -200.0 Epsilon 0.5569999999999996 mean q -16.678223\n",
      "Episode:  443 Reward: -200.0 Epsilon 0.5559999999999996 mean q -16.669048\n",
      "Episode:  444 Reward: -200.0 Epsilon 0.5549999999999996 mean q -16.660383\n",
      "Episode:  445 Reward: -200.0 Epsilon 0.5539999999999996 mean q -16.677868\n",
      "Episode:  446 Reward: -200.0 Epsilon 0.5529999999999996 mean q -16.68071\n",
      "Episode:  447 Reward: -200.0 Epsilon 0.5519999999999996 mean q -16.667511\n",
      "Episode:  448 Reward: -200.0 Epsilon 0.5509999999999996 mean q -16.668522\n",
      "Episode:  449 Reward: -200.0 Epsilon 0.5499999999999996 mean q -16.676907\n",
      "Episode:  450 Reward: -200.0 Epsilon 0.5489999999999996 mean q -16.653774\n",
      "Episode:  451 Reward: -200.0 Epsilon 0.5479999999999996 mean q -16.644941\n",
      "Episode:  452 Reward: -200.0 Epsilon 0.5469999999999996 mean q -16.68592\n",
      "Episode:  453 Reward: -200.0 Epsilon 0.5459999999999996 mean q -16.674976\n",
      "Episode:  454 Reward: -200.0 Epsilon 0.5449999999999996 mean q -16.68963\n",
      "Episode:  455 Reward: -200.0 Epsilon 0.5439999999999996 mean q -16.690203\n",
      "Episode:  456 Reward: -200.0 Epsilon 0.5429999999999996 mean q -16.654615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  457 Reward: -200.0 Epsilon 0.5419999999999996 mean q -16.651482\n",
      "Episode:  458 Reward: -200.0 Epsilon 0.5409999999999996 mean q -16.655691\n",
      "Episode:  459 Reward: -200.0 Epsilon 0.5399999999999996 mean q -16.689526\n",
      "Episode:  460 Reward: -200.0 Epsilon 0.5389999999999996 mean q -16.676441\n",
      "Episode:  461 Reward: -200.0 Epsilon 0.5379999999999996 mean q -16.642406\n",
      "Episode:  462 Reward: -200.0 Epsilon 0.5369999999999996 mean q -16.648298\n",
      "Episode:  463 Reward: -200.0 Epsilon 0.5359999999999996 mean q -16.66151\n",
      "Episode:  464 Reward: -200.0 Epsilon 0.5349999999999996 mean q -16.642906\n",
      "Episode:  465 Reward: -200.0 Epsilon 0.5339999999999996 mean q -16.683304\n",
      "Episode:  466 Reward: -200.0 Epsilon 0.5329999999999996 mean q -16.665932\n",
      "Episode:  467 Reward: -200.0 Epsilon 0.5319999999999996 mean q -16.652424\n",
      "Episode:  468 Reward: -200.0 Epsilon 0.5309999999999996 mean q -16.65233\n",
      "Episode:  469 Reward: -200.0 Epsilon 0.5299999999999996 mean q -16.647865\n",
      "Episode:  470 Reward: -200.0 Epsilon 0.5289999999999996 mean q -16.66041\n",
      "Episode:  471 Reward: -200.0 Epsilon 0.5279999999999996 mean q -16.688093\n",
      "Episode:  472 Reward: -200.0 Epsilon 0.5269999999999996 mean q -16.642786\n",
      "Episode:  473 Reward: -200.0 Epsilon 0.5259999999999996 mean q -16.655632\n",
      "Episode:  474 Reward: -200.0 Epsilon 0.5249999999999996 mean q -16.640533\n",
      "Episode:  475 Reward: -200.0 Epsilon 0.5239999999999996 mean q -16.666132\n",
      "Episode:  476 Reward: -200.0 Epsilon 0.5229999999999996 mean q -16.66772\n",
      "Episode:  477 Reward: -200.0 Epsilon 0.5219999999999996 mean q -16.673712\n",
      "Episode:  478 Reward: -200.0 Epsilon 0.5209999999999996 mean q -16.660147\n",
      "Episode:  479 Reward: -200.0 Epsilon 0.5199999999999996 mean q -16.652174\n",
      "Episode:  480 Reward: -200.0 Epsilon 0.5189999999999996 mean q -16.643827\n",
      "Episode:  481 Reward: -200.0 Epsilon 0.5179999999999996 mean q -16.668476\n",
      "Episode:  482 Reward: -200.0 Epsilon 0.5169999999999996 mean q -16.694283\n",
      "Episode:  483 Reward: -200.0 Epsilon 0.5159999999999996 mean q -16.676601\n",
      "Episode:  484 Reward: -200.0 Epsilon 0.5149999999999996 mean q -16.68668\n",
      "Episode:  485 Reward: -200.0 Epsilon 0.5139999999999996 mean q -16.701553\n",
      "Episode:  486 Reward: -200.0 Epsilon 0.5129999999999996 mean q -16.669048\n",
      "Episode:  487 Reward: -200.0 Epsilon 0.5119999999999996 mean q -16.670563\n",
      "Episode:  488 Reward: -200.0 Epsilon 0.5109999999999996 mean q -16.674713\n",
      "Episode:  489 Reward: -200.0 Epsilon 0.5099999999999996 mean q -16.678984\n",
      "Episode:  490 Reward: -200.0 Epsilon 0.5089999999999996 mean q -16.676636\n",
      "Episode:  491 Reward: -200.0 Epsilon 0.5079999999999996 mean q -16.654144\n",
      "Episode:  492 Reward: -200.0 Epsilon 0.5069999999999996 mean q -16.630297\n",
      "Episode:  493 Reward: -200.0 Epsilon 0.5059999999999996 mean q -16.652777\n",
      "Episode:  494 Reward: -200.0 Epsilon 0.5049999999999996 mean q -16.673708\n",
      "Episode:  495 Reward: -200.0 Epsilon 0.5039999999999996 mean q -16.675137\n",
      "Episode:  496 Reward: -200.0 Epsilon 0.5029999999999996 mean q -16.664581\n",
      "Episode:  497 Reward: -200.0 Epsilon 0.5019999999999996 mean q -16.657684\n",
      "Episode:  498 Reward: -200.0 Epsilon 0.5009999999999996 mean q -16.706816\n",
      "Episode:  499 Reward: -200.0 Epsilon 0.49999999999999956 mean q -16.678919\n",
      "Episode:  500 Reward: -200.0 Epsilon 0.49899999999999956 mean q -16.63646\n",
      "Episode:  501 Reward: -200.0 Epsilon 0.49799999999999955 mean q -16.658998\n",
      "Episode:  502 Reward: -200.0 Epsilon 0.49699999999999955 mean q -16.665485\n",
      "Episode:  503 Reward: -200.0 Epsilon 0.49599999999999955 mean q -16.666332\n",
      "Episode:  504 Reward: -200.0 Epsilon 0.49499999999999955 mean q -16.64992\n",
      "Episode:  505 Reward: -200.0 Epsilon 0.49399999999999955 mean q -16.68161\n",
      "Episode:  506 Reward: -200.0 Epsilon 0.49299999999999955 mean q -16.685068\n",
      "Episode:  507 Reward: -200.0 Epsilon 0.49199999999999955 mean q -16.675634\n",
      "Episode:  508 Reward: -200.0 Epsilon 0.49099999999999955 mean q -16.66011\n",
      "Episode:  509 Reward: -200.0 Epsilon 0.48999999999999955 mean q -16.650719\n",
      "Episode:  510 Reward: -200.0 Epsilon 0.48899999999999955 mean q -16.690569\n",
      "Episode:  511 Reward: -200.0 Epsilon 0.48799999999999955 mean q -16.6697\n",
      "Episode:  512 Reward: -200.0 Epsilon 0.48699999999999954 mean q -16.685427\n",
      "Episode:  513 Reward: -200.0 Epsilon 0.48599999999999954 mean q -16.664642\n",
      "Episode:  514 Reward: -200.0 Epsilon 0.48499999999999954 mean q -16.63021\n",
      "Episode:  515 Reward: -200.0 Epsilon 0.48399999999999954 mean q -16.687658\n",
      "Episode:  516 Reward: -200.0 Epsilon 0.48299999999999954 mean q -16.68538\n",
      "Episode:  517 Reward: -200.0 Epsilon 0.48199999999999954 mean q -16.663431\n",
      "Episode:  518 Reward: -200.0 Epsilon 0.48099999999999954 mean q -16.669699\n",
      "Episode:  519 Reward: -200.0 Epsilon 0.47999999999999954 mean q -16.685104\n",
      "Episode:  520 Reward: -200.0 Epsilon 0.47899999999999954 mean q -16.659637\n",
      "Episode:  521 Reward: -200.0 Epsilon 0.47799999999999954 mean q -16.664515\n",
      "Episode:  522 Reward: -200.0 Epsilon 0.47699999999999954 mean q -16.678606\n",
      "Episode:  523 Reward: -200.0 Epsilon 0.47599999999999953 mean q -16.657358\n",
      "Episode:  524 Reward: -200.0 Epsilon 0.47499999999999953 mean q -16.629967\n",
      "Episode:  525 Reward: -200.0 Epsilon 0.47399999999999953 mean q -16.673382\n",
      "Episode:  526 Reward: -200.0 Epsilon 0.47299999999999953 mean q -16.678213\n",
      "Episode:  527 Reward: -200.0 Epsilon 0.47199999999999953 mean q -16.629274\n",
      "Episode:  528 Reward: -200.0 Epsilon 0.47099999999999953 mean q -16.662918\n",
      "Episode:  529 Reward: -200.0 Epsilon 0.46999999999999953 mean q -16.677174\n",
      "Episode:  530 Reward: -200.0 Epsilon 0.46899999999999953 mean q -16.628077\n",
      "Episode:  531 Reward: -200.0 Epsilon 0.4679999999999995 mean q -16.646526\n",
      "Episode:  532 Reward: -200.0 Epsilon 0.4669999999999995 mean q -16.64338\n",
      "Episode:  533 Reward: -200.0 Epsilon 0.4659999999999995 mean q -16.670849\n",
      "Episode:  534 Reward: -200.0 Epsilon 0.4649999999999995 mean q -16.698837\n",
      "Episode:  535 Reward: -200.0 Epsilon 0.4639999999999995 mean q -16.632158\n",
      "Episode:  536 Reward: -200.0 Epsilon 0.4629999999999995 mean q -16.626146\n",
      "Episode:  537 Reward: -200.0 Epsilon 0.4619999999999995 mean q -16.67709\n",
      "Episode:  538 Reward: -200.0 Epsilon 0.4609999999999995 mean q -16.673487\n",
      "Episode:  539 Reward: -200.0 Epsilon 0.4599999999999995 mean q -16.702787\n",
      "Episode:  540 Reward: -200.0 Epsilon 0.4589999999999995 mean q -16.68135\n",
      "Episode:  541 Reward: -200.0 Epsilon 0.4579999999999995 mean q -16.656721\n",
      "Episode:  542 Reward: -200.0 Epsilon 0.4569999999999995 mean q -16.659441\n",
      "Episode:  543 Reward: -200.0 Epsilon 0.4559999999999995 mean q -16.707855\n",
      "Episode:  544 Reward: -200.0 Epsilon 0.4549999999999995 mean q -16.650408\n",
      "Episode:  545 Reward: -200.0 Epsilon 0.4539999999999995 mean q -16.633465\n",
      "Episode:  546 Reward: -200.0 Epsilon 0.4529999999999995 mean q -16.668911\n",
      "Episode:  547 Reward: -200.0 Epsilon 0.4519999999999995 mean q -16.649908\n",
      "Episode:  548 Reward: -200.0 Epsilon 0.4509999999999995 mean q -16.686995\n",
      "Episode:  549 Reward: -200.0 Epsilon 0.4499999999999995 mean q -16.679121\n",
      "Episode:  550 Reward: -200.0 Epsilon 0.4489999999999995 mean q -16.652695\n",
      "Episode:  551 Reward: -200.0 Epsilon 0.4479999999999995 mean q -16.658508\n",
      "Episode:  552 Reward: -200.0 Epsilon 0.4469999999999995 mean q -16.663725\n",
      "Episode:  553 Reward: -200.0 Epsilon 0.4459999999999995 mean q -16.670977\n",
      "Episode:  554 Reward: -200.0 Epsilon 0.4449999999999995 mean q -16.653366\n",
      "Episode:  555 Reward: -200.0 Epsilon 0.4439999999999995 mean q -16.686306\n",
      "Episode:  556 Reward: -200.0 Epsilon 0.4429999999999995 mean q -16.657434\n",
      "Episode:  557 Reward: -200.0 Epsilon 0.4419999999999995 mean q -16.656235\n",
      "Episode:  558 Reward: -200.0 Epsilon 0.4409999999999995 mean q -16.616316\n",
      "Episode:  559 Reward: -200.0 Epsilon 0.4399999999999995 mean q -16.666777\n",
      "Episode:  560 Reward: -200.0 Epsilon 0.4389999999999995 mean q -16.657043\n",
      "Episode:  561 Reward: -200.0 Epsilon 0.4379999999999995 mean q -16.660147\n",
      "Episode:  562 Reward: -200.0 Epsilon 0.4369999999999995 mean q -16.670378\n",
      "Episode:  563 Reward: -200.0 Epsilon 0.4359999999999995 mean q -16.62718\n",
      "Episode:  564 Reward: -200.0 Epsilon 0.4349999999999995 mean q -16.678244\n",
      "Episode:  565 Reward: -200.0 Epsilon 0.4339999999999995 mean q -16.660006\n",
      "Episode:  566 Reward: -200.0 Epsilon 0.4329999999999995 mean q -16.64909\n",
      "Episode:  567 Reward: -200.0 Epsilon 0.4319999999999995 mean q -16.693909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  568 Reward: -200.0 Epsilon 0.4309999999999995 mean q -16.672401\n",
      "Episode:  569 Reward: -200.0 Epsilon 0.4299999999999995 mean q -16.646664\n",
      "Episode:  570 Reward: -200.0 Epsilon 0.4289999999999995 mean q -16.674133\n",
      "Episode:  571 Reward: -200.0 Epsilon 0.4279999999999995 mean q -16.688726\n",
      "Episode:  572 Reward: -200.0 Epsilon 0.4269999999999995 mean q -16.664976\n",
      "Episode:  573 Reward: -200.0 Epsilon 0.4259999999999995 mean q -16.682566\n",
      "Episode:  574 Reward: -200.0 Epsilon 0.4249999999999995 mean q -16.63805\n",
      "Episode:  575 Reward: -200.0 Epsilon 0.4239999999999995 mean q -16.678408\n",
      "Episode:  576 Reward: -200.0 Epsilon 0.4229999999999995 mean q -16.651585\n",
      "Episode:  577 Reward: -200.0 Epsilon 0.4219999999999995 mean q -16.665369\n",
      "Episode:  578 Reward: -200.0 Epsilon 0.4209999999999995 mean q -16.69641\n",
      "Episode:  579 Reward: -200.0 Epsilon 0.4199999999999995 mean q -16.66877\n",
      "Episode:  580 Reward: -200.0 Epsilon 0.4189999999999995 mean q -16.699135\n",
      "Episode:  581 Reward: -200.0 Epsilon 0.4179999999999995 mean q -16.663403\n",
      "Episode:  582 Reward: -200.0 Epsilon 0.4169999999999995 mean q -16.654142\n",
      "Episode:  583 Reward: -200.0 Epsilon 0.4159999999999995 mean q -16.663101\n",
      "Episode:  584 Reward: -200.0 Epsilon 0.4149999999999995 mean q -16.648075\n",
      "Episode:  585 Reward: -200.0 Epsilon 0.4139999999999995 mean q -16.66907\n",
      "Episode:  586 Reward: -200.0 Epsilon 0.4129999999999995 mean q -16.658533\n",
      "Episode:  587 Reward: -200.0 Epsilon 0.4119999999999995 mean q -16.664938\n",
      "Episode:  588 Reward: -200.0 Epsilon 0.4109999999999995 mean q -16.65051\n",
      "Episode:  589 Reward: -200.0 Epsilon 0.4099999999999995 mean q -16.651432\n",
      "Episode:  590 Reward: -200.0 Epsilon 0.4089999999999995 mean q -16.690832\n",
      "Episode:  591 Reward: -200.0 Epsilon 0.4079999999999995 mean q -16.662813\n",
      "Episode:  592 Reward: -200.0 Epsilon 0.4069999999999995 mean q -16.695602\n",
      "Episode:  593 Reward: -200.0 Epsilon 0.4059999999999995 mean q -16.685795\n",
      "Episode:  594 Reward: -200.0 Epsilon 0.40499999999999947 mean q -16.697233\n",
      "Episode:  595 Reward: -200.0 Epsilon 0.40399999999999947 mean q -16.66654\n",
      "Episode:  596 Reward: -200.0 Epsilon 0.40299999999999947 mean q -16.66784\n",
      "Episode:  597 Reward: -200.0 Epsilon 0.40199999999999947 mean q -16.656715\n",
      "Episode:  598 Reward: -200.0 Epsilon 0.40099999999999947 mean q -16.700022\n",
      "Episode:  599 Reward: -200.0 Epsilon 0.39999999999999947 mean q -16.682962\n",
      "Episode:  600 Reward: -200.0 Epsilon 0.39899999999999947 mean q -16.674994\n",
      "Episode:  601 Reward: -200.0 Epsilon 0.39799999999999947 mean q -16.67026\n",
      "Episode:  602 Reward: -200.0 Epsilon 0.39699999999999946 mean q -16.663338\n",
      "Episode:  603 Reward: -200.0 Epsilon 0.39599999999999946 mean q -16.628662\n",
      "Episode:  604 Reward: -200.0 Epsilon 0.39499999999999946 mean q -16.640831\n",
      "Episode:  605 Reward: -200.0 Epsilon 0.39399999999999946 mean q -16.638504\n",
      "Episode:  606 Reward: -200.0 Epsilon 0.39299999999999946 mean q -16.68087\n",
      "Episode:  607 Reward: -200.0 Epsilon 0.39199999999999946 mean q -16.643194\n",
      "Episode:  608 Reward: -200.0 Epsilon 0.39099999999999946 mean q -16.637182\n",
      "Episode:  609 Reward: -200.0 Epsilon 0.38999999999999946 mean q -16.636513\n",
      "Episode:  610 Reward: -200.0 Epsilon 0.38899999999999946 mean q -16.66792\n",
      "Episode:  611 Reward: -200.0 Epsilon 0.38799999999999946 mean q -16.639746\n",
      "Episode:  612 Reward: -200.0 Epsilon 0.38699999999999946 mean q -16.616169\n",
      "Episode:  613 Reward: -200.0 Epsilon 0.38599999999999945 mean q -16.709085\n",
      "Episode:  614 Reward: -200.0 Epsilon 0.38499999999999945 mean q -16.627447\n",
      "Episode:  615 Reward: -200.0 Epsilon 0.38399999999999945 mean q -16.663746\n",
      "Episode:  616 Reward: -200.0 Epsilon 0.38299999999999945 mean q -16.675434\n",
      "Episode:  617 Reward: -200.0 Epsilon 0.38199999999999945 mean q -16.672949\n",
      "Episode:  618 Reward: -200.0 Epsilon 0.38099999999999945 mean q -16.669176\n",
      "Episode:  619 Reward: -200.0 Epsilon 0.37999999999999945 mean q -16.656532\n",
      "Episode:  620 Reward: -200.0 Epsilon 0.37899999999999945 mean q -16.67121\n",
      "Episode:  621 Reward: -200.0 Epsilon 0.37799999999999945 mean q -16.620356\n",
      "Episode:  622 Reward: -200.0 Epsilon 0.37699999999999945 mean q -16.662327\n",
      "Episode:  623 Reward: -200.0 Epsilon 0.37599999999999945 mean q -16.683916\n",
      "Episode:  624 Reward: -200.0 Epsilon 0.37499999999999944 mean q -16.682516\n",
      "Episode:  625 Reward: -200.0 Epsilon 0.37399999999999944 mean q -16.645733\n",
      "Episode:  626 Reward: -200.0 Epsilon 0.37299999999999944 mean q -16.681639\n",
      "Episode:  627 Reward: -200.0 Epsilon 0.37199999999999944 mean q -16.682068\n",
      "Episode:  628 Reward: -200.0 Epsilon 0.37099999999999944 mean q -16.699688\n",
      "Episode:  629 Reward: -200.0 Epsilon 0.36999999999999944 mean q -16.676086\n",
      "Episode:  630 Reward: -200.0 Epsilon 0.36899999999999944 mean q -16.648891\n",
      "Episode:  631 Reward: -200.0 Epsilon 0.36799999999999944 mean q -16.66293\n",
      "Episode:  632 Reward: -200.0 Epsilon 0.36699999999999944 mean q -16.680183\n",
      "Episode:  633 Reward: -200.0 Epsilon 0.36599999999999944 mean q -16.641064\n",
      "Episode:  634 Reward: -200.0 Epsilon 0.36499999999999944 mean q -16.675037\n",
      "Episode:  635 Reward: -200.0 Epsilon 0.36399999999999944 mean q -16.67062\n",
      "Episode:  636 Reward: -200.0 Epsilon 0.36299999999999943 mean q -16.687057\n",
      "Episode:  637 Reward: -200.0 Epsilon 0.36199999999999943 mean q -16.66859\n",
      "Episode:  638 Reward: -200.0 Epsilon 0.36099999999999943 mean q -16.643852\n",
      "Episode:  639 Reward: -200.0 Epsilon 0.35999999999999943 mean q -16.653294\n",
      "Episode:  640 Reward: -200.0 Epsilon 0.35899999999999943 mean q -16.642113\n",
      "Episode:  641 Reward: -200.0 Epsilon 0.35799999999999943 mean q -16.652884\n",
      "Episode:  642 Reward: -200.0 Epsilon 0.35699999999999943 mean q -16.661879\n",
      "Episode:  643 Reward: -200.0 Epsilon 0.35599999999999943 mean q -16.676386\n",
      "Episode:  644 Reward: -200.0 Epsilon 0.3549999999999994 mean q -16.65338\n",
      "Episode:  645 Reward: -200.0 Epsilon 0.3539999999999994 mean q -16.645628\n",
      "Episode:  646 Reward: -200.0 Epsilon 0.3529999999999994 mean q -16.676888\n",
      "Episode:  647 Reward: -200.0 Epsilon 0.3519999999999994 mean q -16.628597\n",
      "Episode:  648 Reward: -200.0 Epsilon 0.3509999999999994 mean q -16.684132\n",
      "Episode:  649 Reward: -200.0 Epsilon 0.3499999999999994 mean q -16.675606\n",
      "Episode:  650 Reward: -200.0 Epsilon 0.3489999999999994 mean q -16.688128\n",
      "Episode:  651 Reward: -200.0 Epsilon 0.3479999999999994 mean q -16.660694\n",
      "Episode:  652 Reward: -200.0 Epsilon 0.3469999999999994 mean q -16.672321\n",
      "Episode:  653 Reward: -200.0 Epsilon 0.3459999999999994 mean q -16.657972\n",
      "Episode:  654 Reward: -200.0 Epsilon 0.3449999999999994 mean q -16.67379\n",
      "Episode:  655 Reward: -200.0 Epsilon 0.3439999999999994 mean q -16.659061\n",
      "Episode:  656 Reward: -200.0 Epsilon 0.3429999999999994 mean q -16.670115\n",
      "Episode:  657 Reward: -200.0 Epsilon 0.3419999999999994 mean q -16.656157\n",
      "Episode:  658 Reward: -200.0 Epsilon 0.3409999999999994 mean q -16.670849\n",
      "Episode:  659 Reward: -200.0 Epsilon 0.3399999999999994 mean q -16.698708\n",
      "Episode:  660 Reward: -200.0 Epsilon 0.3389999999999994 mean q -16.644356\n",
      "Episode:  661 Reward: -200.0 Epsilon 0.3379999999999994 mean q -16.60908\n",
      "Episode:  662 Reward: -200.0 Epsilon 0.3369999999999994 mean q -16.656687\n",
      "Episode:  663 Reward: -200.0 Epsilon 0.3359999999999994 mean q -16.679707\n",
      "Episode:  664 Reward: -200.0 Epsilon 0.3349999999999994 mean q -16.650051\n",
      "Episode:  665 Reward: -200.0 Epsilon 0.3339999999999994 mean q -16.669416\n",
      "Episode:  666 Reward: -200.0 Epsilon 0.3329999999999994 mean q -16.684574\n",
      "Episode:  667 Reward: -200.0 Epsilon 0.3319999999999994 mean q -16.670517\n",
      "Episode:  668 Reward: -200.0 Epsilon 0.3309999999999994 mean q -16.663054\n",
      "Episode:  669 Reward: -200.0 Epsilon 0.3299999999999994 mean q -16.658165\n",
      "Episode:  670 Reward: -200.0 Epsilon 0.3289999999999994 mean q -16.654503\n",
      "Episode:  671 Reward: -200.0 Epsilon 0.3279999999999994 mean q -16.655827\n",
      "Episode:  672 Reward: -200.0 Epsilon 0.3269999999999994 mean q -16.686085\n",
      "Episode:  673 Reward: -200.0 Epsilon 0.3259999999999994 mean q -16.658188\n",
      "Episode:  674 Reward: -200.0 Epsilon 0.3249999999999994 mean q -16.704784\n",
      "Episode:  675 Reward: -200.0 Epsilon 0.3239999999999994 mean q -16.65937\n",
      "Episode:  676 Reward: -200.0 Epsilon 0.3229999999999994 mean q -16.661465\n",
      "Episode:  677 Reward: -200.0 Epsilon 0.3219999999999994 mean q -16.64534\n",
      "Episode:  678 Reward: -200.0 Epsilon 0.3209999999999994 mean q -16.651537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  679 Reward: -200.0 Epsilon 0.3199999999999994 mean q -16.633955\n",
      "Episode:  680 Reward: -200.0 Epsilon 0.3189999999999994 mean q -16.638689\n",
      "Episode:  681 Reward: -200.0 Epsilon 0.3179999999999994 mean q -16.656366\n",
      "Episode:  682 Reward: -200.0 Epsilon 0.3169999999999994 mean q -16.678106\n",
      "Episode:  683 Reward: -200.0 Epsilon 0.3159999999999994 mean q -16.653868\n",
      "Episode:  684 Reward: -200.0 Epsilon 0.3149999999999994 mean q -16.710424\n",
      "Episode:  685 Reward: -200.0 Epsilon 0.3139999999999994 mean q -16.671515\n",
      "Episode:  686 Reward: -200.0 Epsilon 0.3129999999999994 mean q -16.663025\n",
      "Episode:  687 Reward: -200.0 Epsilon 0.3119999999999994 mean q -16.674532\n",
      "Episode:  688 Reward: -200.0 Epsilon 0.3109999999999994 mean q -16.66431\n",
      "Episode:  689 Reward: -200.0 Epsilon 0.3099999999999994 mean q -16.656342\n",
      "Episode:  690 Reward: -200.0 Epsilon 0.3089999999999994 mean q -16.651016\n",
      "Episode:  691 Reward: -200.0 Epsilon 0.3079999999999994 mean q -16.650963\n",
      "Episode:  692 Reward: -200.0 Epsilon 0.3069999999999994 mean q -16.65458\n",
      "Episode:  693 Reward: -200.0 Epsilon 0.3059999999999994 mean q -16.69991\n",
      "Episode:  694 Reward: -200.0 Epsilon 0.3049999999999994 mean q -16.655102\n",
      "Episode:  695 Reward: -200.0 Epsilon 0.3039999999999994 mean q -16.65826\n",
      "Episode:  696 Reward: -200.0 Epsilon 0.3029999999999994 mean q -16.657774\n",
      "Episode:  697 Reward: -200.0 Epsilon 0.3019999999999994 mean q -16.662193\n",
      "Episode:  698 Reward: -200.0 Epsilon 0.3009999999999994 mean q -16.667397\n",
      "Episode:  699 Reward: -200.0 Epsilon 0.2999999999999994 mean q -16.634838\n",
      "Episode:  700 Reward: -200.0 Epsilon 0.2989999999999994 mean q -16.662918\n",
      "Episode:  701 Reward: -200.0 Epsilon 0.2979999999999994 mean q -16.67429\n",
      "Episode:  702 Reward: -200.0 Epsilon 0.2969999999999994 mean q -16.694828\n",
      "Episode:  703 Reward: -200.0 Epsilon 0.2959999999999994 mean q -16.684792\n",
      "Episode:  704 Reward: -200.0 Epsilon 0.2949999999999994 mean q -16.65742\n",
      "Episode:  705 Reward: -200.0 Epsilon 0.2939999999999994 mean q -16.677717\n",
      "Episode:  706 Reward: -200.0 Epsilon 0.29299999999999937 mean q -16.662994\n",
      "Episode:  707 Reward: -200.0 Epsilon 0.29199999999999937 mean q -16.679365\n",
      "Episode:  708 Reward: -200.0 Epsilon 0.29099999999999937 mean q -16.714626\n",
      "Episode:  709 Reward: -200.0 Epsilon 0.28999999999999937 mean q -16.625456\n",
      "Episode:  710 Reward: -200.0 Epsilon 0.28899999999999937 mean q -16.657866\n",
      "Episode:  711 Reward: -200.0 Epsilon 0.28799999999999937 mean q -16.667784\n",
      "Episode:  712 Reward: -200.0 Epsilon 0.28699999999999937 mean q -16.684847\n",
      "Episode:  713 Reward: -200.0 Epsilon 0.28599999999999937 mean q -16.678917\n",
      "Episode:  714 Reward: -200.0 Epsilon 0.28499999999999936 mean q -16.702654\n",
      "Episode:  715 Reward: -200.0 Epsilon 0.28399999999999936 mean q -16.713097\n",
      "Episode:  716 Reward: -200.0 Epsilon 0.28299999999999936 mean q -16.68325\n",
      "Episode:  717 Reward: -200.0 Epsilon 0.28199999999999936 mean q -16.621275\n",
      "Episode:  718 Reward: -200.0 Epsilon 0.28099999999999936 mean q -16.643782\n",
      "Episode:  719 Reward: -200.0 Epsilon 0.27999999999999936 mean q -16.661724\n",
      "Episode:  720 Reward: -200.0 Epsilon 0.27899999999999936 mean q -16.635468\n",
      "Episode:  721 Reward: -200.0 Epsilon 0.27799999999999936 mean q -16.684124\n",
      "Episode:  722 Reward: -200.0 Epsilon 0.27699999999999936 mean q -16.651495\n",
      "Episode:  723 Reward: -200.0 Epsilon 0.27599999999999936 mean q -16.644945\n",
      "Episode:  724 Reward: -200.0 Epsilon 0.27499999999999936 mean q -16.670801\n",
      "Episode:  725 Reward: -200.0 Epsilon 0.27399999999999936 mean q -16.660034\n",
      "Episode:  726 Reward: -200.0 Epsilon 0.27299999999999935 mean q -16.620611\n",
      "Episode:  727 Reward: -200.0 Epsilon 0.27199999999999935 mean q -16.657969\n",
      "Episode:  728 Reward: -200.0 Epsilon 0.27099999999999935 mean q -16.674448\n",
      "Episode:  729 Reward: -200.0 Epsilon 0.26999999999999935 mean q -16.680157\n",
      "Episode:  730 Reward: -200.0 Epsilon 0.26899999999999935 mean q -16.67476\n",
      "Episode:  731 Reward: -200.0 Epsilon 0.26799999999999935 mean q -16.634493\n",
      "Episode:  732 Reward: -200.0 Epsilon 0.26699999999999935 mean q -16.631197\n",
      "Episode:  733 Reward: -200.0 Epsilon 0.26599999999999935 mean q -16.698902\n",
      "Episode:  734 Reward: -200.0 Epsilon 0.26499999999999935 mean q -16.702646\n",
      "Episode:  735 Reward: -200.0 Epsilon 0.26399999999999935 mean q -16.641607\n",
      "Episode:  736 Reward: -200.0 Epsilon 0.26299999999999935 mean q -16.655294\n",
      "Episode:  737 Reward: -200.0 Epsilon 0.26199999999999934 mean q -16.697277\n",
      "Episode:  738 Reward: -200.0 Epsilon 0.26099999999999934 mean q -16.677126\n",
      "Episode:  739 Reward: -200.0 Epsilon 0.25999999999999934 mean q -16.682335\n",
      "Episode:  740 Reward: -200.0 Epsilon 0.25899999999999934 mean q -16.676775\n",
      "Episode:  741 Reward: -200.0 Epsilon 0.25799999999999934 mean q -16.660398\n",
      "Episode:  742 Reward: -200.0 Epsilon 0.25699999999999934 mean q -16.648743\n",
      "Episode:  743 Reward: -200.0 Epsilon 0.25599999999999934 mean q -16.66738\n",
      "Episode:  744 Reward: -200.0 Epsilon 0.25499999999999934 mean q -16.67558\n",
      "Episode:  745 Reward: -200.0 Epsilon 0.25399999999999934 mean q -16.652855\n",
      "Episode:  746 Reward: -200.0 Epsilon 0.25299999999999934 mean q -16.645342\n",
      "Episode:  747 Reward: -200.0 Epsilon 0.25199999999999934 mean q -16.682598\n",
      "Episode:  748 Reward: -200.0 Epsilon 0.25099999999999933 mean q -16.66318\n",
      "Episode:  749 Reward: -200.0 Epsilon 0.24999999999999933 mean q -16.697252\n",
      "Episode:  750 Reward: -200.0 Epsilon 0.24899999999999933 mean q -16.65863\n",
      "Episode:  751 Reward: -200.0 Epsilon 0.24799999999999933 mean q -16.647966\n",
      "Episode:  752 Reward: -200.0 Epsilon 0.24699999999999933 mean q -16.643473\n",
      "Episode:  753 Reward: -200.0 Epsilon 0.24599999999999933 mean q -16.673994\n",
      "Episode:  754 Reward: -200.0 Epsilon 0.24499999999999933 mean q -16.663675\n",
      "Episode:  755 Reward: -200.0 Epsilon 0.24399999999999933 mean q -16.658957\n",
      "Episode:  756 Reward: -200.0 Epsilon 0.24299999999999933 mean q -16.642406\n",
      "Episode:  757 Reward: -200.0 Epsilon 0.24199999999999933 mean q -16.695768\n",
      "Episode:  758 Reward: -200.0 Epsilon 0.24099999999999933 mean q -16.689758\n",
      "Episode:  759 Reward: -200.0 Epsilon 0.23999999999999932 mean q -16.692888\n",
      "Episode:  760 Reward: -200.0 Epsilon 0.23899999999999932 mean q -16.667376\n",
      "Episode:  761 Reward: -200.0 Epsilon 0.23799999999999932 mean q -16.642412\n",
      "Episode:  762 Reward: -200.0 Epsilon 0.23699999999999932 mean q -16.690094\n",
      "Episode:  763 Reward: -200.0 Epsilon 0.23599999999999932 mean q -16.666029\n",
      "Episode:  764 Reward: -200.0 Epsilon 0.23499999999999932 mean q -16.655752\n",
      "Episode:  765 Reward: -200.0 Epsilon 0.23399999999999932 mean q -16.657034\n",
      "Episode:  766 Reward: -200.0 Epsilon 0.23299999999999932 mean q -16.650076\n",
      "Episode:  767 Reward: -200.0 Epsilon 0.23199999999999932 mean q -16.676985\n",
      "Episode:  768 Reward: -200.0 Epsilon 0.23099999999999932 mean q -16.649904\n",
      "Episode:  769 Reward: -200.0 Epsilon 0.22999999999999932 mean q -16.674606\n",
      "Episode:  770 Reward: -200.0 Epsilon 0.22899999999999932 mean q -16.656223\n",
      "Episode:  771 Reward: -200.0 Epsilon 0.22799999999999931 mean q -16.679296\n",
      "Episode:  772 Reward: -200.0 Epsilon 0.2269999999999993 mean q -16.664478\n",
      "Episode:  773 Reward: -200.0 Epsilon 0.2259999999999993 mean q -16.624018\n",
      "Episode:  774 Reward: -200.0 Epsilon 0.2249999999999993 mean q -16.659515\n",
      "Episode:  775 Reward: -200.0 Epsilon 0.2239999999999993 mean q -16.643164\n",
      "Episode:  776 Reward: -200.0 Epsilon 0.2229999999999993 mean q -16.658419\n",
      "Episode:  777 Reward: -200.0 Epsilon 0.2219999999999993 mean q -16.656693\n",
      "Episode:  778 Reward: -200.0 Epsilon 0.2209999999999993 mean q -16.660414\n",
      "Episode:  779 Reward: -200.0 Epsilon 0.2199999999999993 mean q -16.6724\n",
      "Episode:  780 Reward: -200.0 Epsilon 0.2189999999999993 mean q -16.6638\n",
      "Episode:  781 Reward: -200.0 Epsilon 0.2179999999999993 mean q -16.667181\n",
      "Episode:  782 Reward: -200.0 Epsilon 0.2169999999999993 mean q -16.66742\n",
      "Episode:  783 Reward: -200.0 Epsilon 0.2159999999999993 mean q -16.636337\n",
      "Episode:  784 Reward: -200.0 Epsilon 0.2149999999999993 mean q -16.68749\n",
      "Episode:  785 Reward: -200.0 Epsilon 0.2139999999999993 mean q -16.676249\n",
      "Episode:  786 Reward: -200.0 Epsilon 0.2129999999999993 mean q -16.669296\n",
      "Episode:  787 Reward: -200.0 Epsilon 0.2119999999999993 mean q -16.660961\n",
      "Episode:  788 Reward: -200.0 Epsilon 0.2109999999999993 mean q -16.656725\n",
      "Episode:  789 Reward: -200.0 Epsilon 0.2099999999999993 mean q -16.648521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  790 Reward: -200.0 Epsilon 0.2089999999999993 mean q -16.658506\n",
      "Episode:  791 Reward: -200.0 Epsilon 0.2079999999999993 mean q -16.66853\n",
      "Episode:  792 Reward: -200.0 Epsilon 0.2069999999999993 mean q -16.670494\n",
      "Episode:  793 Reward: -200.0 Epsilon 0.2059999999999993 mean q -16.68879\n",
      "Episode:  794 Reward: -200.0 Epsilon 0.2049999999999993 mean q -16.665068\n",
      "Episode:  795 Reward: -200.0 Epsilon 0.2039999999999993 mean q -16.683414\n",
      "Episode:  796 Reward: -200.0 Epsilon 0.2029999999999993 mean q -16.666634\n",
      "Episode:  797 Reward: -200.0 Epsilon 0.2019999999999993 mean q -16.71453\n",
      "Episode:  798 Reward: -200.0 Epsilon 0.2009999999999993 mean q -16.65254\n",
      "Episode:  799 Reward: -200.0 Epsilon 0.1999999999999993 mean q -16.663155\n",
      "Episode:  800 Reward: -200.0 Epsilon 0.1989999999999993 mean q -16.682528\n",
      "Episode:  801 Reward: -200.0 Epsilon 0.1979999999999993 mean q -16.693089\n",
      "Episode:  802 Reward: -200.0 Epsilon 0.1969999999999993 mean q -16.642973\n",
      "Episode:  803 Reward: -200.0 Epsilon 0.19599999999999929 mean q -16.679422\n",
      "Episode:  804 Reward: -200.0 Epsilon 0.19499999999999929 mean q -16.677961\n",
      "Episode:  805 Reward: -200.0 Epsilon 0.19399999999999928 mean q -16.673967\n",
      "Episode:  806 Reward: -200.0 Epsilon 0.19299999999999928 mean q -16.637468\n",
      "Episode:  807 Reward: -200.0 Epsilon 0.19199999999999928 mean q -16.638865\n",
      "Episode:  808 Reward: -200.0 Epsilon 0.19099999999999928 mean q -16.655424\n",
      "Episode:  809 Reward: -200.0 Epsilon 0.18999999999999928 mean q -16.670355\n",
      "Episode:  810 Reward: -200.0 Epsilon 0.18899999999999928 mean q -16.643105\n",
      "Episode:  811 Reward: -200.0 Epsilon 0.18799999999999928 mean q -16.648743\n",
      "Episode:  812 Reward: -200.0 Epsilon 0.18699999999999928 mean q -16.62629\n",
      "Episode:  813 Reward: -200.0 Epsilon 0.18599999999999928 mean q -16.647667\n",
      "Episode:  814 Reward: -200.0 Epsilon 0.18499999999999928 mean q -16.690645\n",
      "Episode:  815 Reward: -200.0 Epsilon 0.18399999999999928 mean q -16.65779\n",
      "Episode:  816 Reward: -200.0 Epsilon 0.18299999999999927 mean q -16.637056\n",
      "Episode:  817 Reward: -200.0 Epsilon 0.18199999999999927 mean q -16.66288\n",
      "Episode:  818 Reward: -200.0 Epsilon 0.18099999999999927 mean q -16.666075\n",
      "Episode:  819 Reward: -200.0 Epsilon 0.17999999999999927 mean q -16.673948\n",
      "Episode:  820 Reward: -200.0 Epsilon 0.17899999999999927 mean q -16.622084\n",
      "Episode:  821 Reward: -200.0 Epsilon 0.17799999999999927 mean q -16.685953\n",
      "Episode:  822 Reward: -200.0 Epsilon 0.17699999999999927 mean q -16.655195\n",
      "Episode:  823 Reward: -200.0 Epsilon 0.17599999999999927 mean q -16.678509\n",
      "Episode:  824 Reward: -200.0 Epsilon 0.17499999999999927 mean q -16.708101\n",
      "Episode:  825 Reward: -200.0 Epsilon 0.17399999999999927 mean q -16.675459\n",
      "Episode:  826 Reward: -200.0 Epsilon 0.17299999999999927 mean q -16.666752\n",
      "Episode:  827 Reward: -200.0 Epsilon 0.17199999999999926 mean q -16.67193\n",
      "Episode:  828 Reward: -200.0 Epsilon 0.17099999999999926 mean q -16.691368\n",
      "Episode:  829 Reward: -200.0 Epsilon 0.16999999999999926 mean q -16.683311\n",
      "Episode:  830 Reward: -200.0 Epsilon 0.16899999999999926 mean q -16.648783\n",
      "Episode:  831 Reward: -200.0 Epsilon 0.16799999999999926 mean q -16.648375\n",
      "Episode:  832 Reward: -200.0 Epsilon 0.16699999999999926 mean q -16.686275\n",
      "Episode:  833 Reward: -200.0 Epsilon 0.16599999999999926 mean q -16.685736\n",
      "Episode:  834 Reward: -200.0 Epsilon 0.16499999999999926 mean q -16.665745\n",
      "Episode:  835 Reward: -200.0 Epsilon 0.16399999999999926 mean q -16.677181\n",
      "Episode:  836 Reward: -200.0 Epsilon 0.16299999999999926 mean q -16.706217\n",
      "Episode:  837 Reward: -200.0 Epsilon 0.16199999999999926 mean q -16.666431\n",
      "Episode:  838 Reward: -200.0 Epsilon 0.16099999999999925 mean q -16.66677\n",
      "Episode:  839 Reward: -200.0 Epsilon 0.15999999999999925 mean q -16.651058\n",
      "Episode:  840 Reward: -200.0 Epsilon 0.15899999999999925 mean q -16.645634\n",
      "Episode:  841 Reward: -200.0 Epsilon 0.15799999999999925 mean q -16.656523\n",
      "Episode:  842 Reward: -200.0 Epsilon 0.15699999999999925 mean q -16.6332\n",
      "Episode:  843 Reward: -200.0 Epsilon 0.15599999999999925 mean q -16.646637\n",
      "Episode:  844 Reward: -200.0 Epsilon 0.15499999999999925 mean q -16.659925\n",
      "Episode:  845 Reward: -200.0 Epsilon 0.15399999999999925 mean q -16.656818\n",
      "Episode:  846 Reward: -200.0 Epsilon 0.15299999999999925 mean q -16.655745\n",
      "Episode:  847 Reward: -200.0 Epsilon 0.15199999999999925 mean q -16.649818\n",
      "Episode:  848 Reward: -200.0 Epsilon 0.15099999999999925 mean q -16.687147\n",
      "Episode:  849 Reward: -200.0 Epsilon 0.14999999999999925 mean q -16.628515\n",
      "Episode:  850 Reward: -200.0 Epsilon 0.14899999999999924 mean q -16.648912\n",
      "Episode:  851 Reward: -200.0 Epsilon 0.14799999999999924 mean q -16.680397\n",
      "Episode:  852 Reward: -200.0 Epsilon 0.14699999999999924 mean q -16.679544\n",
      "Episode:  853 Reward: -200.0 Epsilon 0.14599999999999924 mean q -16.663675\n",
      "Episode:  854 Reward: -200.0 Epsilon 0.14499999999999924 mean q -16.615868\n",
      "Episode:  855 Reward: -200.0 Epsilon 0.14399999999999924 mean q -16.64642\n",
      "Episode:  856 Reward: -200.0 Epsilon 0.14299999999999924 mean q -16.640896\n",
      "Episode:  857 Reward: -200.0 Epsilon 0.14199999999999924 mean q -16.634605\n",
      "Episode:  858 Reward: -200.0 Epsilon 0.14099999999999924 mean q -16.678156\n",
      "Episode:  859 Reward: -200.0 Epsilon 0.13999999999999924 mean q -16.67633\n",
      "Episode:  860 Reward: -200.0 Epsilon 0.13899999999999924 mean q -16.648409\n",
      "Episode:  861 Reward: -200.0 Epsilon 0.13799999999999923 mean q -16.652271\n",
      "Episode:  862 Reward: -200.0 Epsilon 0.13699999999999923 mean q -16.642122\n",
      "Episode:  863 Reward: -200.0 Epsilon 0.13599999999999923 mean q -16.685543\n",
      "Episode:  864 Reward: -200.0 Epsilon 0.13499999999999923 mean q -16.691935\n",
      "Episode:  865 Reward: -200.0 Epsilon 0.13399999999999923 mean q -16.645157\n",
      "Episode:  866 Reward: -200.0 Epsilon 0.13299999999999923 mean q -16.684645\n",
      "Episode:  867 Reward: -200.0 Epsilon 0.13199999999999923 mean q -16.70363\n",
      "Episode:  868 Reward: -200.0 Epsilon 0.13099999999999923 mean q -16.681484\n",
      "Episode:  869 Reward: -200.0 Epsilon 0.12999999999999923 mean q -16.69097\n",
      "Episode:  870 Reward: -200.0 Epsilon 0.12899999999999923 mean q -16.646646\n",
      "Episode:  871 Reward: -200.0 Epsilon 0.12799999999999923 mean q -16.655386\n",
      "Episode:  872 Reward: -200.0 Epsilon 0.12699999999999922 mean q -16.639854\n",
      "Episode:  873 Reward: -200.0 Epsilon 0.12599999999999922 mean q -16.6581\n",
      "Episode:  874 Reward: -200.0 Epsilon 0.12499999999999922 mean q -16.624043\n",
      "Episode:  875 Reward: -200.0 Epsilon 0.12399999999999922 mean q -16.648766\n",
      "Episode:  876 Reward: -200.0 Epsilon 0.12299999999999922 mean q -16.690601\n",
      "Episode:  877 Reward: -200.0 Epsilon 0.12199999999999922 mean q -16.655645\n",
      "Episode:  878 Reward: -200.0 Epsilon 0.12099999999999922 mean q -16.70266\n",
      "Episode:  879 Reward: -200.0 Epsilon 0.11999999999999922 mean q -16.659756\n",
      "Episode:  880 Reward: -200.0 Epsilon 0.11899999999999922 mean q -16.66676\n",
      "Episode:  881 Reward: -200.0 Epsilon 0.11799999999999922 mean q -16.648668\n",
      "Episode:  882 Reward: -200.0 Epsilon 0.11699999999999922 mean q -16.667175\n",
      "Episode:  883 Reward: -200.0 Epsilon 0.11599999999999921 mean q -16.690506\n",
      "Episode:  884 Reward: -200.0 Epsilon 0.11499999999999921 mean q -16.67743\n",
      "Episode:  885 Reward: -200.0 Epsilon 0.11399999999999921 mean q -16.661882\n",
      "Episode:  886 Reward: -200.0 Epsilon 0.11299999999999921 mean q -16.65942\n",
      "Episode:  887 Reward: -200.0 Epsilon 0.11199999999999921 mean q -16.693634\n",
      "Episode:  888 Reward: -200.0 Epsilon 0.11099999999999921 mean q -16.648273\n",
      "Episode:  889 Reward: -200.0 Epsilon 0.10999999999999921 mean q -16.661224\n",
      "Episode:  890 Reward: -200.0 Epsilon 0.10899999999999921 mean q -16.664297\n",
      "Episode:  891 Reward: -200.0 Epsilon 0.10799999999999921 mean q -16.673838\n",
      "Episode:  892 Reward: -200.0 Epsilon 0.1069999999999992 mean q -16.659063\n",
      "Episode:  893 Reward: -200.0 Epsilon 0.1059999999999992 mean q -16.649414\n",
      "Episode:  894 Reward: -200.0 Epsilon 0.1049999999999992 mean q -16.668257\n",
      "Episode:  895 Reward: -200.0 Epsilon 0.1039999999999992 mean q -16.690527\n",
      "Episode:  896 Reward: -200.0 Epsilon 0.1029999999999992 mean q -16.66911\n",
      "Episode:  897 Reward: -200.0 Epsilon 0.1019999999999992 mean q -16.693419\n",
      "Episode:  898 Reward: -200.0 Epsilon 0.1009999999999992 mean q -16.626253\n",
      "Episode:  899 Reward: -200.0 Epsilon 0.1 mean q -16.680052\n",
      "Episode:  900 Reward: -200.0 Epsilon 0.1 mean q -16.663774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  901 Reward: -200.0 Epsilon 0.1 mean q -16.672262\n",
      "Episode:  902 Reward: -200.0 Epsilon 0.1 mean q -16.642836\n",
      "Episode:  903 Reward: -200.0 Epsilon 0.1 mean q -16.68369\n",
      "Episode:  904 Reward: -200.0 Epsilon 0.1 mean q -16.668106\n",
      "Episode:  905 Reward: -200.0 Epsilon 0.1 mean q -16.667757\n",
      "Episode:  906 Reward: -200.0 Epsilon 0.1 mean q -16.695156\n",
      "Episode:  907 Reward: -200.0 Epsilon 0.1 mean q -16.676523\n",
      "Episode:  908 Reward: -200.0 Epsilon 0.1 mean q -16.669493\n",
      "Episode:  909 Reward: -200.0 Epsilon 0.1 mean q -16.684008\n",
      "Episode:  910 Reward: -200.0 Epsilon 0.1 mean q -16.68527\n",
      "Episode:  911 Reward: -200.0 Epsilon 0.1 mean q -16.68759\n",
      "Episode:  912 Reward: -200.0 Epsilon 0.1 mean q -16.679504\n",
      "Episode:  913 Reward: -200.0 Epsilon 0.1 mean q -16.65486\n",
      "Episode:  914 Reward: -200.0 Epsilon 0.1 mean q -16.647799\n",
      "Episode:  915 Reward: -200.0 Epsilon 0.1 mean q -16.618925\n",
      "Episode:  916 Reward: -200.0 Epsilon 0.1 mean q -16.640139\n",
      "Episode:  917 Reward: -200.0 Epsilon 0.1 mean q -16.679491\n",
      "Episode:  918 Reward: -200.0 Epsilon 0.1 mean q -16.658401\n",
      "Episode:  919 Reward: -200.0 Epsilon 0.1 mean q -16.670273\n",
      "Episode:  920 Reward: -200.0 Epsilon 0.1 mean q -16.670185\n",
      "Episode:  921 Reward: -200.0 Epsilon 0.1 mean q -16.648754\n",
      "Episode:  922 Reward: -200.0 Epsilon 0.1 mean q -16.674194\n",
      "Episode:  923 Reward: -200.0 Epsilon 0.1 mean q -16.696793\n",
      "Episode:  924 Reward: -200.0 Epsilon 0.1 mean q -16.655167\n",
      "Episode:  925 Reward: -200.0 Epsilon 0.1 mean q -16.637108\n",
      "Episode:  926 Reward: -200.0 Epsilon 0.1 mean q -16.664793\n",
      "Episode:  927 Reward: -200.0 Epsilon 0.1 mean q -16.673523\n",
      "Episode:  928 Reward: -200.0 Epsilon 0.1 mean q -16.65196\n",
      "Episode:  929 Reward: -200.0 Epsilon 0.1 mean q -16.67205\n",
      "Episode:  930 Reward: -200.0 Epsilon 0.1 mean q -16.620739\n",
      "Episode:  931 Reward: -200.0 Epsilon 0.1 mean q -16.69054\n",
      "Episode:  932 Reward: -200.0 Epsilon 0.1 mean q -16.699024\n",
      "Episode:  933 Reward: -200.0 Epsilon 0.1 mean q -16.637787\n",
      "Episode:  934 Reward: -200.0 Epsilon 0.1 mean q -16.652855\n",
      "Episode:  935 Reward: -200.0 Epsilon 0.1 mean q -16.66038\n",
      "Episode:  936 Reward: -200.0 Epsilon 0.1 mean q -16.687061\n",
      "Episode:  937 Reward: -200.0 Epsilon 0.1 mean q -16.679472\n",
      "Episode:  938 Reward: -200.0 Epsilon 0.1 mean q -16.681608\n",
      "Episode:  939 Reward: -200.0 Epsilon 0.1 mean q -16.670523\n",
      "Episode:  940 Reward: -200.0 Epsilon 0.1 mean q -16.649893\n",
      "Episode:  941 Reward: -200.0 Epsilon 0.1 mean q -16.633307\n",
      "Episode:  942 Reward: -200.0 Epsilon 0.1 mean q -16.6779\n",
      "Episode:  943 Reward: -200.0 Epsilon 0.1 mean q -16.630917\n",
      "Episode:  944 Reward: -200.0 Epsilon 0.1 mean q -16.668299\n",
      "Episode:  945 Reward: -200.0 Epsilon 0.1 mean q -16.700367\n",
      "Episode:  946 Reward: -200.0 Epsilon 0.1 mean q -16.695585\n",
      "Episode:  947 Reward: -200.0 Epsilon 0.1 mean q -16.697857\n",
      "Episode:  948 Reward: -200.0 Epsilon 0.1 mean q -16.636862\n",
      "Episode:  949 Reward: -200.0 Epsilon 0.1 mean q -16.634464\n",
      "Episode:  950 Reward: -200.0 Epsilon 0.1 mean q -16.64169\n",
      "Episode:  951 Reward: -200.0 Epsilon 0.1 mean q -16.665232\n",
      "Episode:  952 Reward: -200.0 Epsilon 0.1 mean q -16.685415\n",
      "Episode:  953 Reward: -200.0 Epsilon 0.1 mean q -16.665966\n",
      "Episode:  954 Reward: -200.0 Epsilon 0.1 mean q -16.644379\n",
      "Episode:  955 Reward: -200.0 Epsilon 0.1 mean q -16.63788\n",
      "Episode:  956 Reward: -200.0 Epsilon 0.1 mean q -16.683971\n",
      "Episode:  957 Reward: -200.0 Epsilon 0.1 mean q -16.688478\n",
      "Episode:  958 Reward: -200.0 Epsilon 0.1 mean q -16.659143\n",
      "Episode:  959 Reward: -200.0 Epsilon 0.1 mean q -16.640831\n",
      "Episode:  960 Reward: -200.0 Epsilon 0.1 mean q -16.655155\n",
      "Episode:  961 Reward: -200.0 Epsilon 0.1 mean q -16.662136\n",
      "Episode:  962 Reward: -200.0 Epsilon 0.1 mean q -16.677319\n",
      "Episode:  963 Reward: -200.0 Epsilon 0.1 mean q -16.659359\n",
      "Episode:  964 Reward: -200.0 Epsilon 0.1 mean q -16.663082\n",
      "Episode:  965 Reward: -200.0 Epsilon 0.1 mean q -16.627699\n",
      "Episode:  966 Reward: -200.0 Epsilon 0.1 mean q -16.65638\n",
      "Episode:  967 Reward: -200.0 Epsilon 0.1 mean q -16.651888\n",
      "Episode:  968 Reward: -200.0 Epsilon 0.1 mean q -16.649635\n",
      "Episode:  969 Reward: -200.0 Epsilon 0.1 mean q -16.63882\n",
      "Episode:  970 Reward: -200.0 Epsilon 0.1 mean q -16.662294\n",
      "Episode:  971 Reward: -200.0 Epsilon 0.1 mean q -16.700348\n",
      "Episode:  972 Reward: -200.0 Epsilon 0.1 mean q -16.65824\n",
      "Episode:  973 Reward: -200.0 Epsilon 0.1 mean q -16.659595\n",
      "Episode:  974 Reward: -200.0 Epsilon 0.1 mean q -16.717041\n",
      "Episode:  975 Reward: -200.0 Epsilon 0.1 mean q -16.692139\n",
      "Episode:  976 Reward: -200.0 Epsilon 0.1 mean q -16.644077\n",
      "Episode:  977 Reward: -200.0 Epsilon 0.1 mean q -16.692345\n",
      "Episode:  978 Reward: -200.0 Epsilon 0.1 mean q -16.662895\n",
      "Episode:  979 Reward: -200.0 Epsilon 0.1 mean q -16.653679\n",
      "Episode:  980 Reward: -200.0 Epsilon 0.1 mean q -16.659748\n",
      "Episode:  981 Reward: -200.0 Epsilon 0.1 mean q -16.668339\n",
      "Episode:  982 Reward: -200.0 Epsilon 0.1 mean q -16.67134\n",
      "Episode:  983 Reward: -200.0 Epsilon 0.1 mean q -16.648558\n",
      "Episode:  984 Reward: -200.0 Epsilon 0.1 mean q -16.663588\n",
      "Episode:  985 Reward: -200.0 Epsilon 0.1 mean q -16.66199\n",
      "Episode:  986 Reward: -200.0 Epsilon 0.1 mean q -16.65071\n",
      "Episode:  987 Reward: -200.0 Epsilon 0.1 mean q -16.686678\n",
      "Episode:  988 Reward: -200.0 Epsilon 0.1 mean q -16.657116\n",
      "Episode:  989 Reward: -200.0 Epsilon 0.1 mean q -16.649221\n",
      "Episode:  990 Reward: -200.0 Epsilon 0.1 mean q -16.62886\n",
      "Episode:  991 Reward: -200.0 Epsilon 0.1 mean q -16.66821\n",
      "Episode:  992 Reward: -200.0 Epsilon 0.1 mean q -16.702568\n",
      "Episode:  993 Reward: -200.0 Epsilon 0.1 mean q -16.668669\n",
      "Episode:  994 Reward: -200.0 Epsilon 0.1 mean q -16.658686\n",
      "Episode:  995 Reward: -200.0 Epsilon 0.1 mean q -16.678448\n",
      "Episode:  996 Reward: -200.0 Epsilon 0.1 mean q -16.688522\n",
      "Episode:  997 Reward: -200.0 Epsilon 0.1 mean q -16.696693\n",
      "Episode:  998 Reward: -200.0 Epsilon 0.1 mean q -16.62663\n",
      "Episode:  999 Reward: -200.0 Epsilon 0.1 mean q -16.67556\n",
      "Episode:  1000 Reward: -200.0 Epsilon 0.1 mean q -16.667343\n",
      "Episode:  1001 Reward: -200.0 Epsilon 0.1 mean q -16.691954\n",
      "Episode:  1002 Reward: -200.0 Epsilon 0.1 mean q -16.653463\n",
      "Episode:  1003 Reward: -200.0 Epsilon 0.1 mean q -16.646046\n",
      "Episode:  1004 Reward: -200.0 Epsilon 0.1 mean q -16.65057\n",
      "Episode:  1005 Reward: -200.0 Epsilon 0.1 mean q -16.672474\n",
      "Episode:  1006 Reward: -200.0 Epsilon 0.1 mean q -16.669447\n",
      "Episode:  1007 Reward: -200.0 Epsilon 0.1 mean q -16.643583\n",
      "Episode:  1008 Reward: -200.0 Epsilon 0.1 mean q -16.666979\n",
      "Episode:  1009 Reward: -200.0 Epsilon 0.1 mean q -16.679304\n",
      "Episode:  1010 Reward: -200.0 Epsilon 0.1 mean q -16.684175\n",
      "Episode:  1011 Reward: -200.0 Epsilon 0.1 mean q -16.631363\n",
      "Episode:  1012 Reward: -200.0 Epsilon 0.1 mean q -16.62607\n",
      "Episode:  1013 Reward: -200.0 Epsilon 0.1 mean q -16.646412\n",
      "Episode:  1014 Reward: -200.0 Epsilon 0.1 mean q -16.678627\n",
      "Episode:  1015 Reward: -200.0 Epsilon 0.1 mean q -16.633549\n",
      "Episode:  1016 Reward: -200.0 Epsilon 0.1 mean q -16.69412\n",
      "Episode:  1017 Reward: -200.0 Epsilon 0.1 mean q -16.679749\n",
      "Episode:  1018 Reward: -200.0 Epsilon 0.1 mean q -16.641983\n",
      "Episode:  1019 Reward: -200.0 Epsilon 0.1 mean q -16.658356\n",
      "Episode:  1020 Reward: -200.0 Epsilon 0.1 mean q -16.660282\n",
      "Episode:  1021 Reward: -200.0 Epsilon 0.1 mean q -16.680887\n",
      "Episode:  1022 Reward: -200.0 Epsilon 0.1 mean q -16.66813\n",
      "Episode:  1023 Reward: -200.0 Epsilon 0.1 mean q -16.659636\n",
      "Episode:  1024 Reward: -200.0 Epsilon 0.1 mean q -16.673414\n",
      "Episode:  1025 Reward: -200.0 Epsilon 0.1 mean q -16.713299\n",
      "Episode:  1026 Reward: -200.0 Epsilon 0.1 mean q -16.665022\n",
      "Episode:  1027 Reward: -200.0 Epsilon 0.1 mean q -16.671015\n",
      "Episode:  1028 Reward: -200.0 Epsilon 0.1 mean q -16.67698\n",
      "Episode:  1029 Reward: -200.0 Epsilon 0.1 mean q -16.67088\n",
      "Episode:  1030 Reward: -200.0 Epsilon 0.1 mean q -16.664797\n",
      "Episode:  1031 Reward: -200.0 Epsilon 0.1 mean q -16.671644\n",
      "Episode:  1032 Reward: -200.0 Epsilon 0.1 mean q -16.683874\n",
      "Episode:  1033 Reward: -200.0 Epsilon 0.1 mean q -16.670708\n",
      "Episode:  1034 Reward: -200.0 Epsilon 0.1 mean q -16.6604\n",
      "Episode:  1035 Reward: -200.0 Epsilon 0.1 mean q -16.688103\n",
      "Episode:  1036 Reward: -200.0 Epsilon 0.1 mean q -16.686686\n",
      "Episode:  1037 Reward: -200.0 Epsilon 0.1 mean q -16.692112\n",
      "Episode:  1038 Reward: -200.0 Epsilon 0.1 mean q -16.658953\n",
      "Episode:  1039 Reward: -200.0 Epsilon 0.1 mean q -16.65183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1040 Reward: -200.0 Epsilon 0.1 mean q -16.668194\n",
      "Episode:  1041 Reward: -200.0 Epsilon 0.1 mean q -16.651852\n",
      "Episode:  1042 Reward: -200.0 Epsilon 0.1 mean q -16.68734\n",
      "Episode:  1043 Reward: -200.0 Epsilon 0.1 mean q -16.630043\n",
      "Episode:  1044 Reward: -200.0 Epsilon 0.1 mean q -16.669245\n",
      "Episode:  1045 Reward: -200.0 Epsilon 0.1 mean q -16.698463\n",
      "Episode:  1046 Reward: -200.0 Epsilon 0.1 mean q -16.69025\n",
      "Episode:  1047 Reward: -200.0 Epsilon 0.1 mean q -16.634737\n",
      "Episode:  1048 Reward: -200.0 Epsilon 0.1 mean q -16.66237\n",
      "Episode:  1049 Reward: -200.0 Epsilon 0.1 mean q -16.671717\n",
      "Episode:  1050 Reward: -200.0 Epsilon 0.1 mean q -16.66006\n",
      "Episode:  1051 Reward: -200.0 Epsilon 0.1 mean q -16.681787\n",
      "Episode:  1052 Reward: -200.0 Epsilon 0.1 mean q -16.656307\n",
      "Episode:  1053 Reward: -200.0 Epsilon 0.1 mean q -16.642246\n",
      "Episode:  1054 Reward: -200.0 Epsilon 0.1 mean q -16.694214\n",
      "Episode:  1055 Reward: -200.0 Epsilon 0.1 mean q -16.6401\n",
      "Episode:  1056 Reward: -200.0 Epsilon 0.1 mean q -16.656483\n",
      "Episode:  1057 Reward: -200.0 Epsilon 0.1 mean q -16.674713\n",
      "Episode:  1058 Reward: -200.0 Epsilon 0.1 mean q -16.67457\n",
      "Episode:  1059 Reward: -200.0 Epsilon 0.1 mean q -16.688828\n",
      "Episode:  1060 Reward: -200.0 Epsilon 0.1 mean q -16.658463\n",
      "Episode:  1061 Reward: -200.0 Epsilon 0.1 mean q -16.676641\n",
      "Episode:  1062 Reward: -200.0 Epsilon 0.1 mean q -16.682423\n",
      "Episode:  1063 Reward: -200.0 Epsilon 0.1 mean q -16.616468\n",
      "Episode:  1064 Reward: -200.0 Epsilon 0.1 mean q -16.656755\n",
      "Episode:  1065 Reward: -200.0 Epsilon 0.1 mean q -16.654095\n",
      "Episode:  1066 Reward: -200.0 Epsilon 0.1 mean q -16.665064\n",
      "Episode:  1067 Reward: -200.0 Epsilon 0.1 mean q -16.658497\n",
      "Episode:  1068 Reward: -200.0 Epsilon 0.1 mean q -16.674252\n",
      "Episode:  1069 Reward: -200.0 Epsilon 0.1 mean q -16.654753\n",
      "Episode:  1070 Reward: -200.0 Epsilon 0.1 mean q -16.683962\n",
      "Episode:  1071 Reward: -200.0 Epsilon 0.1 mean q -16.678457\n",
      "Episode:  1072 Reward: -200.0 Epsilon 0.1 mean q -16.692802\n",
      "Episode:  1073 Reward: -200.0 Epsilon 0.1 mean q -16.666042\n",
      "Episode:  1074 Reward: -200.0 Epsilon 0.1 mean q -16.664845\n",
      "Episode:  1075 Reward: -200.0 Epsilon 0.1 mean q -16.653492\n",
      "Episode:  1076 Reward: -200.0 Epsilon 0.1 mean q -16.68611\n",
      "Episode:  1077 Reward: -200.0 Epsilon 0.1 mean q -16.658617\n",
      "Episode:  1078 Reward: -200.0 Epsilon 0.1 mean q -16.675186\n",
      "Episode:  1079 Reward: -200.0 Epsilon 0.1 mean q -16.676605\n",
      "Episode:  1080 Reward: -200.0 Epsilon 0.1 mean q -16.671038\n",
      "Episode:  1081 Reward: -200.0 Epsilon 0.1 mean q -16.68693\n",
      "Episode:  1082 Reward: -200.0 Epsilon 0.1 mean q -16.655537\n",
      "Episode:  1083 Reward: -200.0 Epsilon 0.1 mean q -16.689964\n",
      "Episode:  1084 Reward: -200.0 Epsilon 0.1 mean q -16.639608\n",
      "Episode:  1085 Reward: -200.0 Epsilon 0.1 mean q -16.682667\n",
      "Episode:  1086 Reward: -200.0 Epsilon 0.1 mean q -16.639875\n",
      "Episode:  1087 Reward: -200.0 Epsilon 0.1 mean q -16.67655\n",
      "Episode:  1088 Reward: -200.0 Epsilon 0.1 mean q -16.64337\n",
      "Episode:  1089 Reward: -200.0 Epsilon 0.1 mean q -16.64648\n",
      "Episode:  1090 Reward: -200.0 Epsilon 0.1 mean q -16.64819\n",
      "Episode:  1091 Reward: -200.0 Epsilon 0.1 mean q -16.650843\n",
      "Episode:  1092 Reward: -200.0 Epsilon 0.1 mean q -16.636417\n",
      "Episode:  1093 Reward: -200.0 Epsilon 0.1 mean q -16.653614\n",
      "Episode:  1094 Reward: -200.0 Epsilon 0.1 mean q -16.706964\n",
      "Episode:  1095 Reward: -200.0 Epsilon 0.1 mean q -16.704845\n",
      "Episode:  1096 Reward: -200.0 Epsilon 0.1 mean q -16.68747\n",
      "Episode:  1097 Reward: -200.0 Epsilon 0.1 mean q -16.67347\n",
      "Episode:  1098 Reward: -200.0 Epsilon 0.1 mean q -16.650894\n",
      "Episode:  1099 Reward: -200.0 Epsilon 0.1 mean q -16.643848\n",
      "Episode:  1100 Reward: -200.0 Epsilon 0.1 mean q -16.622896\n",
      "Episode:  1101 Reward: -200.0 Epsilon 0.1 mean q -16.645706\n",
      "Episode:  1102 Reward: -200.0 Epsilon 0.1 mean q -16.650766\n",
      "Episode:  1103 Reward: -200.0 Epsilon 0.1 mean q -16.677837\n",
      "Episode:  1104 Reward: -200.0 Epsilon 0.1 mean q -16.650055\n",
      "Episode:  1105 Reward: -200.0 Epsilon 0.1 mean q -16.672768\n",
      "Episode:  1106 Reward: -200.0 Epsilon 0.1 mean q -16.682358\n",
      "Episode:  1107 Reward: -200.0 Epsilon 0.1 mean q -16.661669\n",
      "Episode:  1108 Reward: -200.0 Epsilon 0.1 mean q -16.688927\n",
      "Episode:  1109 Reward: -200.0 Epsilon 0.1 mean q -16.670864\n",
      "Episode:  1110 Reward: -200.0 Epsilon 0.1 mean q -16.694084\n",
      "Episode:  1111 Reward: -200.0 Epsilon 0.1 mean q -16.67733\n",
      "Episode:  1112 Reward: -200.0 Epsilon 0.1 mean q -16.668163\n",
      "Episode:  1113 Reward: -200.0 Epsilon 0.1 mean q -16.658709\n",
      "Episode:  1114 Reward: -200.0 Epsilon 0.1 mean q -16.63695\n",
      "Episode:  1115 Reward: -200.0 Epsilon 0.1 mean q -16.688982\n",
      "Episode:  1116 Reward: -200.0 Epsilon 0.1 mean q -16.657467\n",
      "Episode:  1117 Reward: -200.0 Epsilon 0.1 mean q -16.64971\n",
      "Episode:  1118 Reward: -200.0 Epsilon 0.1 mean q -16.696383\n",
      "Episode:  1119 Reward: -200.0 Epsilon 0.1 mean q -16.672264\n",
      "Episode:  1120 Reward: -200.0 Epsilon 0.1 mean q -16.663296\n",
      "Episode:  1121 Reward: -200.0 Epsilon 0.1 mean q -16.683596\n",
      "Episode:  1122 Reward: -200.0 Epsilon 0.1 mean q -16.6538\n",
      "Episode:  1123 Reward: -200.0 Epsilon 0.1 mean q -16.66073\n",
      "Episode:  1124 Reward: -200.0 Epsilon 0.1 mean q -16.677118\n",
      "Episode:  1125 Reward: -200.0 Epsilon 0.1 mean q -16.672462\n",
      "Episode:  1126 Reward: -200.0 Epsilon 0.1 mean q -16.648834\n",
      "Episode:  1127 Reward: -200.0 Epsilon 0.1 mean q -16.663523\n",
      "Episode:  1128 Reward: -200.0 Epsilon 0.1 mean q -16.676788\n",
      "Episode:  1129 Reward: -200.0 Epsilon 0.1 mean q -16.685902\n",
      "Episode:  1130 Reward: -200.0 Epsilon 0.1 mean q -16.656494\n",
      "Episode:  1131 Reward: -200.0 Epsilon 0.1 mean q -16.653008\n",
      "Episode:  1132 Reward: -200.0 Epsilon 0.1 mean q -16.65286\n",
      "Episode:  1133 Reward: -200.0 Epsilon 0.1 mean q -16.669847\n",
      "Episode:  1134 Reward: -200.0 Epsilon 0.1 mean q -16.650097\n",
      "Episode:  1135 Reward: -200.0 Epsilon 0.1 mean q -16.653906\n",
      "Episode:  1136 Reward: -200.0 Epsilon 0.1 mean q -16.645048\n",
      "Episode:  1137 Reward: -200.0 Epsilon 0.1 mean q -16.668917\n",
      "Episode:  1138 Reward: -200.0 Epsilon 0.1 mean q -16.664597\n",
      "Episode:  1139 Reward: -200.0 Epsilon 0.1 mean q -16.644608\n",
      "Episode:  1140 Reward: -200.0 Epsilon 0.1 mean q -16.674833\n",
      "Episode:  1141 Reward: -200.0 Epsilon 0.1 mean q -16.625788\n",
      "Episode:  1142 Reward: -200.0 Epsilon 0.1 mean q -16.636204\n",
      "Episode:  1143 Reward: -200.0 Epsilon 0.1 mean q -16.665808\n",
      "Episode:  1144 Reward: -200.0 Epsilon 0.1 mean q -16.636147\n",
      "Episode:  1145 Reward: -200.0 Epsilon 0.1 mean q -16.64565\n",
      "Episode:  1146 Reward: -200.0 Epsilon 0.1 mean q -16.666826\n",
      "Episode:  1147 Reward: -200.0 Epsilon 0.1 mean q -16.678045\n",
      "Episode:  1148 Reward: -200.0 Epsilon 0.1 mean q -16.66209\n",
      "Episode:  1149 Reward: -200.0 Epsilon 0.1 mean q -16.678219\n",
      "Episode:  1150 Reward: -200.0 Epsilon 0.1 mean q -16.668617\n",
      "Episode:  1151 Reward: -200.0 Epsilon 0.1 mean q -16.671518\n",
      "Episode:  1152 Reward: -200.0 Epsilon 0.1 mean q -16.640265\n",
      "Episode:  1153 Reward: -200.0 Epsilon 0.1 mean q -16.674425\n",
      "Episode:  1154 Reward: -200.0 Epsilon 0.1 mean q -16.646181\n",
      "Episode:  1155 Reward: -200.0 Epsilon 0.1 mean q -16.6349\n",
      "Episode:  1156 Reward: -200.0 Epsilon 0.1 mean q -16.642485\n",
      "Episode:  1157 Reward: -200.0 Epsilon 0.1 mean q -16.695335\n",
      "Episode:  1158 Reward: -200.0 Epsilon 0.1 mean q -16.670288\n",
      "Episode:  1159 Reward: -200.0 Epsilon 0.1 mean q -16.67944\n",
      "Episode:  1160 Reward: -200.0 Epsilon 0.1 mean q -16.649313\n",
      "Episode:  1161 Reward: -200.0 Epsilon 0.1 mean q -16.692636\n",
      "Episode:  1162 Reward: -200.0 Epsilon 0.1 mean q -16.665258\n",
      "Episode:  1163 Reward: -200.0 Epsilon 0.1 mean q -16.668695\n",
      "Episode:  1164 Reward: -200.0 Epsilon 0.1 mean q -16.673708\n",
      "Episode:  1165 Reward: -200.0 Epsilon 0.1 mean q -16.645618\n",
      "Episode:  1166 Reward: -200.0 Epsilon 0.1 mean q -16.662504\n",
      "Episode:  1167 Reward: -200.0 Epsilon 0.1 mean q -16.70378\n",
      "Episode:  1168 Reward: -200.0 Epsilon 0.1 mean q -16.635265\n",
      "Episode:  1169 Reward: -200.0 Epsilon 0.1 mean q -16.64649\n",
      "Episode:  1170 Reward: -200.0 Epsilon 0.1 mean q -16.699284\n",
      "Episode:  1171 Reward: -200.0 Epsilon 0.1 mean q -16.647097\n",
      "Episode:  1172 Reward: -200.0 Epsilon 0.1 mean q -16.596056\n",
      "Episode:  1173 Reward: -200.0 Epsilon 0.1 mean q -16.6651\n",
      "Episode:  1174 Reward: -200.0 Epsilon 0.1 mean q -16.658634\n",
      "Episode:  1175 Reward: -200.0 Epsilon 0.1 mean q -16.65994\n",
      "Episode:  1176 Reward: -200.0 Epsilon 0.1 mean q -16.65662\n",
      "Episode:  1177 Reward: -200.0 Epsilon 0.1 mean q -16.658575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1178 Reward: -200.0 Epsilon 0.1 mean q -16.638556\n",
      "Episode:  1179 Reward: -200.0 Epsilon 0.1 mean q -16.68484\n",
      "Episode:  1180 Reward: -200.0 Epsilon 0.1 mean q -16.660046\n",
      "Episode:  1181 Reward: -200.0 Epsilon 0.1 mean q -16.668642\n",
      "Episode:  1182 Reward: -200.0 Epsilon 0.1 mean q -16.667164\n",
      "Episode:  1183 Reward: -200.0 Epsilon 0.1 mean q -16.662054\n",
      "Episode:  1184 Reward: -200.0 Epsilon 0.1 mean q -16.673395\n",
      "Episode:  1185 Reward: -200.0 Epsilon 0.1 mean q -16.614954\n",
      "Episode:  1186 Reward: -200.0 Epsilon 0.1 mean q -16.666508\n",
      "Episode:  1187 Reward: -200.0 Epsilon 0.1 mean q -16.637335\n",
      "Episode:  1188 Reward: -200.0 Epsilon 0.1 mean q -16.672638\n",
      "Episode:  1189 Reward: -200.0 Epsilon 0.1 mean q -16.684004\n",
      "Episode:  1190 Reward: -200.0 Epsilon 0.1 mean q -16.682379\n",
      "Episode:  1191 Reward: -200.0 Epsilon 0.1 mean q -16.663235\n",
      "Episode:  1192 Reward: -200.0 Epsilon 0.1 mean q -16.655611\n",
      "Episode:  1193 Reward: -200.0 Epsilon 0.1 mean q -16.6608\n",
      "Episode:  1194 Reward: -200.0 Epsilon 0.1 mean q -16.637524\n",
      "Episode:  1195 Reward: -200.0 Epsilon 0.1 mean q -16.650164\n",
      "Episode:  1196 Reward: -200.0 Epsilon 0.1 mean q -16.641663\n",
      "Episode:  1197 Reward: -200.0 Epsilon 0.1 mean q -16.664993\n",
      "Episode:  1198 Reward: -200.0 Epsilon 0.1 mean q -16.67139\n",
      "Episode:  1199 Reward: -200.0 Epsilon 0.1 mean q -16.652794\n",
      "Episode:  1200 Reward: -200.0 Epsilon 0.1 mean q -16.678051\n",
      "Episode:  1201 Reward: -200.0 Epsilon 0.1 mean q -16.663633\n",
      "Episode:  1202 Reward: -200.0 Epsilon 0.1 mean q -16.682867\n",
      "Episode:  1203 Reward: -200.0 Epsilon 0.1 mean q -16.664053\n",
      "Episode:  1204 Reward: -200.0 Epsilon 0.1 mean q -16.65945\n",
      "Episode:  1205 Reward: -200.0 Epsilon 0.1 mean q -16.656761\n",
      "Episode:  1206 Reward: -200.0 Epsilon 0.1 mean q -16.6885\n",
      "Episode:  1207 Reward: -200.0 Epsilon 0.1 mean q -16.658176\n",
      "Episode:  1208 Reward: -200.0 Epsilon 0.1 mean q -16.64734\n",
      "Episode:  1209 Reward: -200.0 Epsilon 0.1 mean q -16.63143\n",
      "Episode:  1210 Reward: -200.0 Epsilon 0.1 mean q -16.680511\n",
      "Episode:  1211 Reward: -200.0 Epsilon 0.1 mean q -16.65935\n",
      "Episode:  1212 Reward: -200.0 Epsilon 0.1 mean q -16.655895\n",
      "Episode:  1213 Reward: -200.0 Epsilon 0.1 mean q -16.669207\n",
      "Episode:  1214 Reward: -200.0 Epsilon 0.1 mean q -16.66126\n",
      "Episode:  1215 Reward: -200.0 Epsilon 0.1 mean q -16.648876\n",
      "Episode:  1216 Reward: -200.0 Epsilon 0.1 mean q -16.673141\n",
      "Episode:  1217 Reward: -200.0 Epsilon 0.1 mean q -16.69601\n",
      "Episode:  1218 Reward: -200.0 Epsilon 0.1 mean q -16.644848\n",
      "Episode:  1219 Reward: -200.0 Epsilon 0.1 mean q -16.645319\n",
      "Episode:  1220 Reward: -200.0 Epsilon 0.1 mean q -16.688988\n",
      "Episode:  1221 Reward: -200.0 Epsilon 0.1 mean q -16.663897\n",
      "Episode:  1222 Reward: -200.0 Epsilon 0.1 mean q -16.653545\n",
      "Episode:  1223 Reward: -200.0 Epsilon 0.1 mean q -16.670305\n",
      "Episode:  1224 Reward: -200.0 Epsilon 0.1 mean q -16.669691\n",
      "Episode:  1225 Reward: -200.0 Epsilon 0.1 mean q -16.658102\n",
      "Episode:  1226 Reward: -200.0 Epsilon 0.1 mean q -16.683632\n",
      "Episode:  1227 Reward: -200.0 Epsilon 0.1 mean q -16.655394\n",
      "Episode:  1228 Reward: -200.0 Epsilon 0.1 mean q -16.683117\n",
      "Episode:  1229 Reward: -200.0 Epsilon 0.1 mean q -16.665163\n",
      "Episode:  1230 Reward: -200.0 Epsilon 0.1 mean q -16.689636\n",
      "Episode:  1231 Reward: -200.0 Epsilon 0.1 mean q -16.694082\n",
      "Episode:  1232 Reward: -200.0 Epsilon 0.1 mean q -16.62794\n",
      "Episode:  1233 Reward: -200.0 Epsilon 0.1 mean q -16.631683\n",
      "Episode:  1234 Reward: -200.0 Epsilon 0.1 mean q -16.64461\n",
      "Episode:  1235 Reward: -200.0 Epsilon 0.1 mean q -16.69559\n",
      "Episode:  1236 Reward: -200.0 Epsilon 0.1 mean q -16.653221\n",
      "Episode:  1237 Reward: -200.0 Epsilon 0.1 mean q -16.654118\n",
      "Episode:  1238 Reward: -200.0 Epsilon 0.1 mean q -16.638266\n",
      "Episode:  1239 Reward: -200.0 Epsilon 0.1 mean q -16.649681\n",
      "Episode:  1240 Reward: -200.0 Epsilon 0.1 mean q -16.649889\n",
      "Episode:  1241 Reward: -200.0 Epsilon 0.1 mean q -16.642683\n",
      "Episode:  1242 Reward: -200.0 Epsilon 0.1 mean q -16.659801\n",
      "Episode:  1243 Reward: -200.0 Epsilon 0.1 mean q -16.672258\n",
      "Episode:  1244 Reward: -200.0 Epsilon 0.1 mean q -16.626816\n",
      "Episode:  1245 Reward: -200.0 Epsilon 0.1 mean q -16.667904\n",
      "Episode:  1246 Reward: -200.0 Epsilon 0.1 mean q -16.652483\n",
      "Episode:  1247 Reward: -200.0 Epsilon 0.1 mean q -16.6568\n",
      "Episode:  1248 Reward: -200.0 Epsilon 0.1 mean q -16.688772\n",
      "Episode:  1249 Reward: -200.0 Epsilon 0.1 mean q -16.663683\n",
      "Episode:  1250 Reward: -200.0 Epsilon 0.1 mean q -16.67599\n",
      "Episode:  1251 Reward: -200.0 Epsilon 0.1 mean q -16.687063\n",
      "Episode:  1252 Reward: -200.0 Epsilon 0.1 mean q -16.662405\n",
      "Episode:  1253 Reward: -200.0 Epsilon 0.1 mean q -16.630133\n",
      "Episode:  1254 Reward: -200.0 Epsilon 0.1 mean q -16.662304\n",
      "Episode:  1255 Reward: -200.0 Epsilon 0.1 mean q -16.644154\n",
      "Episode:  1256 Reward: -200.0 Epsilon 0.1 mean q -16.664837\n",
      "Episode:  1257 Reward: -200.0 Epsilon 0.1 mean q -16.657938\n",
      "Episode:  1258 Reward: -200.0 Epsilon 0.1 mean q -16.663181\n",
      "Episode:  1259 Reward: -200.0 Epsilon 0.1 mean q -16.664747\n",
      "Episode:  1260 Reward: -200.0 Epsilon 0.1 mean q -16.65132\n",
      "Episode:  1261 Reward: -200.0 Epsilon 0.1 mean q -16.620277\n",
      "Episode:  1262 Reward: -200.0 Epsilon 0.1 mean q -16.651884\n",
      "Episode:  1263 Reward: -200.0 Epsilon 0.1 mean q -16.657297\n",
      "Episode:  1264 Reward: -200.0 Epsilon 0.1 mean q -16.681368\n",
      "Episode:  1265 Reward: -200.0 Epsilon 0.1 mean q -16.650625\n",
      "Episode:  1266 Reward: -200.0 Epsilon 0.1 mean q -16.700844\n",
      "Episode:  1267 Reward: -200.0 Epsilon 0.1 mean q -16.678122\n",
      "Episode:  1268 Reward: -200.0 Epsilon 0.1 mean q -16.678816\n",
      "Episode:  1269 Reward: -200.0 Epsilon 0.1 mean q -16.68595\n",
      "Episode:  1270 Reward: -200.0 Epsilon 0.1 mean q -16.650326\n",
      "Episode:  1271 Reward: -200.0 Epsilon 0.1 mean q -16.684572\n",
      "Episode:  1272 Reward: -200.0 Epsilon 0.1 mean q -16.664509\n",
      "Episode:  1273 Reward: -200.0 Epsilon 0.1 mean q -16.693415\n",
      "Episode:  1274 Reward: -200.0 Epsilon 0.1 mean q -16.681322\n",
      "Episode:  1275 Reward: -200.0 Epsilon 0.1 mean q -16.660612\n",
      "Episode:  1276 Reward: -200.0 Epsilon 0.1 mean q -16.683521\n",
      "Episode:  1277 Reward: -200.0 Epsilon 0.1 mean q -16.691607\n",
      "Episode:  1278 Reward: -200.0 Epsilon 0.1 mean q -16.676003\n",
      "Episode:  1279 Reward: -200.0 Epsilon 0.1 mean q -16.653059\n",
      "Episode:  1280 Reward: -200.0 Epsilon 0.1 mean q -16.613327\n",
      "Episode:  1281 Reward: -200.0 Epsilon 0.1 mean q -16.676067\n",
      "Episode:  1282 Reward: -200.0 Epsilon 0.1 mean q -16.69834\n",
      "Episode:  1283 Reward: -200.0 Epsilon 0.1 mean q -16.716923\n",
      "Episode:  1284 Reward: -200.0 Epsilon 0.1 mean q -16.657198\n",
      "Episode:  1285 Reward: -200.0 Epsilon 0.1 mean q -16.655697\n",
      "Episode:  1286 Reward: -200.0 Epsilon 0.1 mean q -16.685987\n",
      "Episode:  1287 Reward: -200.0 Epsilon 0.1 mean q -16.65266\n",
      "Episode:  1288 Reward: -200.0 Epsilon 0.1 mean q -16.672712\n",
      "Episode:  1289 Reward: -200.0 Epsilon 0.1 mean q -16.672216\n",
      "Episode:  1290 Reward: -200.0 Epsilon 0.1 mean q -16.661999\n",
      "Episode:  1291 Reward: -200.0 Epsilon 0.1 mean q -16.649212\n",
      "Episode:  1292 Reward: -200.0 Epsilon 0.1 mean q -16.631714\n",
      "Episode:  1293 Reward: -200.0 Epsilon 0.1 mean q -16.682972\n",
      "Episode:  1294 Reward: -200.0 Epsilon 0.1 mean q -16.693851\n",
      "Episode:  1295 Reward: -200.0 Epsilon 0.1 mean q -16.68213\n",
      "Episode:  1296 Reward: -200.0 Epsilon 0.1 mean q -16.667665\n",
      "Episode:  1297 Reward: -200.0 Epsilon 0.1 mean q -16.651005\n",
      "Episode:  1298 Reward: -200.0 Epsilon 0.1 mean q -16.679558\n",
      "Episode:  1299 Reward: -200.0 Epsilon 0.1 mean q -16.674866\n",
      "Episode:  1300 Reward: -200.0 Epsilon 0.1 mean q -16.655056\n",
      "Episode:  1301 Reward: -200.0 Epsilon 0.1 mean q -16.667711\n",
      "Episode:  1302 Reward: -200.0 Epsilon 0.1 mean q -16.643517\n",
      "Episode:  1303 Reward: -200.0 Epsilon 0.1 mean q -16.71537\n",
      "Episode:  1304 Reward: -200.0 Epsilon 0.1 mean q -16.639936\n",
      "Episode:  1305 Reward: -200.0 Epsilon 0.1 mean q -16.641218\n",
      "Episode:  1306 Reward: -200.0 Epsilon 0.1 mean q -16.650476\n",
      "Episode:  1307 Reward: -200.0 Epsilon 0.1 mean q -16.646708\n",
      "Episode:  1308 Reward: -200.0 Epsilon 0.1 mean q -16.656567\n",
      "Episode:  1309 Reward: -200.0 Epsilon 0.1 mean q -16.65073\n",
      "Episode:  1310 Reward: -200.0 Epsilon 0.1 mean q -16.642138\n",
      "Episode:  1311 Reward: -200.0 Epsilon 0.1 mean q -16.667484\n",
      "Episode:  1312 Reward: -200.0 Epsilon 0.1 mean q -16.657715\n",
      "Episode:  1313 Reward: -200.0 Epsilon 0.1 mean q -16.646585\n",
      "Episode:  1314 Reward: -200.0 Epsilon 0.1 mean q -16.65776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1315 Reward: -200.0 Epsilon 0.1 mean q -16.637703\n",
      "Episode:  1316 Reward: -200.0 Epsilon 0.1 mean q -16.619339\n",
      "Episode:  1317 Reward: -200.0 Epsilon 0.1 mean q -16.674377\n",
      "Episode:  1318 Reward: -200.0 Epsilon 0.1 mean q -16.660662\n",
      "Episode:  1319 Reward: -200.0 Epsilon 0.1 mean q -16.656809\n",
      "Episode:  1320 Reward: -200.0 Epsilon 0.1 mean q -16.694498\n",
      "Episode:  1321 Reward: -200.0 Epsilon 0.1 mean q -16.673046\n",
      "Episode:  1322 Reward: -200.0 Epsilon 0.1 mean q -16.660936\n",
      "Episode:  1323 Reward: -200.0 Epsilon 0.1 mean q -16.656868\n",
      "Episode:  1324 Reward: -200.0 Epsilon 0.1 mean q -16.641787\n",
      "Episode:  1325 Reward: -200.0 Epsilon 0.1 mean q -16.646856\n",
      "Episode:  1326 Reward: -200.0 Epsilon 0.1 mean q -16.668053\n",
      "Episode:  1327 Reward: -200.0 Epsilon 0.1 mean q -16.632563\n",
      "Episode:  1328 Reward: -200.0 Epsilon 0.1 mean q -16.620354\n",
      "Episode:  1329 Reward: -200.0 Epsilon 0.1 mean q -16.681337\n",
      "Episode:  1330 Reward: -200.0 Epsilon 0.1 mean q -16.659662\n",
      "Episode:  1331 Reward: -200.0 Epsilon 0.1 mean q -16.652761\n",
      "Episode:  1332 Reward: -200.0 Epsilon 0.1 mean q -16.677704\n",
      "Episode:  1333 Reward: -200.0 Epsilon 0.1 mean q -16.654114\n",
      "Episode:  1334 Reward: -200.0 Epsilon 0.1 mean q -16.67446\n",
      "Episode:  1335 Reward: -200.0 Epsilon 0.1 mean q -16.67049\n",
      "Episode:  1336 Reward: -200.0 Epsilon 0.1 mean q -16.696276\n",
      "Episode:  1337 Reward: -200.0 Epsilon 0.1 mean q -16.661224\n",
      "Episode:  1338 Reward: -200.0 Epsilon 0.1 mean q -16.666742\n",
      "Episode:  1339 Reward: -200.0 Epsilon 0.1 mean q -16.672009\n",
      "Episode:  1340 Reward: -200.0 Epsilon 0.1 mean q -16.648165\n",
      "Episode:  1341 Reward: -200.0 Epsilon 0.1 mean q -16.675455\n",
      "Episode:  1342 Reward: -200.0 Epsilon 0.1 mean q -16.644424\n",
      "Episode:  1343 Reward: -200.0 Epsilon 0.1 mean q -16.619461\n",
      "Episode:  1344 Reward: -200.0 Epsilon 0.1 mean q -16.719257\n",
      "Episode:  1345 Reward: -200.0 Epsilon 0.1 mean q -16.633799\n",
      "Episode:  1346 Reward: -200.0 Epsilon 0.1 mean q -16.683598\n",
      "Episode:  1347 Reward: -200.0 Epsilon 0.1 mean q -16.643581\n",
      "Episode:  1348 Reward: -200.0 Epsilon 0.1 mean q -16.676735\n",
      "Episode:  1349 Reward: -200.0 Epsilon 0.1 mean q -16.664707\n",
      "Episode:  1350 Reward: -200.0 Epsilon 0.1 mean q -16.643627\n",
      "Episode:  1351 Reward: -200.0 Epsilon 0.1 mean q -16.675835\n",
      "Episode:  1352 Reward: -200.0 Epsilon 0.1 mean q -16.688833\n",
      "Episode:  1353 Reward: -200.0 Epsilon 0.1 mean q -16.695507\n",
      "Episode:  1354 Reward: -200.0 Epsilon 0.1 mean q -16.680416\n",
      "Episode:  1355 Reward: -200.0 Epsilon 0.1 mean q -16.67957\n",
      "Episode:  1356 Reward: -200.0 Epsilon 0.1 mean q -16.673666\n",
      "Episode:  1357 Reward: -200.0 Epsilon 0.1 mean q -16.686064\n",
      "Episode:  1358 Reward: -200.0 Epsilon 0.1 mean q -16.6856\n",
      "Episode:  1359 Reward: -200.0 Epsilon 0.1 mean q -16.682598\n",
      "Episode:  1360 Reward: -200.0 Epsilon 0.1 mean q -16.675825\n",
      "Episode:  1361 Reward: -200.0 Epsilon 0.1 mean q -16.649446\n",
      "Episode:  1362 Reward: -200.0 Epsilon 0.1 mean q -16.670229\n",
      "Episode:  1363 Reward: -200.0 Epsilon 0.1 mean q -16.65372\n",
      "Episode:  1364 Reward: -200.0 Epsilon 0.1 mean q -16.653465\n",
      "Episode:  1365 Reward: -200.0 Epsilon 0.1 mean q -16.690063\n",
      "Episode:  1366 Reward: -200.0 Epsilon 0.1 mean q -16.667894\n",
      "Episode:  1367 Reward: -200.0 Epsilon 0.1 mean q -16.677217\n",
      "Episode:  1368 Reward: -200.0 Epsilon 0.1 mean q -16.665255\n",
      "Episode:  1369 Reward: -200.0 Epsilon 0.1 mean q -16.685085\n",
      "Episode:  1370 Reward: -200.0 Epsilon 0.1 mean q -16.69796\n",
      "Episode:  1371 Reward: -200.0 Epsilon 0.1 mean q -16.650705\n",
      "Episode:  1372 Reward: -200.0 Epsilon 0.1 mean q -16.623785\n",
      "Episode:  1373 Reward: -200.0 Epsilon 0.1 mean q -16.653399\n",
      "Episode:  1374 Reward: -200.0 Epsilon 0.1 mean q -16.666367\n",
      "Episode:  1375 Reward: -200.0 Epsilon 0.1 mean q -16.652903\n",
      "Episode:  1376 Reward: -200.0 Epsilon 0.1 mean q -16.658875\n",
      "Episode:  1377 Reward: -200.0 Epsilon 0.1 mean q -16.681717\n",
      "Episode:  1378 Reward: -200.0 Epsilon 0.1 mean q -16.628063\n",
      "Episode:  1379 Reward: -200.0 Epsilon 0.1 mean q -16.650297\n",
      "Episode:  1380 Reward: -200.0 Epsilon 0.1 mean q -16.683867\n",
      "Episode:  1381 Reward: -200.0 Epsilon 0.1 mean q -16.644854\n",
      "Episode:  1382 Reward: -200.0 Epsilon 0.1 mean q -16.636644\n",
      "Episode:  1383 Reward: -200.0 Epsilon 0.1 mean q -16.651995\n",
      "Episode:  1384 Reward: -200.0 Epsilon 0.1 mean q -16.60118\n",
      "Episode:  1385 Reward: -200.0 Epsilon 0.1 mean q -16.699944\n",
      "Episode:  1386 Reward: -200.0 Epsilon 0.1 mean q -16.681957\n",
      "Episode:  1387 Reward: -200.0 Epsilon 0.1 mean q -16.653814\n",
      "Episode:  1388 Reward: -200.0 Epsilon 0.1 mean q -16.637146\n",
      "Episode:  1389 Reward: -200.0 Epsilon 0.1 mean q -16.688194\n",
      "Episode:  1390 Reward: -200.0 Epsilon 0.1 mean q -16.634066\n",
      "Episode:  1391 Reward: -200.0 Epsilon 0.1 mean q -16.644958\n",
      "Episode:  1392 Reward: -200.0 Epsilon 0.1 mean q -16.654167\n",
      "Episode:  1393 Reward: -200.0 Epsilon 0.1 mean q -16.698383\n",
      "Episode:  1394 Reward: -200.0 Epsilon 0.1 mean q -16.643566\n",
      "Episode:  1395 Reward: -200.0 Epsilon 0.1 mean q -16.670174\n",
      "Episode:  1396 Reward: -200.0 Epsilon 0.1 mean q -16.632736\n",
      "Episode:  1397 Reward: -200.0 Epsilon 0.1 mean q -16.653606\n",
      "Episode:  1398 Reward: -200.0 Epsilon 0.1 mean q -16.63723\n",
      "Episode:  1399 Reward: -200.0 Epsilon 0.1 mean q -16.684158\n",
      "Episode:  1400 Reward: -200.0 Epsilon 0.1 mean q -16.65348\n",
      "Episode:  1401 Reward: -200.0 Epsilon 0.1 mean q -16.668324\n",
      "Episode:  1402 Reward: -200.0 Epsilon 0.1 mean q -16.67188\n",
      "Episode:  1403 Reward: -200.0 Epsilon 0.1 mean q -16.663168\n",
      "Episode:  1404 Reward: -200.0 Epsilon 0.1 mean q -16.706964\n",
      "Episode:  1405 Reward: -200.0 Epsilon 0.1 mean q -16.668753\n",
      "Episode:  1406 Reward: -200.0 Epsilon 0.1 mean q -16.653538\n",
      "Episode:  1407 Reward: -200.0 Epsilon 0.1 mean q -16.640406\n",
      "Episode:  1408 Reward: -200.0 Epsilon 0.1 mean q -16.625511\n",
      "Episode:  1409 Reward: -200.0 Epsilon 0.1 mean q -16.684965\n",
      "Episode:  1410 Reward: -200.0 Epsilon 0.1 mean q -16.675014\n",
      "Episode:  1411 Reward: -200.0 Epsilon 0.1 mean q -16.671982\n",
      "Episode:  1412 Reward: -200.0 Epsilon 0.1 mean q -16.661926\n",
      "Episode:  1413 Reward: -200.0 Epsilon 0.1 mean q -16.662104\n",
      "Episode:  1414 Reward: -200.0 Epsilon 0.1 mean q -16.655424\n",
      "Episode:  1415 Reward: -200.0 Epsilon 0.1 mean q -16.672113\n",
      "Episode:  1416 Reward: -200.0 Epsilon 0.1 mean q -16.679798\n",
      "Episode:  1417 Reward: -200.0 Epsilon 0.1 mean q -16.642471\n",
      "Episode:  1418 Reward: -200.0 Epsilon 0.1 mean q -16.667278\n",
      "Episode:  1419 Reward: -200.0 Epsilon 0.1 mean q -16.644342\n",
      "Episode:  1420 Reward: -200.0 Epsilon 0.1 mean q -16.668835\n",
      "Episode:  1421 Reward: -200.0 Epsilon 0.1 mean q -16.653128\n",
      "Episode:  1422 Reward: -200.0 Epsilon 0.1 mean q -16.656647\n",
      "Episode:  1423 Reward: -200.0 Epsilon 0.1 mean q -16.675589\n",
      "Episode:  1424 Reward: -200.0 Epsilon 0.1 mean q -16.699697\n",
      "Episode:  1425 Reward: -200.0 Epsilon 0.1 mean q -16.661905\n",
      "Episode:  1426 Reward: -200.0 Epsilon 0.1 mean q -16.667152\n",
      "Episode:  1427 Reward: -200.0 Epsilon 0.1 mean q -16.680733\n",
      "Episode:  1428 Reward: -200.0 Epsilon 0.1 mean q -16.66371\n",
      "Episode:  1429 Reward: -200.0 Epsilon 0.1 mean q -16.637308\n",
      "Episode:  1430 Reward: -200.0 Epsilon 0.1 mean q -16.66318\n",
      "Episode:  1431 Reward: -200.0 Epsilon 0.1 mean q -16.669563\n",
      "Episode:  1432 Reward: -200.0 Epsilon 0.1 mean q -16.666538\n",
      "Episode:  1433 Reward: -200.0 Epsilon 0.1 mean q -16.662685\n",
      "Episode:  1434 Reward: -200.0 Epsilon 0.1 mean q -16.709082\n",
      "Episode:  1435 Reward: -200.0 Epsilon 0.1 mean q -16.634287\n",
      "Episode:  1436 Reward: -200.0 Epsilon 0.1 mean q -16.641672\n",
      "Episode:  1437 Reward: -200.0 Epsilon 0.1 mean q -16.653688\n",
      "Episode:  1438 Reward: -200.0 Epsilon 0.1 mean q -16.656282\n",
      "Episode:  1439 Reward: -200.0 Epsilon 0.1 mean q -16.67047\n",
      "Episode:  1440 Reward: -200.0 Epsilon 0.1 mean q -16.674177\n",
      "Episode:  1441 Reward: -200.0 Epsilon 0.1 mean q -16.656784\n",
      "Episode:  1442 Reward: -200.0 Epsilon 0.1 mean q -16.67592\n",
      "Episode:  1443 Reward: -200.0 Epsilon 0.1 mean q -16.69079\n",
      "Episode:  1444 Reward: -200.0 Epsilon 0.1 mean q -16.637259\n",
      "Episode:  1445 Reward: -200.0 Epsilon 0.1 mean q -16.70213\n",
      "Episode:  1446 Reward: -200.0 Epsilon 0.1 mean q -16.692387\n",
      "Episode:  1447 Reward: -200.0 Epsilon 0.1 mean q -16.687197\n",
      "Episode:  1448 Reward: -200.0 Epsilon 0.1 mean q -16.680859\n",
      "Episode:  1449 Reward: -200.0 Epsilon 0.1 mean q -16.694128\n",
      "Episode:  1450 Reward: -200.0 Epsilon 0.1 mean q -16.657564\n",
      "Episode:  1451 Reward: -200.0 Epsilon 0.1 mean q -16.639193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1452 Reward: -200.0 Epsilon 0.1 mean q -16.669489\n",
      "Episode:  1453 Reward: -200.0 Epsilon 0.1 mean q -16.670797\n",
      "Episode:  1454 Reward: -200.0 Epsilon 0.1 mean q -16.683985\n",
      "Episode:  1455 Reward: -200.0 Epsilon 0.1 mean q -16.676329\n",
      "Episode:  1456 Reward: -200.0 Epsilon 0.1 mean q -16.69126\n",
      "Episode:  1457 Reward: -200.0 Epsilon 0.1 mean q -16.697893\n",
      "Episode:  1458 Reward: -200.0 Epsilon 0.1 mean q -16.630095\n",
      "Episode:  1459 Reward: -200.0 Epsilon 0.1 mean q -16.657444\n",
      "Episode:  1460 Reward: -200.0 Epsilon 0.1 mean q -16.662989\n",
      "Episode:  1461 Reward: -200.0 Epsilon 0.1 mean q -16.653807\n",
      "Episode:  1462 Reward: -200.0 Epsilon 0.1 mean q -16.670277\n",
      "Episode:  1463 Reward: -200.0 Epsilon 0.1 mean q -16.642805\n",
      "Episode:  1464 Reward: -200.0 Epsilon 0.1 mean q -16.685108\n",
      "Episode:  1465 Reward: -200.0 Epsilon 0.1 mean q -16.644707\n",
      "Episode:  1466 Reward: -200.0 Epsilon 0.1 mean q -16.673979\n",
      "Episode:  1467 Reward: -200.0 Epsilon 0.1 mean q -16.686174\n",
      "Episode:  1468 Reward: -200.0 Epsilon 0.1 mean q -16.627037\n",
      "Episode:  1469 Reward: -200.0 Epsilon 0.1 mean q -16.628157\n",
      "Episode:  1470 Reward: -200.0 Epsilon 0.1 mean q -16.662994\n",
      "Episode:  1471 Reward: -200.0 Epsilon 0.1 mean q -16.669075\n",
      "Episode:  1472 Reward: -200.0 Epsilon 0.1 mean q -16.67112\n",
      "Episode:  1473 Reward: -200.0 Epsilon 0.1 mean q -16.694841\n",
      "Episode:  1474 Reward: -200.0 Epsilon 0.1 mean q -16.668962\n",
      "Episode:  1475 Reward: -200.0 Epsilon 0.1 mean q -16.670815\n",
      "Episode:  1476 Reward: -200.0 Epsilon 0.1 mean q -16.662321\n",
      "Episode:  1477 Reward: -200.0 Epsilon 0.1 mean q -16.694527\n",
      "Episode:  1478 Reward: -200.0 Epsilon 0.1 mean q -16.652857\n",
      "Episode:  1479 Reward: -200.0 Epsilon 0.1 mean q -16.67734\n",
      "Episode:  1480 Reward: -200.0 Epsilon 0.1 mean q -16.642096\n",
      "Episode:  1481 Reward: -200.0 Epsilon 0.1 mean q -16.663187\n",
      "Episode:  1482 Reward: -200.0 Epsilon 0.1 mean q -16.65087\n",
      "Episode:  1483 Reward: -200.0 Epsilon 0.1 mean q -16.664389\n",
      "Episode:  1484 Reward: -200.0 Epsilon 0.1 mean q -16.663902\n",
      "Episode:  1485 Reward: -200.0 Epsilon 0.1 mean q -16.594267\n",
      "Episode:  1486 Reward: -200.0 Epsilon 0.1 mean q -16.646305\n",
      "Episode:  1487 Reward: -200.0 Epsilon 0.1 mean q -16.679667\n",
      "Episode:  1488 Reward: -200.0 Epsilon 0.1 mean q -16.682253\n",
      "Episode:  1489 Reward: -200.0 Epsilon 0.1 mean q -16.680712\n",
      "Episode:  1490 Reward: -200.0 Epsilon 0.1 mean q -16.636381\n",
      "Episode:  1491 Reward: -200.0 Epsilon 0.1 mean q -16.650293\n",
      "Episode:  1492 Reward: -200.0 Epsilon 0.1 mean q -16.706392\n",
      "Episode:  1493 Reward: -200.0 Epsilon 0.1 mean q -16.680056\n",
      "Episode:  1494 Reward: -200.0 Epsilon 0.1 mean q -16.684637\n",
      "Episode:  1495 Reward: -200.0 Epsilon 0.1 mean q -16.660131\n",
      "Episode:  1496 Reward: -200.0 Epsilon 0.1 mean q -16.6627\n",
      "Episode:  1497 Reward: -200.0 Epsilon 0.1 mean q -16.646765\n",
      "Episode:  1498 Reward: -200.0 Epsilon 0.1 mean q -16.665648\n",
      "Episode:  1499 Reward: -200.0 Epsilon 0.1 mean q -16.654913\n",
      "Episode:  1500 Reward: -200.0 Epsilon 0.1 mean q -16.671156\n",
      "Episode:  1501 Reward: -200.0 Epsilon 0.1 mean q -16.653582\n",
      "Episode:  1502 Reward: -200.0 Epsilon 0.1 mean q -16.658356\n",
      "Episode:  1503 Reward: -200.0 Epsilon 0.1 mean q -16.637323\n",
      "Episode:  1504 Reward: -200.0 Epsilon 0.1 mean q -16.66181\n",
      "Episode:  1505 Reward: -200.0 Epsilon 0.1 mean q -16.65625\n",
      "Episode:  1506 Reward: -200.0 Epsilon 0.1 mean q -16.67759\n",
      "Episode:  1507 Reward: -200.0 Epsilon 0.1 mean q -16.671404\n",
      "Episode:  1508 Reward: -200.0 Epsilon 0.1 mean q -16.638079\n",
      "Episode:  1509 Reward: -200.0 Epsilon 0.1 mean q -16.688992\n",
      "Episode:  1510 Reward: -200.0 Epsilon 0.1 mean q -16.685537\n",
      "Episode:  1511 Reward: -200.0 Epsilon 0.1 mean q -16.66996\n",
      "Episode:  1512 Reward: -200.0 Epsilon 0.1 mean q -16.659798\n",
      "Episode:  1513 Reward: -200.0 Epsilon 0.1 mean q -16.679493\n",
      "Episode:  1514 Reward: -200.0 Epsilon 0.1 mean q -16.694906\n",
      "Episode:  1515 Reward: -200.0 Epsilon 0.1 mean q -16.641184\n",
      "Episode:  1516 Reward: -200.0 Epsilon 0.1 mean q -16.682009\n",
      "Episode:  1517 Reward: -200.0 Epsilon 0.1 mean q -16.687025\n",
      "Episode:  1518 Reward: -200.0 Epsilon 0.1 mean q -16.632662\n",
      "Episode:  1519 Reward: -200.0 Epsilon 0.1 mean q -16.68176\n",
      "Episode:  1520 Reward: -200.0 Epsilon 0.1 mean q -16.637068\n",
      "Episode:  1521 Reward: -200.0 Epsilon 0.1 mean q -16.671785\n",
      "Episode:  1522 Reward: -200.0 Epsilon 0.1 mean q -16.64775\n",
      "Episode:  1523 Reward: -200.0 Epsilon 0.1 mean q -16.666351\n",
      "Episode:  1524 Reward: -200.0 Epsilon 0.1 mean q -16.653437\n",
      "Episode:  1525 Reward: -200.0 Epsilon 0.1 mean q -16.6637\n",
      "Episode:  1526 Reward: -200.0 Epsilon 0.1 mean q -16.690325\n",
      "Episode:  1527 Reward: -200.0 Epsilon 0.1 mean q -16.652975\n",
      "Episode:  1528 Reward: -200.0 Epsilon 0.1 mean q -16.64377\n",
      "Episode:  1529 Reward: -200.0 Epsilon 0.1 mean q -16.679857\n",
      "Episode:  1530 Reward: -200.0 Epsilon 0.1 mean q -16.667343\n",
      "Episode:  1531 Reward: -200.0 Epsilon 0.1 mean q -16.675472\n",
      "Episode:  1532 Reward: -200.0 Epsilon 0.1 mean q -16.681372\n",
      "Episode:  1533 Reward: -200.0 Epsilon 0.1 mean q -16.708633\n",
      "Episode:  1534 Reward: -200.0 Epsilon 0.1 mean q -16.64065\n",
      "Episode:  1535 Reward: -200.0 Epsilon 0.1 mean q -16.688692\n",
      "Episode:  1536 Reward: -200.0 Epsilon 0.1 mean q -16.668625\n",
      "Episode:  1537 Reward: -200.0 Epsilon 0.1 mean q -16.674326\n",
      "Episode:  1538 Reward: -200.0 Epsilon 0.1 mean q -16.664043\n",
      "Episode:  1539 Reward: -200.0 Epsilon 0.1 mean q -16.695908\n",
      "Episode:  1540 Reward: -200.0 Epsilon 0.1 mean q -16.664925\n",
      "Episode:  1541 Reward: -200.0 Epsilon 0.1 mean q -16.670774\n",
      "Episode:  1542 Reward: -200.0 Epsilon 0.1 mean q -16.669245\n",
      "Episode:  1543 Reward: -200.0 Epsilon 0.1 mean q -16.694052\n",
      "Episode:  1544 Reward: -200.0 Epsilon 0.1 mean q -16.637938\n",
      "Episode:  1545 Reward: -200.0 Epsilon 0.1 mean q -16.685598\n",
      "Episode:  1546 Reward: -200.0 Epsilon 0.1 mean q -16.685698\n",
      "Episode:  1547 Reward: -200.0 Epsilon 0.1 mean q -16.62893\n",
      "Episode:  1548 Reward: -200.0 Epsilon 0.1 mean q -16.673817\n",
      "Episode:  1549 Reward: -200.0 Epsilon 0.1 mean q -16.662586\n",
      "Episode:  1550 Reward: -200.0 Epsilon 0.1 mean q -16.691608\n",
      "Episode:  1551 Reward: -200.0 Epsilon 0.1 mean q -16.702698\n",
      "Episode:  1552 Reward: -200.0 Epsilon 0.1 mean q -16.641182\n",
      "Episode:  1553 Reward: -200.0 Epsilon 0.1 mean q -16.72328\n",
      "Episode:  1554 Reward: -200.0 Epsilon 0.1 mean q -16.651796\n",
      "Episode:  1555 Reward: -200.0 Epsilon 0.1 mean q -16.674267\n",
      "Episode:  1556 Reward: -200.0 Epsilon 0.1 mean q -16.663845\n",
      "Episode:  1557 Reward: -200.0 Epsilon 0.1 mean q -16.633429\n",
      "Episode:  1558 Reward: -200.0 Epsilon 0.1 mean q -16.641136\n",
      "Episode:  1559 Reward: -200.0 Epsilon 0.1 mean q -16.647743\n",
      "Episode:  1560 Reward: -200.0 Epsilon 0.1 mean q -16.681936\n",
      "Episode:  1561 Reward: -200.0 Epsilon 0.1 mean q -16.661572\n",
      "Episode:  1562 Reward: -200.0 Epsilon 0.1 mean q -16.651491\n",
      "Episode:  1563 Reward: -200.0 Epsilon 0.1 mean q -16.64923\n",
      "Episode:  1564 Reward: -200.0 Epsilon 0.1 mean q -16.661432\n",
      "Episode:  1565 Reward: -200.0 Epsilon 0.1 mean q -16.65479\n",
      "Episode:  1566 Reward: -200.0 Epsilon 0.1 mean q -16.694902\n",
      "Episode:  1567 Reward: -200.0 Epsilon 0.1 mean q -16.660004\n",
      "Episode:  1568 Reward: -200.0 Epsilon 0.1 mean q -16.675415\n",
      "Episode:  1569 Reward: -200.0 Epsilon 0.1 mean q -16.657835\n",
      "Episode:  1570 Reward: -200.0 Epsilon 0.1 mean q -16.696796\n",
      "Episode:  1571 Reward: -200.0 Epsilon 0.1 mean q -16.68387\n",
      "Episode:  1572 Reward: -200.0 Epsilon 0.1 mean q -16.668272\n",
      "Episode:  1573 Reward: -200.0 Epsilon 0.1 mean q -16.651007\n",
      "Episode:  1574 Reward: -200.0 Epsilon 0.1 mean q -16.637623\n",
      "Episode:  1575 Reward: -200.0 Epsilon 0.1 mean q -16.671799\n",
      "Episode:  1576 Reward: -200.0 Epsilon 0.1 mean q -16.690504\n",
      "Episode:  1577 Reward: -200.0 Epsilon 0.1 mean q -16.682842\n",
      "Episode:  1578 Reward: -200.0 Epsilon 0.1 mean q -16.66966\n",
      "Episode:  1579 Reward: -200.0 Epsilon 0.1 mean q -16.643705\n",
      "Episode:  1580 Reward: -200.0 Epsilon 0.1 mean q -16.677402\n",
      "Episode:  1581 Reward: -200.0 Epsilon 0.1 mean q -16.667707\n",
      "Episode:  1582 Reward: -200.0 Epsilon 0.1 mean q -16.6658\n",
      "Episode:  1583 Reward: -200.0 Epsilon 0.1 mean q -16.63927\n",
      "Episode:  1584 Reward: -200.0 Epsilon 0.1 mean q -16.684137\n",
      "Episode:  1585 Reward: -200.0 Epsilon 0.1 mean q -16.653477\n",
      "Episode:  1586 Reward: -200.0 Epsilon 0.1 mean q -16.658558\n",
      "Episode:  1587 Reward: -200.0 Epsilon 0.1 mean q -16.662104\n",
      "Episode:  1588 Reward: -200.0 Epsilon 0.1 mean q -16.695248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1589 Reward: -200.0 Epsilon 0.1 mean q -16.676247\n",
      "Episode:  1590 Reward: -200.0 Epsilon 0.1 mean q -16.647364\n",
      "Episode:  1591 Reward: -200.0 Epsilon 0.1 mean q -16.664124\n",
      "Episode:  1592 Reward: -200.0 Epsilon 0.1 mean q -16.657696\n",
      "Episode:  1593 Reward: -200.0 Epsilon 0.1 mean q -16.677254\n",
      "Episode:  1594 Reward: -200.0 Epsilon 0.1 mean q -16.655518\n",
      "Episode:  1595 Reward: -200.0 Epsilon 0.1 mean q -16.639809\n",
      "Episode:  1596 Reward: -200.0 Epsilon 0.1 mean q -16.62371\n",
      "Episode:  1597 Reward: -200.0 Epsilon 0.1 mean q -16.639273\n",
      "Episode:  1598 Reward: -200.0 Epsilon 0.1 mean q -16.687906\n",
      "Episode:  1599 Reward: -200.0 Epsilon 0.1 mean q -16.677448\n",
      "Episode:  1600 Reward: -200.0 Epsilon 0.1 mean q -16.663616\n",
      "Episode:  1601 Reward: -200.0 Epsilon 0.1 mean q -16.647432\n",
      "Episode:  1602 Reward: -200.0 Epsilon 0.1 mean q -16.66765\n",
      "Episode:  1603 Reward: -200.0 Epsilon 0.1 mean q -16.652647\n",
      "Episode:  1604 Reward: -200.0 Epsilon 0.1 mean q -16.65847\n",
      "Episode:  1605 Reward: -200.0 Epsilon 0.1 mean q -16.718294\n",
      "Episode:  1606 Reward: -200.0 Epsilon 0.1 mean q -16.677557\n",
      "Episode:  1607 Reward: -200.0 Epsilon 0.1 mean q -16.671278\n",
      "Episode:  1608 Reward: -200.0 Epsilon 0.1 mean q -16.716146\n",
      "Episode:  1609 Reward: -200.0 Epsilon 0.1 mean q -16.649378\n",
      "Episode:  1610 Reward: -200.0 Epsilon 0.1 mean q -16.651766\n",
      "Episode:  1611 Reward: -200.0 Epsilon 0.1 mean q -16.705889\n",
      "Episode:  1612 Reward: -200.0 Epsilon 0.1 mean q -16.630632\n",
      "Episode:  1613 Reward: -200.0 Epsilon 0.1 mean q -16.678135\n",
      "Episode:  1614 Reward: -200.0 Epsilon 0.1 mean q -16.67358\n",
      "Episode:  1615 Reward: -200.0 Epsilon 0.1 mean q -16.648134\n",
      "Episode:  1616 Reward: -200.0 Epsilon 0.1 mean q -16.664993\n",
      "Episode:  1617 Reward: -200.0 Epsilon 0.1 mean q -16.680273\n",
      "Episode:  1618 Reward: -200.0 Epsilon 0.1 mean q -16.673727\n",
      "Episode:  1619 Reward: -200.0 Epsilon 0.1 mean q -16.648598\n",
      "Episode:  1620 Reward: -200.0 Epsilon 0.1 mean q -16.68031\n",
      "Episode:  1621 Reward: -200.0 Epsilon 0.1 mean q -16.670612\n",
      "Episode:  1622 Reward: -200.0 Epsilon 0.1 mean q -16.679724\n",
      "Episode:  1623 Reward: -200.0 Epsilon 0.1 mean q -16.696663\n",
      "Episode:  1624 Reward: -200.0 Epsilon 0.1 mean q -16.6538\n",
      "Episode:  1625 Reward: -200.0 Epsilon 0.1 mean q -16.671892\n",
      "Episode:  1626 Reward: -200.0 Epsilon 0.1 mean q -16.679375\n",
      "Episode:  1627 Reward: -200.0 Epsilon 0.1 mean q -16.648787\n",
      "Episode:  1628 Reward: -200.0 Epsilon 0.1 mean q -16.625221\n",
      "Episode:  1629 Reward: -200.0 Epsilon 0.1 mean q -16.652142\n",
      "Episode:  1630 Reward: -200.0 Epsilon 0.1 mean q -16.638033\n",
      "Episode:  1631 Reward: -200.0 Epsilon 0.1 mean q -16.647234\n",
      "Episode:  1632 Reward: -200.0 Epsilon 0.1 mean q -16.657032\n",
      "Episode:  1633 Reward: -200.0 Epsilon 0.1 mean q -16.691046\n",
      "Episode:  1634 Reward: -200.0 Epsilon 0.1 mean q -16.661057\n",
      "Episode:  1635 Reward: -200.0 Epsilon 0.1 mean q -16.66136\n",
      "Episode:  1636 Reward: -200.0 Epsilon 0.1 mean q -16.646824\n",
      "Episode:  1637 Reward: -200.0 Epsilon 0.1 mean q -16.67817\n",
      "Episode:  1638 Reward: -200.0 Epsilon 0.1 mean q -16.677181\n",
      "Episode:  1639 Reward: -200.0 Epsilon 0.1 mean q -16.67402\n",
      "Episode:  1640 Reward: -200.0 Epsilon 0.1 mean q -16.667168\n",
      "Episode:  1641 Reward: -200.0 Epsilon 0.1 mean q -16.667522\n",
      "Episode:  1642 Reward: -200.0 Epsilon 0.1 mean q -16.662544\n",
      "Episode:  1643 Reward: -200.0 Epsilon 0.1 mean q -16.700293\n",
      "Episode:  1644 Reward: -200.0 Epsilon 0.1 mean q -16.645884\n",
      "Episode:  1645 Reward: -200.0 Epsilon 0.1 mean q -16.647547\n",
      "Episode:  1646 Reward: -200.0 Epsilon 0.1 mean q -16.689838\n",
      "Episode:  1647 Reward: -200.0 Epsilon 0.1 mean q -16.692856\n",
      "Episode:  1648 Reward: -200.0 Epsilon 0.1 mean q -16.688166\n",
      "Episode:  1649 Reward: -200.0 Epsilon 0.1 mean q -16.638119\n",
      "Episode:  1650 Reward: -200.0 Epsilon 0.1 mean q -16.628796\n",
      "Episode:  1651 Reward: -200.0 Epsilon 0.1 mean q -16.66178\n",
      "Episode:  1652 Reward: -200.0 Epsilon 0.1 mean q -16.682556\n",
      "Episode:  1653 Reward: -200.0 Epsilon 0.1 mean q -16.64969\n",
      "Episode:  1654 Reward: -200.0 Epsilon 0.1 mean q -16.663658\n",
      "Episode:  1655 Reward: -200.0 Epsilon 0.1 mean q -16.658253\n",
      "Episode:  1656 Reward: -200.0 Epsilon 0.1 mean q -16.680387\n",
      "Episode:  1657 Reward: -200.0 Epsilon 0.1 mean q -16.693922\n",
      "Episode:  1658 Reward: -200.0 Epsilon 0.1 mean q -16.683561\n",
      "Episode:  1659 Reward: -200.0 Epsilon 0.1 mean q -16.65168\n",
      "Episode:  1660 Reward: -200.0 Epsilon 0.1 mean q -16.648933\n",
      "Episode:  1661 Reward: -200.0 Epsilon 0.1 mean q -16.629103\n",
      "Episode:  1662 Reward: -200.0 Epsilon 0.1 mean q -16.669142\n",
      "Episode:  1663 Reward: -200.0 Epsilon 0.1 mean q -16.642647\n",
      "Episode:  1664 Reward: -200.0 Epsilon 0.1 mean q -16.682592\n",
      "Episode:  1665 Reward: -200.0 Epsilon 0.1 mean q -16.634604\n",
      "Episode:  1666 Reward: -200.0 Epsilon 0.1 mean q -16.649723\n",
      "Episode:  1667 Reward: -200.0 Epsilon 0.1 mean q -16.648594\n",
      "Episode:  1668 Reward: -200.0 Epsilon 0.1 mean q -16.657127\n",
      "Episode:  1669 Reward: -200.0 Epsilon 0.1 mean q -16.670866\n",
      "Episode:  1670 Reward: -200.0 Epsilon 0.1 mean q -16.667439\n",
      "Episode:  1671 Reward: -200.0 Epsilon 0.1 mean q -16.687565\n",
      "Episode:  1672 Reward: -200.0 Epsilon 0.1 mean q -16.654568\n",
      "Episode:  1673 Reward: -200.0 Epsilon 0.1 mean q -16.679638\n",
      "Episode:  1674 Reward: -200.0 Epsilon 0.1 mean q -16.635918\n",
      "Episode:  1675 Reward: -200.0 Epsilon 0.1 mean q -16.651691\n",
      "Episode:  1676 Reward: -200.0 Epsilon 0.1 mean q -16.680693\n",
      "Episode:  1677 Reward: -200.0 Epsilon 0.1 mean q -16.669624\n",
      "Episode:  1678 Reward: -200.0 Epsilon 0.1 mean q -16.688707\n",
      "Episode:  1679 Reward: -200.0 Epsilon 0.1 mean q -16.660517\n",
      "Episode:  1680 Reward: -200.0 Epsilon 0.1 mean q -16.6466\n",
      "Episode:  1681 Reward: -200.0 Epsilon 0.1 mean q -16.664648\n",
      "Episode:  1682 Reward: -200.0 Epsilon 0.1 mean q -16.686247\n",
      "Episode:  1683 Reward: -200.0 Epsilon 0.1 mean q -16.700958\n",
      "Episode:  1684 Reward: -200.0 Epsilon 0.1 mean q -16.66359\n",
      "Episode:  1685 Reward: -200.0 Epsilon 0.1 mean q -16.65216\n",
      "Episode:  1686 Reward: -200.0 Epsilon 0.1 mean q -16.64682\n",
      "Episode:  1687 Reward: -200.0 Epsilon 0.1 mean q -16.690702\n",
      "Episode:  1688 Reward: -200.0 Epsilon 0.1 mean q -16.668854\n",
      "Episode:  1689 Reward: -200.0 Epsilon 0.1 mean q -16.690613\n",
      "Episode:  1690 Reward: -200.0 Epsilon 0.1 mean q -16.70615\n",
      "Episode:  1691 Reward: -200.0 Epsilon 0.1 mean q -16.657122\n",
      "Episode:  1692 Reward: -200.0 Epsilon 0.1 mean q -16.64923\n",
      "Episode:  1693 Reward: -200.0 Epsilon 0.1 mean q -16.645298\n",
      "Episode:  1694 Reward: -200.0 Epsilon 0.1 mean q -16.653782\n",
      "Episode:  1695 Reward: -200.0 Epsilon 0.1 mean q -16.642473\n",
      "Episode:  1696 Reward: -200.0 Epsilon 0.1 mean q -16.640656\n",
      "Episode:  1697 Reward: -200.0 Epsilon 0.1 mean q -16.668503\n",
      "Episode:  1698 Reward: -200.0 Epsilon 0.1 mean q -16.663347\n",
      "Episode:  1699 Reward: -200.0 Epsilon 0.1 mean q -16.658916\n",
      "Episode:  1700 Reward: -200.0 Epsilon 0.1 mean q -16.662022\n",
      "Episode:  1701 Reward: -200.0 Epsilon 0.1 mean q -16.649542\n",
      "Episode:  1702 Reward: -200.0 Epsilon 0.1 mean q -16.667463\n",
      "Episode:  1703 Reward: -200.0 Epsilon 0.1 mean q -16.68988\n",
      "Episode:  1704 Reward: -200.0 Epsilon 0.1 mean q -16.661278\n",
      "Episode:  1705 Reward: -200.0 Epsilon 0.1 mean q -16.638857\n",
      "Episode:  1706 Reward: -200.0 Epsilon 0.1 mean q -16.639421\n",
      "Episode:  1707 Reward: -200.0 Epsilon 0.1 mean q -16.678705\n",
      "Episode:  1708 Reward: -200.0 Epsilon 0.1 mean q -16.67393\n",
      "Episode:  1709 Reward: -200.0 Epsilon 0.1 mean q -16.67096\n",
      "Episode:  1710 Reward: -200.0 Epsilon 0.1 mean q -16.68163\n",
      "Episode:  1711 Reward: -200.0 Epsilon 0.1 mean q -16.656212\n",
      "Episode:  1712 Reward: -200.0 Epsilon 0.1 mean q -16.677643\n",
      "Episode:  1713 Reward: -200.0 Epsilon 0.1 mean q -16.686596\n",
      "Episode:  1714 Reward: -200.0 Epsilon 0.1 mean q -16.64623\n",
      "Episode:  1715 Reward: -200.0 Epsilon 0.1 mean q -16.655495\n",
      "Episode:  1716 Reward: -200.0 Epsilon 0.1 mean q -16.67187\n",
      "Episode:  1717 Reward: -200.0 Epsilon 0.1 mean q -16.685293\n",
      "Episode:  1718 Reward: -200.0 Epsilon 0.1 mean q -16.643421\n",
      "Episode:  1719 Reward: -200.0 Epsilon 0.1 mean q -16.681738\n",
      "Episode:  1720 Reward: -200.0 Epsilon 0.1 mean q -16.67769\n",
      "Episode:  1721 Reward: -200.0 Epsilon 0.1 mean q -16.68387\n",
      "Episode:  1722 Reward: -200.0 Epsilon 0.1 mean q -16.663256\n",
      "Episode:  1723 Reward: -200.0 Epsilon 0.1 mean q -16.650114\n",
      "Episode:  1724 Reward: -200.0 Epsilon 0.1 mean q -16.678204\n",
      "Episode:  1725 Reward: -200.0 Epsilon 0.1 mean q -16.644884\n",
      "Episode:  1726 Reward: -200.0 Epsilon 0.1 mean q -16.655088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1727 Reward: -200.0 Epsilon 0.1 mean q -16.676445\n",
      "Episode:  1728 Reward: -200.0 Epsilon 0.1 mean q -16.678932\n",
      "Episode:  1729 Reward: -200.0 Epsilon 0.1 mean q -16.709078\n",
      "Episode:  1730 Reward: -200.0 Epsilon 0.1 mean q -16.676085\n",
      "Episode:  1731 Reward: -200.0 Epsilon 0.1 mean q -16.636494\n",
      "Episode:  1732 Reward: -200.0 Epsilon 0.1 mean q -16.684727\n",
      "Episode:  1733 Reward: -200.0 Epsilon 0.1 mean q -16.638725\n",
      "Episode:  1734 Reward: -200.0 Epsilon 0.1 mean q -16.624529\n",
      "Episode:  1735 Reward: -200.0 Epsilon 0.1 mean q -16.630888\n",
      "Episode:  1736 Reward: -200.0 Epsilon 0.1 mean q -16.650774\n",
      "Episode:  1737 Reward: -200.0 Epsilon 0.1 mean q -16.669329\n",
      "Episode:  1738 Reward: -200.0 Epsilon 0.1 mean q -16.669504\n",
      "Episode:  1739 Reward: -200.0 Epsilon 0.1 mean q -16.669664\n",
      "Episode:  1740 Reward: -200.0 Epsilon 0.1 mean q -16.642813\n",
      "Episode:  1741 Reward: -200.0 Epsilon 0.1 mean q -16.701689\n",
      "Episode:  1742 Reward: -200.0 Epsilon 0.1 mean q -16.67572\n",
      "Episode:  1743 Reward: -200.0 Epsilon 0.1 mean q -16.645807\n",
      "Episode:  1744 Reward: -200.0 Epsilon 0.1 mean q -16.68291\n",
      "Episode:  1745 Reward: -200.0 Epsilon 0.1 mean q -16.694788\n",
      "Episode:  1746 Reward: -200.0 Epsilon 0.1 mean q -16.627043\n",
      "Episode:  1747 Reward: -200.0 Epsilon 0.1 mean q -16.648056\n",
      "Episode:  1748 Reward: -200.0 Epsilon 0.1 mean q -16.681223\n",
      "Episode:  1749 Reward: -200.0 Epsilon 0.1 mean q -16.67105\n",
      "Episode:  1750 Reward: -200.0 Epsilon 0.1 mean q -16.666222\n",
      "Episode:  1751 Reward: -200.0 Epsilon 0.1 mean q -16.667871\n",
      "Episode:  1752 Reward: -200.0 Epsilon 0.1 mean q -16.681204\n",
      "Episode:  1753 Reward: -200.0 Epsilon 0.1 mean q -16.688343\n",
      "Episode:  1754 Reward: -200.0 Epsilon 0.1 mean q -16.655674\n",
      "Episode:  1755 Reward: -200.0 Epsilon 0.1 mean q -16.703718\n",
      "Episode:  1756 Reward: -200.0 Epsilon 0.1 mean q -16.71471\n",
      "Episode:  1757 Reward: -200.0 Epsilon 0.1 mean q -16.702457\n",
      "Episode:  1758 Reward: -200.0 Epsilon 0.1 mean q -16.652838\n",
      "Episode:  1759 Reward: -200.0 Epsilon 0.1 mean q -16.65386\n",
      "Episode:  1760 Reward: -200.0 Epsilon 0.1 mean q -16.662785\n",
      "Episode:  1761 Reward: -200.0 Epsilon 0.1 mean q -16.679293\n",
      "Episode:  1762 Reward: -200.0 Epsilon 0.1 mean q -16.682411\n",
      "Episode:  1763 Reward: -200.0 Epsilon 0.1 mean q -16.67359\n",
      "Episode:  1764 Reward: -200.0 Epsilon 0.1 mean q -16.688213\n",
      "Episode:  1765 Reward: -200.0 Epsilon 0.1 mean q -16.678526\n",
      "Episode:  1766 Reward: -200.0 Epsilon 0.1 mean q -16.69705\n",
      "Episode:  1767 Reward: -200.0 Epsilon 0.1 mean q -16.697266\n",
      "Episode:  1768 Reward: -200.0 Epsilon 0.1 mean q -16.633131\n",
      "Episode:  1769 Reward: -200.0 Epsilon 0.1 mean q -16.706903\n",
      "Episode:  1770 Reward: -200.0 Epsilon 0.1 mean q -16.685593\n",
      "Episode:  1771 Reward: -200.0 Epsilon 0.1 mean q -16.685064\n",
      "Episode:  1772 Reward: -200.0 Epsilon 0.1 mean q -16.672846\n",
      "Episode:  1773 Reward: -200.0 Epsilon 0.1 mean q -16.657568\n",
      "Episode:  1774 Reward: -200.0 Epsilon 0.1 mean q -16.658243\n",
      "Episode:  1775 Reward: -200.0 Epsilon 0.1 mean q -16.665066\n",
      "Episode:  1776 Reward: -200.0 Epsilon 0.1 mean q -16.65763\n",
      "Episode:  1777 Reward: -200.0 Epsilon 0.1 mean q -16.707146\n",
      "Episode:  1778 Reward: -200.0 Epsilon 0.1 mean q -16.676523\n",
      "Episode:  1779 Reward: -200.0 Epsilon 0.1 mean q -16.6687\n",
      "Episode:  1780 Reward: -200.0 Epsilon 0.1 mean q -16.642534\n",
      "Episode:  1781 Reward: -200.0 Epsilon 0.1 mean q -16.68018\n",
      "Episode:  1782 Reward: -200.0 Epsilon 0.1 mean q -16.647675\n",
      "Episode:  1783 Reward: -200.0 Epsilon 0.1 mean q -16.722462\n",
      "Episode:  1784 Reward: -200.0 Epsilon 0.1 mean q -16.654547\n",
      "Episode:  1785 Reward: -200.0 Epsilon 0.1 mean q -16.678066\n",
      "Episode:  1786 Reward: -200.0 Epsilon 0.1 mean q -16.70944\n",
      "Episode:  1787 Reward: -200.0 Epsilon 0.1 mean q -16.703997\n",
      "Episode:  1788 Reward: -200.0 Epsilon 0.1 mean q -16.698586\n",
      "Episode:  1789 Reward: -200.0 Epsilon 0.1 mean q -16.672926\n",
      "Episode:  1790 Reward: -200.0 Epsilon 0.1 mean q -16.702618\n",
      "Episode:  1791 Reward: -200.0 Epsilon 0.1 mean q -16.654146\n",
      "Episode:  1792 Reward: -200.0 Epsilon 0.1 mean q -16.663553\n",
      "Episode:  1793 Reward: -200.0 Epsilon 0.1 mean q -16.673323\n",
      "Episode:  1794 Reward: -200.0 Epsilon 0.1 mean q -16.687204\n",
      "Episode:  1795 Reward: -200.0 Epsilon 0.1 mean q -16.65124\n",
      "Episode:  1796 Reward: -200.0 Epsilon 0.1 mean q -16.656225\n",
      "Episode:  1797 Reward: -200.0 Epsilon 0.1 mean q -16.66644\n",
      "Episode:  1798 Reward: -200.0 Epsilon 0.1 mean q -16.639456\n",
      "Episode:  1799 Reward: -200.0 Epsilon 0.1 mean q -16.65944\n",
      "Episode:  1800 Reward: -200.0 Epsilon 0.1 mean q -16.667587\n",
      "Episode:  1801 Reward: -200.0 Epsilon 0.1 mean q -16.67953\n",
      "Episode:  1802 Reward: -200.0 Epsilon 0.1 mean q -16.664291\n",
      "Episode:  1803 Reward: -200.0 Epsilon 0.1 mean q -16.648787\n",
      "Episode:  1804 Reward: -200.0 Epsilon 0.1 mean q -16.645557\n",
      "Episode:  1805 Reward: -200.0 Epsilon 0.1 mean q -16.689177\n",
      "Episode:  1806 Reward: -200.0 Epsilon 0.1 mean q -16.674625\n",
      "Episode:  1807 Reward: -200.0 Epsilon 0.1 mean q -16.67551\n",
      "Episode:  1808 Reward: -200.0 Epsilon 0.1 mean q -16.68667\n",
      "Episode:  1809 Reward: -200.0 Epsilon 0.1 mean q -16.667933\n",
      "Episode:  1810 Reward: -200.0 Epsilon 0.1 mean q -16.672281\n",
      "Episode:  1811 Reward: -200.0 Epsilon 0.1 mean q -16.687561\n",
      "Episode:  1812 Reward: -200.0 Epsilon 0.1 mean q -16.668446\n",
      "Episode:  1813 Reward: -200.0 Epsilon 0.1 mean q -16.70126\n",
      "Episode:  1814 Reward: -200.0 Epsilon 0.1 mean q -16.67046\n",
      "Episode:  1815 Reward: -200.0 Epsilon 0.1 mean q -16.632307\n",
      "Episode:  1816 Reward: -200.0 Epsilon 0.1 mean q -16.6716\n",
      "Episode:  1817 Reward: -200.0 Epsilon 0.1 mean q -16.676762\n",
      "Episode:  1818 Reward: -200.0 Epsilon 0.1 mean q -16.69494\n",
      "Episode:  1819 Reward: -200.0 Epsilon 0.1 mean q -16.682566\n",
      "Episode:  1820 Reward: -200.0 Epsilon 0.1 mean q -16.669205\n",
      "Episode:  1821 Reward: -200.0 Epsilon 0.1 mean q -16.648985\n",
      "Episode:  1822 Reward: -200.0 Epsilon 0.1 mean q -16.680328\n",
      "Episode:  1823 Reward: -200.0 Epsilon 0.1 mean q -16.631405\n",
      "Episode:  1824 Reward: -200.0 Epsilon 0.1 mean q -16.696133\n",
      "Episode:  1825 Reward: -200.0 Epsilon 0.1 mean q -16.683222\n",
      "Episode:  1826 Reward: -200.0 Epsilon 0.1 mean q -16.68563\n",
      "Episode:  1827 Reward: -200.0 Epsilon 0.1 mean q -16.659985\n",
      "Episode:  1828 Reward: -200.0 Epsilon 0.1 mean q -16.682264\n",
      "Episode:  1829 Reward: -200.0 Epsilon 0.1 mean q -16.688854\n",
      "Episode:  1830 Reward: -200.0 Epsilon 0.1 mean q -16.666471\n",
      "Episode:  1831 Reward: -200.0 Epsilon 0.1 mean q -16.684072\n",
      "Episode:  1832 Reward: -200.0 Epsilon 0.1 mean q -16.65236\n",
      "Episode:  1833 Reward: -200.0 Epsilon 0.1 mean q -16.665112\n",
      "Episode:  1834 Reward: -200.0 Epsilon 0.1 mean q -16.682262\n",
      "Episode:  1835 Reward: -200.0 Epsilon 0.1 mean q -16.646036\n",
      "Episode:  1836 Reward: -200.0 Epsilon 0.1 mean q -16.663025\n",
      "Episode:  1837 Reward: -200.0 Epsilon 0.1 mean q -16.658888\n",
      "Episode:  1838 Reward: -200.0 Epsilon 0.1 mean q -16.672136\n",
      "Episode:  1839 Reward: -200.0 Epsilon 0.1 mean q -16.667072\n",
      "Episode:  1840 Reward: -200.0 Epsilon 0.1 mean q -16.677109\n",
      "Episode:  1841 Reward: -200.0 Epsilon 0.1 mean q -16.69393\n",
      "Episode:  1842 Reward: -200.0 Epsilon 0.1 mean q -16.662592\n",
      "Episode:  1843 Reward: -200.0 Epsilon 0.1 mean q -16.68861\n",
      "Episode:  1844 Reward: -200.0 Epsilon 0.1 mean q -16.638197\n",
      "Episode:  1845 Reward: -200.0 Epsilon 0.1 mean q -16.672157\n",
      "Episode:  1846 Reward: -200.0 Epsilon 0.1 mean q -16.670538\n",
      "Episode:  1847 Reward: -200.0 Epsilon 0.1 mean q -16.641409\n",
      "Episode:  1848 Reward: -200.0 Epsilon 0.1 mean q -16.637505\n",
      "Episode:  1849 Reward: -200.0 Epsilon 0.1 mean q -16.663486\n",
      "Episode:  1850 Reward: -200.0 Epsilon 0.1 mean q -16.671593\n",
      "Episode:  1851 Reward: -200.0 Epsilon 0.1 mean q -16.680946\n",
      "Episode:  1852 Reward: -200.0 Epsilon 0.1 mean q -16.67837\n",
      "Episode:  1853 Reward: -200.0 Epsilon 0.1 mean q -16.667637\n",
      "Episode:  1854 Reward: -200.0 Epsilon 0.1 mean q -16.69073\n",
      "Episode:  1855 Reward: -200.0 Epsilon 0.1 mean q -16.666998\n",
      "Episode:  1856 Reward: -200.0 Epsilon 0.1 mean q -16.658457\n",
      "Episode:  1857 Reward: -200.0 Epsilon 0.1 mean q -16.66918\n",
      "Episode:  1858 Reward: -200.0 Epsilon 0.1 mean q -16.63044\n",
      "Episode:  1859 Reward: -200.0 Epsilon 0.1 mean q -16.689062\n",
      "Episode:  1860 Reward: -200.0 Epsilon 0.1 mean q -16.662882\n",
      "Episode:  1861 Reward: -200.0 Epsilon 0.1 mean q -16.662645\n",
      "Episode:  1862 Reward: -200.0 Epsilon 0.1 mean q -16.67049\n",
      "Episode:  1863 Reward: -200.0 Epsilon 0.1 mean q -16.667973\n",
      "Episode:  1864 Reward: -200.0 Epsilon 0.1 mean q -16.674555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1865 Reward: -200.0 Epsilon 0.1 mean q -16.633018\n",
      "Episode:  1866 Reward: -200.0 Epsilon 0.1 mean q -16.694994\n",
      "Episode:  1867 Reward: -200.0 Epsilon 0.1 mean q -16.624441\n",
      "Episode:  1868 Reward: -200.0 Epsilon 0.1 mean q -16.676025\n",
      "Episode:  1869 Reward: -200.0 Epsilon 0.1 mean q -16.673359\n",
      "Episode:  1870 Reward: -200.0 Epsilon 0.1 mean q -16.674692\n",
      "Episode:  1871 Reward: -200.0 Epsilon 0.1 mean q -16.683487\n",
      "Episode:  1872 Reward: -200.0 Epsilon 0.1 mean q -16.704088\n",
      "Episode:  1873 Reward: -200.0 Epsilon 0.1 mean q -16.682947\n",
      "Episode:  1874 Reward: -200.0 Epsilon 0.1 mean q -16.658133\n",
      "Episode:  1875 Reward: -200.0 Epsilon 0.1 mean q -16.671793\n",
      "Episode:  1876 Reward: -200.0 Epsilon 0.1 mean q -16.652657\n",
      "Episode:  1877 Reward: -200.0 Epsilon 0.1 mean q -16.697237\n",
      "Episode:  1878 Reward: -200.0 Epsilon 0.1 mean q -16.68766\n",
      "Episode:  1879 Reward: -200.0 Epsilon 0.1 mean q -16.687645\n",
      "Episode:  1880 Reward: -200.0 Epsilon 0.1 mean q -16.6924\n",
      "Episode:  1881 Reward: -200.0 Epsilon 0.1 mean q -16.66434\n",
      "Episode:  1882 Reward: -200.0 Epsilon 0.1 mean q -16.646702\n",
      "Episode:  1883 Reward: -200.0 Epsilon 0.1 mean q -16.674355\n",
      "Episode:  1884 Reward: -200.0 Epsilon 0.1 mean q -16.677748\n",
      "Episode:  1885 Reward: -200.0 Epsilon 0.1 mean q -16.683779\n",
      "Episode:  1886 Reward: -200.0 Epsilon 0.1 mean q -16.6932\n",
      "Episode:  1887 Reward: -200.0 Epsilon 0.1 mean q -16.667698\n",
      "Episode:  1888 Reward: -200.0 Epsilon 0.1 mean q -16.634562\n",
      "Episode:  1889 Reward: -200.0 Epsilon 0.1 mean q -16.673878\n",
      "Episode:  1890 Reward: -200.0 Epsilon 0.1 mean q -16.66313\n",
      "Episode:  1891 Reward: -200.0 Epsilon 0.1 mean q -16.698248\n",
      "Episode:  1892 Reward: -200.0 Epsilon 0.1 mean q -16.679392\n",
      "Episode:  1893 Reward: -200.0 Epsilon 0.1 mean q -16.687449\n",
      "Episode:  1894 Reward: -200.0 Epsilon 0.1 mean q -16.641356\n",
      "Episode:  1895 Reward: -200.0 Epsilon 0.1 mean q -16.643463\n",
      "Episode:  1896 Reward: -200.0 Epsilon 0.1 mean q -16.657078\n",
      "Episode:  1897 Reward: -200.0 Epsilon 0.1 mean q -16.668682\n",
      "Episode:  1898 Reward: -200.0 Epsilon 0.1 mean q -16.682035\n",
      "Episode:  1899 Reward: -200.0 Epsilon 0.1 mean q -16.668734\n",
      "Episode:  1900 Reward: -200.0 Epsilon 0.1 mean q -16.652966\n",
      "Episode:  1901 Reward: -200.0 Epsilon 0.1 mean q -16.68612\n",
      "Episode:  1902 Reward: -200.0 Epsilon 0.1 mean q -16.675072\n",
      "Episode:  1903 Reward: -200.0 Epsilon 0.1 mean q -16.64419\n",
      "Episode:  1904 Reward: -200.0 Epsilon 0.1 mean q -16.665098\n",
      "Episode:  1905 Reward: -200.0 Epsilon 0.1 mean q -16.67322\n",
      "Episode:  1906 Reward: -200.0 Epsilon 0.1 mean q -16.64677\n",
      "Episode:  1907 Reward: -200.0 Epsilon 0.1 mean q -16.696465\n",
      "Episode:  1908 Reward: -200.0 Epsilon 0.1 mean q -16.69406\n",
      "Episode:  1909 Reward: -200.0 Epsilon 0.1 mean q -16.618351\n",
      "Episode:  1910 Reward: -200.0 Epsilon 0.1 mean q -16.658798\n",
      "Episode:  1911 Reward: -200.0 Epsilon 0.1 mean q -16.646425\n",
      "Episode:  1912 Reward: -200.0 Epsilon 0.1 mean q -16.657318\n",
      "Episode:  1913 Reward: -200.0 Epsilon 0.1 mean q -16.672113\n",
      "Episode:  1914 Reward: -200.0 Epsilon 0.1 mean q -16.676674\n",
      "Episode:  1915 Reward: -200.0 Epsilon 0.1 mean q -16.639942\n",
      "Episode:  1916 Reward: -200.0 Epsilon 0.1 mean q -16.64186\n",
      "Episode:  1917 Reward: -200.0 Epsilon 0.1 mean q -16.672506\n",
      "Episode:  1918 Reward: -200.0 Epsilon 0.1 mean q -16.631868\n",
      "Episode:  1919 Reward: -200.0 Epsilon 0.1 mean q -16.67608\n",
      "Episode:  1920 Reward: -200.0 Epsilon 0.1 mean q -16.670729\n",
      "Episode:  1921 Reward: -200.0 Epsilon 0.1 mean q -16.683496\n",
      "Episode:  1922 Reward: -200.0 Epsilon 0.1 mean q -16.647123\n",
      "Episode:  1923 Reward: -200.0 Epsilon 0.1 mean q -16.637981\n",
      "Episode:  1924 Reward: -200.0 Epsilon 0.1 mean q -16.685177\n",
      "Episode:  1925 Reward: -200.0 Epsilon 0.1 mean q -16.67397\n",
      "Episode:  1926 Reward: -200.0 Epsilon 0.1 mean q -16.657804\n",
      "Episode:  1927 Reward: -200.0 Epsilon 0.1 mean q -16.729897\n",
      "Episode:  1928 Reward: -200.0 Epsilon 0.1 mean q -16.681095\n",
      "Episode:  1929 Reward: -200.0 Epsilon 0.1 mean q -16.660378\n",
      "Episode:  1930 Reward: -200.0 Epsilon 0.1 mean q -16.647224\n",
      "Episode:  1931 Reward: -200.0 Epsilon 0.1 mean q -16.670372\n",
      "Episode:  1932 Reward: -200.0 Epsilon 0.1 mean q -16.642141\n",
      "Episode:  1933 Reward: -200.0 Epsilon 0.1 mean q -16.679108\n",
      "Episode:  1934 Reward: -200.0 Epsilon 0.1 mean q -16.672825\n",
      "Episode:  1935 Reward: -200.0 Epsilon 0.1 mean q -16.656725\n",
      "Episode:  1936 Reward: -200.0 Epsilon 0.1 mean q -16.64079\n",
      "Episode:  1937 Reward: -200.0 Epsilon 0.1 mean q -16.681974\n",
      "Episode:  1938 Reward: -200.0 Epsilon 0.1 mean q -16.645485\n",
      "Episode:  1939 Reward: -200.0 Epsilon 0.1 mean q -16.70139\n",
      "Episode:  1940 Reward: -200.0 Epsilon 0.1 mean q -16.668274\n",
      "Episode:  1941 Reward: -200.0 Epsilon 0.1 mean q -16.665218\n",
      "Episode:  1942 Reward: -200.0 Epsilon 0.1 mean q -16.69194\n",
      "Episode:  1943 Reward: -200.0 Epsilon 0.1 mean q -16.708698\n",
      "Episode:  1944 Reward: -200.0 Epsilon 0.1 mean q -16.667038\n",
      "Episode:  1945 Reward: -200.0 Epsilon 0.1 mean q -16.636925\n",
      "Episode:  1946 Reward: -200.0 Epsilon 0.1 mean q -16.664175\n",
      "Episode:  1947 Reward: -200.0 Epsilon 0.1 mean q -16.674221\n",
      "Episode:  1948 Reward: -200.0 Epsilon 0.1 mean q -16.641464\n",
      "Episode:  1949 Reward: -200.0 Epsilon 0.1 mean q -16.639248\n",
      "Episode:  1950 Reward: -200.0 Epsilon 0.1 mean q -16.676882\n",
      "Episode:  1951 Reward: -200.0 Epsilon 0.1 mean q -16.667948\n",
      "Episode:  1952 Reward: -200.0 Epsilon 0.1 mean q -16.678936\n",
      "Episode:  1953 Reward: -200.0 Epsilon 0.1 mean q -16.695456\n",
      "Episode:  1954 Reward: -200.0 Epsilon 0.1 mean q -16.64275\n",
      "Episode:  1955 Reward: -200.0 Epsilon 0.1 mean q -16.680134\n",
      "Episode:  1956 Reward: -200.0 Epsilon 0.1 mean q -16.667048\n",
      "Episode:  1957 Reward: -200.0 Epsilon 0.1 mean q -16.692762\n",
      "Episode:  1958 Reward: -200.0 Epsilon 0.1 mean q -16.684908\n",
      "Episode:  1959 Reward: -200.0 Epsilon 0.1 mean q -16.641794\n",
      "Episode:  1960 Reward: -200.0 Epsilon 0.1 mean q -16.657963\n",
      "Episode:  1961 Reward: -200.0 Epsilon 0.1 mean q -16.652826\n",
      "Episode:  1962 Reward: -200.0 Epsilon 0.1 mean q -16.66406\n",
      "Episode:  1963 Reward: -200.0 Epsilon 0.1 mean q -16.665823\n",
      "Episode:  1964 Reward: -200.0 Epsilon 0.1 mean q -16.67312\n",
      "Episode:  1965 Reward: -200.0 Epsilon 0.1 mean q -16.684916\n",
      "Episode:  1966 Reward: -200.0 Epsilon 0.1 mean q -16.645752\n",
      "Episode:  1967 Reward: -200.0 Epsilon 0.1 mean q -16.66415\n",
      "Episode:  1968 Reward: -200.0 Epsilon 0.1 mean q -16.66111\n",
      "Episode:  1969 Reward: -200.0 Epsilon 0.1 mean q -16.662361\n",
      "Episode:  1970 Reward: -200.0 Epsilon 0.1 mean q -16.680283\n",
      "Episode:  1971 Reward: -200.0 Epsilon 0.1 mean q -16.691748\n",
      "Episode:  1972 Reward: -200.0 Epsilon 0.1 mean q -16.65209\n",
      "Episode:  1973 Reward: -200.0 Epsilon 0.1 mean q -16.686966\n",
      "Episode:  1974 Reward: -200.0 Epsilon 0.1 mean q -16.657454\n",
      "Episode:  1975 Reward: -200.0 Epsilon 0.1 mean q -16.655664\n",
      "Episode:  1976 Reward: -200.0 Epsilon 0.1 mean q -16.680403\n",
      "Episode:  1977 Reward: -200.0 Epsilon 0.1 mean q -16.616993\n",
      "Episode:  1978 Reward: -200.0 Epsilon 0.1 mean q -16.65093\n",
      "Episode:  1979 Reward: -200.0 Epsilon 0.1 mean q -16.631289\n",
      "Episode:  1980 Reward: -200.0 Epsilon 0.1 mean q -16.690197\n",
      "Episode:  1981 Reward: -200.0 Epsilon 0.1 mean q -16.678518\n",
      "Episode:  1982 Reward: -200.0 Epsilon 0.1 mean q -16.672207\n",
      "Episode:  1983 Reward: -200.0 Epsilon 0.1 mean q -16.643326\n",
      "Episode:  1984 Reward: -200.0 Epsilon 0.1 mean q -16.64843\n",
      "Episode:  1985 Reward: -200.0 Epsilon 0.1 mean q -16.675255\n",
      "Episode:  1986 Reward: -200.0 Epsilon 0.1 mean q -16.659906\n",
      "Episode:  1987 Reward: -200.0 Epsilon 0.1 mean q -16.667725\n",
      "Episode:  1988 Reward: -200.0 Epsilon 0.1 mean q -16.666807\n",
      "Episode:  1989 Reward: -200.0 Epsilon 0.1 mean q -16.66811\n",
      "Episode:  1990 Reward: -200.0 Epsilon 0.1 mean q -16.646973\n",
      "Episode:  1991 Reward: -200.0 Epsilon 0.1 mean q -16.672272\n",
      "Episode:  1992 Reward: -200.0 Epsilon 0.1 mean q -16.67734\n",
      "Episode:  1993 Reward: -200.0 Epsilon 0.1 mean q -16.667223\n",
      "Episode:  1994 Reward: -200.0 Epsilon 0.1 mean q -16.663452\n",
      "Episode:  1995 Reward: -200.0 Epsilon 0.1 mean q -16.679863\n",
      "Episode:  1996 Reward: -200.0 Epsilon 0.1 mean q -16.72222\n",
      "Episode:  1997 Reward: -200.0 Epsilon 0.1 mean q -16.671534\n",
      "Episode:  1998 Reward: -200.0 Epsilon 0.1 mean q -16.680853\n",
      "Episode:  1999 Reward: -200.0 Epsilon 0.1 mean q -16.668125\n",
      "Episode:  2000 Reward: -200.0 Epsilon 0.1 mean q -16.700453\n",
      "Episode:  2001 Reward: -200.0 Epsilon 0.1 mean q -16.640202\n",
      "Episode:  2002 Reward: -200.0 Epsilon 0.1 mean q -16.655468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  2003 Reward: -200.0 Epsilon 0.1 mean q -16.664068\n",
      "Episode:  2004 Reward: -200.0 Epsilon 0.1 mean q -16.654747\n",
      "Episode:  2005 Reward: -200.0 Epsilon 0.1 mean q -16.643957\n",
      "Episode:  2006 Reward: -200.0 Epsilon 0.1 mean q -16.670033\n",
      "Episode:  2007 Reward: -200.0 Epsilon 0.1 mean q -16.668484\n",
      "Episode:  2008 Reward: -200.0 Epsilon 0.1 mean q -16.65754\n",
      "Episode:  2009 Reward: -200.0 Epsilon 0.1 mean q -16.672327\n",
      "Episode:  2010 Reward: -200.0 Epsilon 0.1 mean q -16.659771\n",
      "Episode:  2011 Reward: -200.0 Epsilon 0.1 mean q -16.653872\n",
      "Episode:  2012 Reward: -200.0 Epsilon 0.1 mean q -16.712437\n",
      "Episode:  2013 Reward: -200.0 Epsilon 0.1 mean q -16.654236\n",
      "Episode:  2014 Reward: -200.0 Epsilon 0.1 mean q -16.631586\n",
      "Episode:  2015 Reward: -200.0 Epsilon 0.1 mean q -16.650663\n",
      "Episode:  2016 Reward: -200.0 Epsilon 0.1 mean q -16.664375\n",
      "Episode:  2017 Reward: -200.0 Epsilon 0.1 mean q -16.674164\n",
      "Episode:  2018 Reward: -200.0 Epsilon 0.1 mean q -16.627483\n",
      "Episode:  2019 Reward: -200.0 Epsilon 0.1 mean q -16.674145\n",
      "Episode:  2020 Reward: -200.0 Epsilon 0.1 mean q -16.688816\n",
      "Episode:  2021 Reward: -200.0 Epsilon 0.1 mean q -16.675642\n",
      "Episode:  2022 Reward: -200.0 Epsilon 0.1 mean q -16.625364\n",
      "Episode:  2023 Reward: -200.0 Epsilon 0.1 mean q -16.67693\n",
      "Episode:  2024 Reward: -200.0 Epsilon 0.1 mean q -16.681623\n",
      "Episode:  2025 Reward: -200.0 Epsilon 0.1 mean q -16.661196\n",
      "Episode:  2026 Reward: -200.0 Epsilon 0.1 mean q -16.677343\n",
      "Episode:  2027 Reward: -200.0 Epsilon 0.1 mean q -16.664206\n",
      "Episode:  2028 Reward: -200.0 Epsilon 0.1 mean q -16.685244\n",
      "Episode:  2029 Reward: -200.0 Epsilon 0.1 mean q -16.676453\n",
      "Episode:  2030 Reward: -200.0 Epsilon 0.1 mean q -16.69392\n",
      "Episode:  2031 Reward: -200.0 Epsilon 0.1 mean q -16.672028\n",
      "Episode:  2032 Reward: -200.0 Epsilon 0.1 mean q -16.66832\n",
      "Episode:  2033 Reward: -200.0 Epsilon 0.1 mean q -16.718437\n",
      "Episode:  2034 Reward: -200.0 Epsilon 0.1 mean q -16.654354\n",
      "Episode:  2035 Reward: -200.0 Epsilon 0.1 mean q -16.667349\n",
      "Episode:  2036 Reward: -200.0 Epsilon 0.1 mean q -16.666103\n",
      "Episode:  2037 Reward: -200.0 Epsilon 0.1 mean q -16.694935\n",
      "Episode:  2038 Reward: -200.0 Epsilon 0.1 mean q -16.664326\n",
      "Episode:  2039 Reward: -200.0 Epsilon 0.1 mean q -16.648987\n",
      "Episode:  2040 Reward: -200.0 Epsilon 0.1 mean q -16.65466\n",
      "Episode:  2041 Reward: -200.0 Epsilon 0.1 mean q -16.661608\n",
      "Episode:  2042 Reward: -200.0 Epsilon 0.1 mean q -16.64045\n",
      "Episode:  2043 Reward: -200.0 Epsilon 0.1 mean q -16.682537\n",
      "Episode:  2044 Reward: -200.0 Epsilon 0.1 mean q -16.682297\n",
      "Episode:  2045 Reward: -200.0 Epsilon 0.1 mean q -16.691051\n",
      "Episode:  2046 Reward: -200.0 Epsilon 0.1 mean q -16.643183\n",
      "Episode:  2047 Reward: -200.0 Epsilon 0.1 mean q -16.687895\n",
      "Episode:  2048 Reward: -200.0 Epsilon 0.1 mean q -16.64523\n",
      "Episode:  2049 Reward: -200.0 Epsilon 0.1 mean q -16.654423\n",
      "Episode:  2050 Reward: -200.0 Epsilon 0.1 mean q -16.708288\n",
      "Episode:  2051 Reward: -200.0 Epsilon 0.1 mean q -16.672165\n",
      "Episode:  2052 Reward: -200.0 Epsilon 0.1 mean q -16.668262\n",
      "Episode:  2053 Reward: -200.0 Epsilon 0.1 mean q -16.656431\n",
      "Episode:  2054 Reward: -200.0 Epsilon 0.1 mean q -16.644053\n",
      "Episode:  2055 Reward: -200.0 Epsilon 0.1 mean q -16.669916\n",
      "Episode:  2056 Reward: -200.0 Epsilon 0.1 mean q -16.666061\n",
      "Episode:  2057 Reward: -200.0 Epsilon 0.1 mean q -16.65372\n",
      "Episode:  2058 Reward: -200.0 Epsilon 0.1 mean q -16.658695\n",
      "Episode:  2059 Reward: -200.0 Epsilon 0.1 mean q -16.686596\n",
      "Episode:  2060 Reward: -200.0 Epsilon 0.1 mean q -16.648083\n",
      "Episode:  2061 Reward: -200.0 Epsilon 0.1 mean q -16.643684\n",
      "Episode:  2062 Reward: -200.0 Epsilon 0.1 mean q -16.665844\n",
      "Episode:  2063 Reward: -200.0 Epsilon 0.1 mean q -16.636364\n",
      "Episode:  2064 Reward: -200.0 Epsilon 0.1 mean q -16.652052\n",
      "Episode:  2065 Reward: -200.0 Epsilon 0.1 mean q -16.654648\n",
      "Episode:  2066 Reward: -200.0 Epsilon 0.1 mean q -16.652723\n",
      "Episode:  2067 Reward: -200.0 Epsilon 0.1 mean q -16.698545\n",
      "Episode:  2068 Reward: -200.0 Epsilon 0.1 mean q -16.660013\n",
      "Episode:  2069 Reward: -200.0 Epsilon 0.1 mean q -16.663391\n",
      "Episode:  2070 Reward: -200.0 Epsilon 0.1 mean q -16.689075\n",
      "Episode:  2071 Reward: -200.0 Epsilon 0.1 mean q -16.693077\n",
      "Episode:  2072 Reward: -200.0 Epsilon 0.1 mean q -16.66097\n",
      "Episode:  2073 Reward: -200.0 Epsilon 0.1 mean q -16.659485\n",
      "Episode:  2074 Reward: -200.0 Epsilon 0.1 mean q -16.637999\n",
      "Episode:  2075 Reward: -200.0 Epsilon 0.1 mean q -16.64\n",
      "Episode:  2076 Reward: -200.0 Epsilon 0.1 mean q -16.636553\n",
      "Episode:  2077 Reward: -200.0 Epsilon 0.1 mean q -16.678328\n",
      "Episode:  2078 Reward: -200.0 Epsilon 0.1 mean q -16.667456\n",
      "Episode:  2079 Reward: -200.0 Epsilon 0.1 mean q -16.681503\n",
      "Episode:  2080 Reward: -200.0 Epsilon 0.1 mean q -16.661839\n",
      "Episode:  2081 Reward: -200.0 Epsilon 0.1 mean q -16.678663\n",
      "Episode:  2082 Reward: -200.0 Epsilon 0.1 mean q -16.67732\n",
      "Episode:  2083 Reward: -200.0 Epsilon 0.1 mean q -16.6642\n",
      "Episode:  2084 Reward: -200.0 Epsilon 0.1 mean q -16.66704\n",
      "Episode:  2085 Reward: -200.0 Epsilon 0.1 mean q -16.662169\n",
      "Episode:  2086 Reward: -200.0 Epsilon 0.1 mean q -16.700243\n",
      "Episode:  2087 Reward: -200.0 Epsilon 0.1 mean q -16.684969\n",
      "Episode:  2088 Reward: -200.0 Epsilon 0.1 mean q -16.678242\n",
      "Episode:  2089 Reward: -200.0 Epsilon 0.1 mean q -16.665472\n",
      "Episode:  2090 Reward: -200.0 Epsilon 0.1 mean q -16.683453\n",
      "Episode:  2091 Reward: -200.0 Epsilon 0.1 mean q -16.673662\n",
      "Episode:  2092 Reward: -200.0 Epsilon 0.1 mean q -16.67904\n",
      "Episode:  2093 Reward: -200.0 Epsilon 0.1 mean q -16.651344\n",
      "Episode:  2094 Reward: -200.0 Epsilon 0.1 mean q -16.667955\n",
      "Episode:  2095 Reward: -200.0 Epsilon 0.1 mean q -16.649057\n",
      "Episode:  2096 Reward: -200.0 Epsilon 0.1 mean q -16.663177\n",
      "Episode:  2097 Reward: -200.0 Epsilon 0.1 mean q -16.65333\n",
      "Episode:  2098 Reward: -200.0 Epsilon 0.1 mean q -16.679916\n",
      "Episode:  2099 Reward: -200.0 Epsilon 0.1 mean q -16.645992\n",
      "Episode:  2100 Reward: -200.0 Epsilon 0.1 mean q -16.662382\n",
      "Episode:  2101 Reward: -200.0 Epsilon 0.1 mean q -16.683437\n",
      "Episode:  2102 Reward: -200.0 Epsilon 0.1 mean q -16.668697\n",
      "Episode:  2103 Reward: -200.0 Epsilon 0.1 mean q -16.69038\n",
      "Episode:  2104 Reward: -200.0 Epsilon 0.1 mean q -16.646338\n",
      "Episode:  2105 Reward: -200.0 Epsilon 0.1 mean q -16.679958\n",
      "Episode:  2106 Reward: -200.0 Epsilon 0.1 mean q -16.680882\n",
      "Episode:  2107 Reward: -200.0 Epsilon 0.1 mean q -16.634752\n",
      "Episode:  2108 Reward: -200.0 Epsilon 0.1 mean q -16.657112\n",
      "Episode:  2109 Reward: -200.0 Epsilon 0.1 mean q -16.6481\n",
      "Episode:  2110 Reward: -200.0 Epsilon 0.1 mean q -16.667063\n",
      "Episode:  2111 Reward: -200.0 Epsilon 0.1 mean q -16.69613\n",
      "Episode:  2112 Reward: -200.0 Epsilon 0.1 mean q -16.667841\n",
      "Episode:  2113 Reward: -200.0 Epsilon 0.1 mean q -16.657839\n",
      "Episode:  2114 Reward: -200.0 Epsilon 0.1 mean q -16.702642\n",
      "Episode:  2115 Reward: -200.0 Epsilon 0.1 mean q -16.6528\n",
      "Episode:  2116 Reward: -200.0 Epsilon 0.1 mean q -16.668385\n",
      "Episode:  2117 Reward: -200.0 Epsilon 0.1 mean q -16.673885\n",
      "Episode:  2118 Reward: -200.0 Epsilon 0.1 mean q -16.640162\n",
      "Episode:  2119 Reward: -200.0 Epsilon 0.1 mean q -16.667763\n",
      "Episode:  2120 Reward: -200.0 Epsilon 0.1 mean q -16.681341\n",
      "Episode:  2121 Reward: -200.0 Epsilon 0.1 mean q -16.683096\n",
      "Episode:  2122 Reward: -200.0 Epsilon 0.1 mean q -16.681309\n",
      "Episode:  2123 Reward: -200.0 Epsilon 0.1 mean q -16.651882\n",
      "Episode:  2124 Reward: -200.0 Epsilon 0.1 mean q -16.697588\n",
      "Episode:  2125 Reward: -200.0 Epsilon 0.1 mean q -16.663832\n",
      "Episode:  2126 Reward: -200.0 Epsilon 0.1 mean q -16.633131\n",
      "Episode:  2127 Reward: -200.0 Epsilon 0.1 mean q -16.65529\n",
      "Episode:  2128 Reward: -200.0 Epsilon 0.1 mean q -16.699343\n",
      "Episode:  2129 Reward: -200.0 Epsilon 0.1 mean q -16.652449\n",
      "Episode:  2130 Reward: -200.0 Epsilon 0.1 mean q -16.673645\n",
      "Episode:  2131 Reward: -200.0 Epsilon 0.1 mean q -16.643808\n",
      "Episode:  2132 Reward: -200.0 Epsilon 0.1 mean q -16.67674\n",
      "Episode:  2133 Reward: -200.0 Epsilon 0.1 mean q -16.655813\n",
      "Episode:  2134 Reward: -200.0 Epsilon 0.1 mean q -16.676542\n",
      "Episode:  2135 Reward: -200.0 Epsilon 0.1 mean q -16.665653\n",
      "Episode:  2136 Reward: -200.0 Epsilon 0.1 mean q -16.672216\n",
      "Episode:  2137 Reward: -200.0 Epsilon 0.1 mean q -16.634727\n",
      "Episode:  2138 Reward: -200.0 Epsilon 0.1 mean q -16.693607\n",
      "Episode:  2139 Reward: -200.0 Epsilon 0.1 mean q -16.632914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  2140 Reward: -200.0 Epsilon 0.1 mean q -16.668262\n",
      "Episode:  2141 Reward: -200.0 Epsilon 0.1 mean q -16.683329\n",
      "Episode:  2142 Reward: -200.0 Epsilon 0.1 mean q -16.67945\n",
      "Episode:  2143 Reward: -200.0 Epsilon 0.1 mean q -16.690811\n",
      "Episode:  2144 Reward: -200.0 Epsilon 0.1 mean q -16.697311\n",
      "Episode:  2145 Reward: -200.0 Epsilon 0.1 mean q -16.643393\n",
      "Episode:  2146 Reward: -200.0 Epsilon 0.1 mean q -16.666601\n",
      "Episode:  2147 Reward: -200.0 Epsilon 0.1 mean q -16.672407\n",
      "Episode:  2148 Reward: -200.0 Epsilon 0.1 mean q -16.671692\n",
      "Episode:  2149 Reward: -200.0 Epsilon 0.1 mean q -16.697796\n",
      "Episode:  2150 Reward: -200.0 Epsilon 0.1 mean q -16.660967\n",
      "Episode:  2151 Reward: -200.0 Epsilon 0.1 mean q -16.695442\n",
      "Episode:  2152 Reward: -200.0 Epsilon 0.1 mean q -16.655973\n",
      "Episode:  2153 Reward: -200.0 Epsilon 0.1 mean q -16.650496\n",
      "Episode:  2154 Reward: -200.0 Epsilon 0.1 mean q -16.652037\n",
      "Episode:  2155 Reward: -200.0 Epsilon 0.1 mean q -16.670048\n",
      "Episode:  2156 Reward: -200.0 Epsilon 0.1 mean q -16.69979\n",
      "Episode:  2157 Reward: -200.0 Epsilon 0.1 mean q -16.666048\n",
      "Episode:  2158 Reward: -200.0 Epsilon 0.1 mean q -16.694975\n",
      "Episode:  2159 Reward: -200.0 Epsilon 0.1 mean q -16.66653\n",
      "Episode:  2160 Reward: -200.0 Epsilon 0.1 mean q -16.688421\n",
      "Episode:  2161 Reward: -200.0 Epsilon 0.1 mean q -16.671402\n",
      "Episode:  2162 Reward: -200.0 Epsilon 0.1 mean q -16.65592\n",
      "Episode:  2163 Reward: -200.0 Epsilon 0.1 mean q -16.632738\n",
      "Episode:  2164 Reward: -200.0 Epsilon 0.1 mean q -16.653646\n",
      "Episode:  2165 Reward: -200.0 Epsilon 0.1 mean q -16.647585\n",
      "Episode:  2166 Reward: -200.0 Epsilon 0.1 mean q -16.637604\n",
      "Episode:  2167 Reward: -200.0 Epsilon 0.1 mean q -16.649488\n",
      "Episode:  2168 Reward: -200.0 Epsilon 0.1 mean q -16.675537\n",
      "Episode:  2169 Reward: -200.0 Epsilon 0.1 mean q -16.666077\n",
      "Episode:  2170 Reward: -200.0 Epsilon 0.1 mean q -16.699013\n",
      "Episode:  2171 Reward: -200.0 Epsilon 0.1 mean q -16.66475\n",
      "Episode:  2172 Reward: -200.0 Epsilon 0.1 mean q -16.662088\n",
      "Episode:  2173 Reward: -200.0 Epsilon 0.1 mean q -16.66602\n",
      "Episode:  2174 Reward: -200.0 Epsilon 0.1 mean q -16.655375\n",
      "Episode:  2175 Reward: -200.0 Epsilon 0.1 mean q -16.635181\n",
      "Episode:  2176 Reward: -200.0 Epsilon 0.1 mean q -16.666248\n",
      "Episode:  2177 Reward: -200.0 Epsilon 0.1 mean q -16.670666\n",
      "Episode:  2178 Reward: -200.0 Epsilon 0.1 mean q -16.673506\n",
      "Episode:  2179 Reward: -200.0 Epsilon 0.1 mean q -16.685719\n",
      "Episode:  2180 Reward: -200.0 Epsilon 0.1 mean q -16.663292\n",
      "Episode:  2181 Reward: -200.0 Epsilon 0.1 mean q -16.665478\n",
      "Episode:  2182 Reward: -200.0 Epsilon 0.1 mean q -16.699873\n",
      "Episode:  2183 Reward: -200.0 Epsilon 0.1 mean q -16.659441\n",
      "Episode:  2184 Reward: -200.0 Epsilon 0.1 mean q -16.674782\n",
      "Episode:  2185 Reward: -200.0 Epsilon 0.1 mean q -16.652357\n",
      "Episode:  2186 Reward: -200.0 Epsilon 0.1 mean q -16.638157\n",
      "Episode:  2187 Reward: -200.0 Epsilon 0.1 mean q -16.671703\n",
      "Episode:  2188 Reward: -200.0 Epsilon 0.1 mean q -16.646278\n",
      "Episode:  2189 Reward: -200.0 Epsilon 0.1 mean q -16.661207\n",
      "Episode:  2190 Reward: -200.0 Epsilon 0.1 mean q -16.676126\n",
      "Episode:  2191 Reward: -200.0 Epsilon 0.1 mean q -16.647154\n",
      "Episode:  2192 Reward: -200.0 Epsilon 0.1 mean q -16.646418\n",
      "Episode:  2193 Reward: -200.0 Epsilon 0.1 mean q -16.693766\n",
      "Episode:  2194 Reward: -200.0 Epsilon 0.1 mean q -16.655346\n",
      "Episode:  2195 Reward: -200.0 Epsilon 0.1 mean q -16.654547\n",
      "Episode:  2196 Reward: -200.0 Epsilon 0.1 mean q -16.696262\n",
      "Episode:  2197 Reward: -200.0 Epsilon 0.1 mean q -16.645403\n",
      "Episode:  2198 Reward: -200.0 Epsilon 0.1 mean q -16.64821\n",
      "Episode:  2199 Reward: -200.0 Epsilon 0.1 mean q -16.68193\n",
      "Episode:  2200 Reward: -200.0 Epsilon 0.1 mean q -16.680126\n",
      "Episode:  2201 Reward: -200.0 Epsilon 0.1 mean q -16.654646\n",
      "Episode:  2202 Reward: -200.0 Epsilon 0.1 mean q -16.632784\n",
      "Episode:  2203 Reward: -200.0 Epsilon 0.1 mean q -16.667742\n",
      "Episode:  2204 Reward: -200.0 Epsilon 0.1 mean q -16.647526\n",
      "Episode:  2205 Reward: -200.0 Epsilon 0.1 mean q -16.655954\n",
      "Episode:  2206 Reward: -200.0 Epsilon 0.1 mean q -16.64349\n",
      "Episode:  2207 Reward: -200.0 Epsilon 0.1 mean q -16.65906\n",
      "Episode:  2208 Reward: -200.0 Epsilon 0.1 mean q -16.666807\n",
      "Episode:  2209 Reward: -200.0 Epsilon 0.1 mean q -16.671045\n",
      "Episode:  2210 Reward: -200.0 Epsilon 0.1 mean q -16.70722\n",
      "Episode:  2211 Reward: -200.0 Epsilon 0.1 mean q -16.64296\n",
      "Episode:  2212 Reward: -200.0 Epsilon 0.1 mean q -16.687637\n",
      "Episode:  2213 Reward: -200.0 Epsilon 0.1 mean q -16.66671\n",
      "Episode:  2214 Reward: -200.0 Epsilon 0.1 mean q -16.661804\n",
      "Episode:  2215 Reward: -200.0 Epsilon 0.1 mean q -16.65472\n",
      "Episode:  2216 Reward: -200.0 Epsilon 0.1 mean q -16.666536\n",
      "Episode:  2217 Reward: -200.0 Epsilon 0.1 mean q -16.66721\n",
      "Episode:  2218 Reward: -200.0 Epsilon 0.1 mean q -16.670036\n",
      "Episode:  2219 Reward: -200.0 Epsilon 0.1 mean q -16.659521\n",
      "Episode:  2220 Reward: -200.0 Epsilon 0.1 mean q -16.673302\n",
      "Episode:  2221 Reward: -200.0 Epsilon 0.1 mean q -16.642118\n",
      "Episode:  2222 Reward: -200.0 Epsilon 0.1 mean q -16.656233\n",
      "Episode:  2223 Reward: -200.0 Epsilon 0.1 mean q -16.674511\n",
      "Episode:  2224 Reward: -200.0 Epsilon 0.1 mean q -16.66404\n",
      "Episode:  2225 Reward: -200.0 Epsilon 0.1 mean q -16.66701\n",
      "Episode:  2226 Reward: -200.0 Epsilon 0.1 mean q -16.683727\n",
      "Episode:  2227 Reward: -200.0 Epsilon 0.1 mean q -16.691523\n",
      "Episode:  2228 Reward: -200.0 Epsilon 0.1 mean q -16.686373\n",
      "Episode:  2229 Reward: -200.0 Epsilon 0.1 mean q -16.700256\n",
      "Episode:  2230 Reward: -200.0 Epsilon 0.1 mean q -16.646961\n",
      "Episode:  2231 Reward: -200.0 Epsilon 0.1 mean q -16.650063\n",
      "Episode:  2232 Reward: -200.0 Epsilon 0.1 mean q -16.669548\n",
      "Episode:  2233 Reward: -200.0 Epsilon 0.1 mean q -16.669151\n",
      "Episode:  2234 Reward: -200.0 Epsilon 0.1 mean q -16.668636\n",
      "Episode:  2235 Reward: -200.0 Epsilon 0.1 mean q -16.672922\n",
      "Episode:  2236 Reward: -200.0 Epsilon 0.1 mean q -16.662695\n",
      "Episode:  2237 Reward: -200.0 Epsilon 0.1 mean q -16.657543\n",
      "Episode:  2238 Reward: -200.0 Epsilon 0.1 mean q -16.646591\n",
      "Episode:  2239 Reward: -200.0 Epsilon 0.1 mean q -16.64098\n",
      "Episode:  2240 Reward: -200.0 Epsilon 0.1 mean q -16.648\n",
      "Episode:  2241 Reward: -200.0 Epsilon 0.1 mean q -16.667042\n",
      "Episode:  2242 Reward: -200.0 Epsilon 0.1 mean q -16.66479\n",
      "Episode:  2243 Reward: -200.0 Epsilon 0.1 mean q -16.713816\n",
      "Episode:  2244 Reward: -200.0 Epsilon 0.1 mean q -16.691784\n",
      "Episode:  2245 Reward: -200.0 Epsilon 0.1 mean q -16.640898\n",
      "Episode:  2246 Reward: -200.0 Epsilon 0.1 mean q -16.675957\n",
      "Episode:  2247 Reward: -200.0 Epsilon 0.1 mean q -16.691183\n",
      "Episode:  2248 Reward: -200.0 Epsilon 0.1 mean q -16.670237\n",
      "Episode:  2249 Reward: -200.0 Epsilon 0.1 mean q -16.692997\n",
      "Episode:  2250 Reward: -200.0 Epsilon 0.1 mean q -16.704195\n",
      "Episode:  2251 Reward: -200.0 Epsilon 0.1 mean q -16.65993\n",
      "Episode:  2252 Reward: -200.0 Epsilon 0.1 mean q -16.703093\n",
      "Episode:  2253 Reward: -200.0 Epsilon 0.1 mean q -16.654081\n",
      "Episode:  2254 Reward: -200.0 Epsilon 0.1 mean q -16.670805\n",
      "Episode:  2255 Reward: -200.0 Epsilon 0.1 mean q -16.686459\n",
      "Episode:  2256 Reward: -200.0 Epsilon 0.1 mean q -16.643665\n",
      "Episode:  2257 Reward: -200.0 Epsilon 0.1 mean q -16.707003\n",
      "Episode:  2258 Reward: -200.0 Epsilon 0.1 mean q -16.682005\n",
      "Episode:  2259 Reward: -200.0 Epsilon 0.1 mean q -16.683376\n",
      "Episode:  2260 Reward: -200.0 Epsilon 0.1 mean q -16.682068\n",
      "Episode:  2261 Reward: -200.0 Epsilon 0.1 mean q -16.652845\n",
      "Episode:  2262 Reward: -200.0 Epsilon 0.1 mean q -16.662758\n",
      "Episode:  2263 Reward: -200.0 Epsilon 0.1 mean q -16.652859\n",
      "Episode:  2264 Reward: -200.0 Epsilon 0.1 mean q -16.635706\n",
      "Episode:  2265 Reward: -200.0 Epsilon 0.1 mean q -16.63362\n",
      "Episode:  2266 Reward: -200.0 Epsilon 0.1 mean q -16.655348\n",
      "Episode:  2267 Reward: -200.0 Epsilon 0.1 mean q -16.67519\n",
      "Episode:  2268 Reward: -200.0 Epsilon 0.1 mean q -16.654583\n",
      "Episode:  2269 Reward: -200.0 Epsilon 0.1 mean q -16.698702\n",
      "Episode:  2270 Reward: -200.0 Epsilon 0.1 mean q -16.63771\n",
      "Episode:  2271 Reward: -200.0 Epsilon 0.1 mean q -16.660656\n",
      "Episode:  2272 Reward: -200.0 Epsilon 0.1 mean q -16.651848\n",
      "Episode:  2273 Reward: -200.0 Epsilon 0.1 mean q -16.651316\n",
      "Episode:  2274 Reward: -200.0 Epsilon 0.1 mean q -16.648272\n",
      "Episode:  2275 Reward: -200.0 Epsilon 0.1 mean q -16.66059\n",
      "Episode:  2276 Reward: -200.0 Epsilon 0.1 mean q -16.634836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  2277 Reward: -200.0 Epsilon 0.1 mean q -16.687685\n",
      "Episode:  2278 Reward: -200.0 Epsilon 0.1 mean q -16.64905\n",
      "Episode:  2279 Reward: -200.0 Epsilon 0.1 mean q -16.657192\n",
      "Episode:  2280 Reward: -200.0 Epsilon 0.1 mean q -16.64714\n",
      "Episode:  2281 Reward: -200.0 Epsilon 0.1 mean q -16.718367\n",
      "Episode:  2282 Reward: -200.0 Epsilon 0.1 mean q -16.651112\n",
      "Episode:  2283 Reward: -200.0 Epsilon 0.1 mean q -16.674688\n",
      "Episode:  2284 Reward: -200.0 Epsilon 0.1 mean q -16.669443\n",
      "Episode:  2285 Reward: -200.0 Epsilon 0.1 mean q -16.677135\n",
      "Episode:  2286 Reward: -200.0 Epsilon 0.1 mean q -16.650953\n",
      "Episode:  2287 Reward: -200.0 Epsilon 0.1 mean q -16.665745\n",
      "Episode:  2288 Reward: -200.0 Epsilon 0.1 mean q -16.64588\n",
      "Episode:  2289 Reward: -200.0 Epsilon 0.1 mean q -16.683664\n",
      "Episode:  2290 Reward: -200.0 Epsilon 0.1 mean q -16.645462\n",
      "Episode:  2291 Reward: -200.0 Epsilon 0.1 mean q -16.669716\n",
      "Episode:  2292 Reward: -200.0 Epsilon 0.1 mean q -16.692719\n",
      "Episode:  2293 Reward: -200.0 Epsilon 0.1 mean q -16.663658\n",
      "Episode:  2294 Reward: -200.0 Epsilon 0.1 mean q -16.682737\n",
      "Episode:  2295 Reward: -200.0 Epsilon 0.1 mean q -16.64265\n",
      "Episode:  2296 Reward: -200.0 Epsilon 0.1 mean q -16.659521\n",
      "Episode:  2297 Reward: -200.0 Epsilon 0.1 mean q -16.69565\n",
      "Episode:  2298 Reward: -200.0 Epsilon 0.1 mean q -16.652592\n",
      "Episode:  2299 Reward: -200.0 Epsilon 0.1 mean q -16.661804\n",
      "Episode:  2300 Reward: -200.0 Epsilon 0.1 mean q -16.636538\n",
      "Episode:  2301 Reward: -200.0 Epsilon 0.1 mean q -16.689579\n",
      "Episode:  2302 Reward: -200.0 Epsilon 0.1 mean q -16.699656\n",
      "Episode:  2303 Reward: -200.0 Epsilon 0.1 mean q -16.662792\n",
      "Episode:  2304 Reward: -200.0 Epsilon 0.1 mean q -16.680553\n",
      "Episode:  2305 Reward: -200.0 Epsilon 0.1 mean q -16.697523\n",
      "Episode:  2306 Reward: -200.0 Epsilon 0.1 mean q -16.668715\n",
      "Episode:  2307 Reward: -200.0 Epsilon 0.1 mean q -16.652971\n",
      "Episode:  2308 Reward: -200.0 Epsilon 0.1 mean q -16.656572\n",
      "Episode:  2309 Reward: -200.0 Epsilon 0.1 mean q -16.692478\n",
      "Episode:  2310 Reward: -200.0 Epsilon 0.1 mean q -16.655094\n",
      "Episode:  2311 Reward: -200.0 Epsilon 0.1 mean q -16.683893\n",
      "Episode:  2312 Reward: -200.0 Epsilon 0.1 mean q -16.635029\n",
      "Episode:  2313 Reward: -200.0 Epsilon 0.1 mean q -16.641602\n",
      "Episode:  2314 Reward: -200.0 Epsilon 0.1 mean q -16.681602\n",
      "Episode:  2315 Reward: -200.0 Epsilon 0.1 mean q -16.665684\n",
      "Episode:  2316 Reward: -200.0 Epsilon 0.1 mean q -16.685818\n",
      "Episode:  2317 Reward: -200.0 Epsilon 0.1 mean q -16.666117\n",
      "Episode:  2318 Reward: -200.0 Epsilon 0.1 mean q -16.633793\n",
      "Episode:  2319 Reward: -200.0 Epsilon 0.1 mean q -16.65592\n",
      "Episode:  2320 Reward: -200.0 Epsilon 0.1 mean q -16.670172\n",
      "Episode:  2321 Reward: -200.0 Epsilon 0.1 mean q -16.675768\n",
      "Episode:  2322 Reward: -200.0 Epsilon 0.1 mean q -16.677048\n",
      "Episode:  2323 Reward: -200.0 Epsilon 0.1 mean q -16.659294\n",
      "Episode:  2324 Reward: -200.0 Epsilon 0.1 mean q -16.649736\n",
      "Episode:  2325 Reward: -200.0 Epsilon 0.1 mean q -16.676432\n",
      "Episode:  2326 Reward: -200.0 Epsilon 0.1 mean q -16.631641\n",
      "Episode:  2327 Reward: -200.0 Epsilon 0.1 mean q -16.63849\n",
      "Episode:  2328 Reward: -200.0 Epsilon 0.1 mean q -16.659906\n",
      "Episode:  2329 Reward: -200.0 Epsilon 0.1 mean q -16.665424\n",
      "Episode:  2330 Reward: -200.0 Epsilon 0.1 mean q -16.663923\n",
      "Episode:  2331 Reward: -200.0 Epsilon 0.1 mean q -16.691023\n",
      "Episode:  2332 Reward: -200.0 Epsilon 0.1 mean q -16.666636\n",
      "Episode:  2333 Reward: -200.0 Epsilon 0.1 mean q -16.654057\n",
      "Episode:  2334 Reward: -200.0 Epsilon 0.1 mean q -16.660088\n",
      "Episode:  2335 Reward: -200.0 Epsilon 0.1 mean q -16.663883\n",
      "Episode:  2336 Reward: -200.0 Epsilon 0.1 mean q -16.691624\n",
      "Episode:  2337 Reward: -200.0 Epsilon 0.1 mean q -16.665588\n",
      "Episode:  2338 Reward: -200.0 Epsilon 0.1 mean q -16.681232\n",
      "Episode:  2339 Reward: -200.0 Epsilon 0.1 mean q -16.677702\n",
      "Episode:  2340 Reward: -200.0 Epsilon 0.1 mean q -16.654003\n",
      "Episode:  2341 Reward: -200.0 Epsilon 0.1 mean q -16.64382\n",
      "Episode:  2342 Reward: -200.0 Epsilon 0.1 mean q -16.67811\n",
      "Episode:  2343 Reward: -200.0 Epsilon 0.1 mean q -16.670841\n",
      "Episode:  2344 Reward: -200.0 Epsilon 0.1 mean q -16.689447\n",
      "Episode:  2345 Reward: -200.0 Epsilon 0.1 mean q -16.63455\n",
      "Episode:  2346 Reward: -200.0 Epsilon 0.1 mean q -16.702236\n",
      "Episode:  2347 Reward: -200.0 Epsilon 0.1 mean q -16.681137\n",
      "Episode:  2348 Reward: -200.0 Epsilon 0.1 mean q -16.653397\n",
      "Episode:  2349 Reward: -200.0 Epsilon 0.1 mean q -16.649487\n",
      "Episode:  2350 Reward: -200.0 Epsilon 0.1 mean q -16.650658\n",
      "Episode:  2351 Reward: -200.0 Epsilon 0.1 mean q -16.625147\n",
      "Episode:  2352 Reward: -200.0 Epsilon 0.1 mean q -16.667574\n",
      "Episode:  2353 Reward: -200.0 Epsilon 0.1 mean q -16.67193\n",
      "Episode:  2354 Reward: -200.0 Epsilon 0.1 mean q -16.66682\n",
      "Episode:  2355 Reward: -200.0 Epsilon 0.1 mean q -16.669964\n",
      "Episode:  2356 Reward: -200.0 Epsilon 0.1 mean q -16.668928\n",
      "Episode:  2357 Reward: -200.0 Epsilon 0.1 mean q -16.67796\n",
      "Episode:  2358 Reward: -200.0 Epsilon 0.1 mean q -16.668816\n",
      "Episode:  2359 Reward: -200.0 Epsilon 0.1 mean q -16.673214\n",
      "Episode:  2360 Reward: -200.0 Epsilon 0.1 mean q -16.638655\n",
      "Episode:  2361 Reward: -200.0 Epsilon 0.1 mean q -16.641838\n",
      "Episode:  2362 Reward: -200.0 Epsilon 0.1 mean q -16.664629\n",
      "Episode:  2363 Reward: -200.0 Epsilon 0.1 mean q -16.676107\n",
      "Episode:  2364 Reward: -200.0 Epsilon 0.1 mean q -16.664597\n",
      "Episode:  2365 Reward: -200.0 Epsilon 0.1 mean q -16.698437\n",
      "Episode:  2366 Reward: -200.0 Epsilon 0.1 mean q -16.67148\n",
      "Episode:  2367 Reward: -200.0 Epsilon 0.1 mean q -16.677717\n",
      "Episode:  2368 Reward: -200.0 Epsilon 0.1 mean q -16.679134\n",
      "Episode:  2369 Reward: -200.0 Epsilon 0.1 mean q -16.62463\n",
      "Episode:  2370 Reward: -200.0 Epsilon 0.1 mean q -16.669216\n",
      "Episode:  2371 Reward: -200.0 Epsilon 0.1 mean q -16.690964\n",
      "Episode:  2372 Reward: -200.0 Epsilon 0.1 mean q -16.641054\n",
      "Episode:  2373 Reward: -200.0 Epsilon 0.1 mean q -16.645487\n",
      "Episode:  2374 Reward: -200.0 Epsilon 0.1 mean q -16.669006\n",
      "Episode:  2375 Reward: -200.0 Epsilon 0.1 mean q -16.709297\n",
      "Episode:  2376 Reward: -200.0 Epsilon 0.1 mean q -16.705967\n",
      "Episode:  2377 Reward: -200.0 Epsilon 0.1 mean q -16.670904\n",
      "Episode:  2378 Reward: -200.0 Epsilon 0.1 mean q -16.684786\n",
      "Episode:  2379 Reward: -200.0 Epsilon 0.1 mean q -16.663397\n",
      "Episode:  2380 Reward: -200.0 Epsilon 0.1 mean q -16.690708\n",
      "Episode:  2381 Reward: -200.0 Epsilon 0.1 mean q -16.667435\n",
      "Episode:  2382 Reward: -200.0 Epsilon 0.1 mean q -16.643606\n",
      "Episode:  2383 Reward: -200.0 Epsilon 0.1 mean q -16.674667\n",
      "Episode:  2384 Reward: -200.0 Epsilon 0.1 mean q -16.674469\n",
      "Episode:  2385 Reward: -200.0 Epsilon 0.1 mean q -16.651106\n",
      "Episode:  2386 Reward: -200.0 Epsilon 0.1 mean q -16.691622\n",
      "Episode:  2387 Reward: -200.0 Epsilon 0.1 mean q -16.689035\n",
      "Episode:  2388 Reward: -200.0 Epsilon 0.1 mean q -16.693773\n",
      "Episode:  2389 Reward: -200.0 Epsilon 0.1 mean q -16.642572\n",
      "Episode:  2390 Reward: -200.0 Epsilon 0.1 mean q -16.6333\n",
      "Episode:  2391 Reward: -200.0 Epsilon 0.1 mean q -16.643343\n",
      "Episode:  2392 Reward: -200.0 Epsilon 0.1 mean q -16.694843\n",
      "Episode:  2393 Reward: -200.0 Epsilon 0.1 mean q -16.671862\n",
      "Episode:  2394 Reward: -200.0 Epsilon 0.1 mean q -16.655048\n",
      "Episode:  2395 Reward: -200.0 Epsilon 0.1 mean q -16.68429\n",
      "Episode:  2396 Reward: -200.0 Epsilon 0.1 mean q -16.675234\n",
      "Episode:  2397 Reward: -200.0 Epsilon 0.1 mean q -16.682034\n",
      "Episode:  2398 Reward: -200.0 Epsilon 0.1 mean q -16.653017\n",
      "Episode:  2399 Reward: -200.0 Epsilon 0.1 mean q -16.651823\n",
      "Episode:  2400 Reward: -200.0 Epsilon 0.1 mean q -16.643623\n",
      "Episode:  2401 Reward: -200.0 Epsilon 0.1 mean q -16.64718\n",
      "Episode:  2402 Reward: -200.0 Epsilon 0.1 mean q -16.62968\n",
      "Episode:  2403 Reward: -200.0 Epsilon 0.1 mean q -16.660067\n",
      "Episode:  2404 Reward: -200.0 Epsilon 0.1 mean q -16.644846\n",
      "Episode:  2405 Reward: -200.0 Epsilon 0.1 mean q -16.675116\n",
      "Episode:  2406 Reward: -200.0 Epsilon 0.1 mean q -16.646305\n",
      "Episode:  2407 Reward: -200.0 Epsilon 0.1 mean q -16.677763\n",
      "Episode:  2408 Reward: -200.0 Epsilon 0.1 mean q -16.654871\n",
      "Episode:  2409 Reward: -200.0 Epsilon 0.1 mean q -16.67057\n",
      "Episode:  2410 Reward: -200.0 Epsilon 0.1 mean q -16.668556\n",
      "Episode:  2411 Reward: -200.0 Epsilon 0.1 mean q -16.653896\n",
      "Episode:  2412 Reward: -200.0 Epsilon 0.1 mean q -16.66138\n",
      "Episode:  2413 Reward: -200.0 Epsilon 0.1 mean q -16.676575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  2414 Reward: -200.0 Epsilon 0.1 mean q -16.667915\n",
      "Episode:  2415 Reward: -200.0 Epsilon 0.1 mean q -16.703045\n",
      "Episode:  2416 Reward: -200.0 Epsilon 0.1 mean q -16.710398\n",
      "Episode:  2417 Reward: -200.0 Epsilon 0.1 mean q -16.655739\n",
      "Episode:  2418 Reward: -200.0 Epsilon 0.1 mean q -16.663795\n",
      "Episode:  2419 Reward: -200.0 Epsilon 0.1 mean q -16.671604\n",
      "Episode:  2420 Reward: -200.0 Epsilon 0.1 mean q -16.672684\n",
      "Episode:  2421 Reward: -200.0 Epsilon 0.1 mean q -16.69173\n",
      "Episode:  2422 Reward: -200.0 Epsilon 0.1 mean q -16.607227\n",
      "Episode:  2423 Reward: -200.0 Epsilon 0.1 mean q -16.663155\n",
      "Episode:  2424 Reward: -200.0 Epsilon 0.1 mean q -16.707737\n",
      "Episode:  2425 Reward: -200.0 Epsilon 0.1 mean q -16.652536\n",
      "Episode:  2426 Reward: -200.0 Epsilon 0.1 mean q -16.65713\n",
      "Episode:  2427 Reward: -200.0 Epsilon 0.1 mean q -16.64291\n",
      "Episode:  2428 Reward: -200.0 Epsilon 0.1 mean q -16.625471\n",
      "Episode:  2429 Reward: -200.0 Epsilon 0.1 mean q -16.662601\n",
      "Episode:  2430 Reward: -200.0 Epsilon 0.1 mean q -16.653475\n",
      "Episode:  2431 Reward: -200.0 Epsilon 0.1 mean q -16.669336\n",
      "Episode:  2432 Reward: -200.0 Epsilon 0.1 mean q -16.695332\n",
      "Episode:  2433 Reward: -200.0 Epsilon 0.1 mean q -16.622856\n",
      "Episode:  2434 Reward: -200.0 Epsilon 0.1 mean q -16.678753\n",
      "Episode:  2435 Reward: -200.0 Epsilon 0.1 mean q -16.672478\n",
      "Episode:  2436 Reward: -200.0 Epsilon 0.1 mean q -16.645279\n",
      "Episode:  2437 Reward: -200.0 Epsilon 0.1 mean q -16.703053\n",
      "Episode:  2438 Reward: -200.0 Epsilon 0.1 mean q -16.677366\n",
      "Episode:  2439 Reward: -200.0 Epsilon 0.1 mean q -16.6563\n",
      "Episode:  2440 Reward: -200.0 Epsilon 0.1 mean q -16.651161\n",
      "Episode:  2441 Reward: -200.0 Epsilon 0.1 mean q -16.652918\n",
      "Episode:  2442 Reward: -200.0 Epsilon 0.1 mean q -16.66187\n",
      "Episode:  2443 Reward: -200.0 Epsilon 0.1 mean q -16.706377\n",
      "Episode:  2444 Reward: -200.0 Epsilon 0.1 mean q -16.664656\n",
      "Episode:  2445 Reward: -200.0 Epsilon 0.1 mean q -16.67878\n",
      "Episode:  2446 Reward: -200.0 Epsilon 0.1 mean q -16.661171\n",
      "Episode:  2447 Reward: -200.0 Epsilon 0.1 mean q -16.673922\n",
      "Episode:  2448 Reward: -200.0 Epsilon 0.1 mean q -16.662796\n",
      "Episode:  2449 Reward: -200.0 Epsilon 0.1 mean q -16.673119\n",
      "Episode:  2450 Reward: -200.0 Epsilon 0.1 mean q -16.682484\n",
      "Episode:  2451 Reward: -200.0 Epsilon 0.1 mean q -16.687326\n",
      "Episode:  2452 Reward: -200.0 Epsilon 0.1 mean q -16.663671\n",
      "Episode:  2453 Reward: -200.0 Epsilon 0.1 mean q -16.654219\n",
      "Episode:  2454 Reward: -200.0 Epsilon 0.1 mean q -16.652597\n",
      "Episode:  2455 Reward: -200.0 Epsilon 0.1 mean q -16.655563\n",
      "Episode:  2456 Reward: -200.0 Epsilon 0.1 mean q -16.68346\n",
      "Episode:  2457 Reward: -200.0 Epsilon 0.1 mean q -16.646921\n",
      "Episode:  2458 Reward: -200.0 Epsilon 0.1 mean q -16.663874\n",
      "Episode:  2459 Reward: -200.0 Epsilon 0.1 mean q -16.651215\n",
      "Episode:  2460 Reward: -200.0 Epsilon 0.1 mean q -16.688126\n",
      "Episode:  2461 Reward: -200.0 Epsilon 0.1 mean q -16.700308\n",
      "Episode:  2462 Reward: -200.0 Epsilon 0.1 mean q -16.67444\n",
      "Episode:  2463 Reward: -200.0 Epsilon 0.1 mean q -16.668789\n",
      "Episode:  2464 Reward: -200.0 Epsilon 0.1 mean q -16.659801\n",
      "Episode:  2465 Reward: -200.0 Epsilon 0.1 mean q -16.648428\n",
      "Episode:  2466 Reward: -200.0 Epsilon 0.1 mean q -16.63577\n",
      "Episode:  2467 Reward: -200.0 Epsilon 0.1 mean q -16.686037\n",
      "Episode:  2468 Reward: -200.0 Epsilon 0.1 mean q -16.641191\n",
      "Episode:  2469 Reward: -200.0 Epsilon 0.1 mean q -16.644363\n",
      "Episode:  2470 Reward: -200.0 Epsilon 0.1 mean q -16.674633\n",
      "Episode:  2471 Reward: -200.0 Epsilon 0.1 mean q -16.65926\n",
      "Episode:  2472 Reward: -200.0 Epsilon 0.1 mean q -16.661926\n",
      "Episode:  2473 Reward: -200.0 Epsilon 0.1 mean q -16.64529\n",
      "Episode:  2474 Reward: -200.0 Epsilon 0.1 mean q -16.685055\n",
      "Episode:  2475 Reward: -200.0 Epsilon 0.1 mean q -16.698252\n",
      "Episode:  2476 Reward: -200.0 Epsilon 0.1 mean q -16.675358\n",
      "Episode:  2477 Reward: -200.0 Epsilon 0.1 mean q -16.661467\n",
      "Episode:  2478 Reward: -200.0 Epsilon 0.1 mean q -16.657564\n",
      "Episode:  2479 Reward: -200.0 Epsilon 0.1 mean q -16.673918\n",
      "Episode:  2480 Reward: -200.0 Epsilon 0.1 mean q -16.693073\n",
      "Episode:  2481 Reward: -200.0 Epsilon 0.1 mean q -16.658669\n",
      "Episode:  2482 Reward: -200.0 Epsilon 0.1 mean q -16.655901\n",
      "Episode:  2483 Reward: -200.0 Epsilon 0.1 mean q -16.668236\n",
      "Episode:  2484 Reward: -200.0 Epsilon 0.1 mean q -16.683258\n",
      "Episode:  2485 Reward: -200.0 Epsilon 0.1 mean q -16.61838\n",
      "Episode:  2486 Reward: -200.0 Epsilon 0.1 mean q -16.674185\n",
      "Episode:  2487 Reward: -200.0 Epsilon 0.1 mean q -16.646185\n",
      "Episode:  2488 Reward: -200.0 Epsilon 0.1 mean q -16.674456\n",
      "Episode:  2489 Reward: -200.0 Epsilon 0.1 mean q -16.664434\n",
      "Episode:  2490 Reward: -200.0 Epsilon 0.1 mean q -16.695581\n",
      "Episode:  2491 Reward: -200.0 Epsilon 0.1 mean q -16.680319\n",
      "Episode:  2492 Reward: -200.0 Epsilon 0.1 mean q -16.692116\n",
      "Episode:  2493 Reward: -200.0 Epsilon 0.1 mean q -16.655186\n",
      "Episode:  2494 Reward: -200.0 Epsilon 0.1 mean q -16.678638\n",
      "Episode:  2495 Reward: -200.0 Epsilon 0.1 mean q -16.653622\n",
      "Episode:  2496 Reward: -200.0 Epsilon 0.1 mean q -16.653555\n",
      "Episode:  2497 Reward: -200.0 Epsilon 0.1 mean q -16.695202\n",
      "Episode:  2498 Reward: -200.0 Epsilon 0.1 mean q -16.667143\n",
      "Episode:  2499 Reward: -200.0 Epsilon 0.1 mean q -16.663525\n",
      "Episode:  2500 Reward: -200.0 Epsilon 0.1 mean q -16.626936\n",
      "Episode:  2501 Reward: -200.0 Epsilon 0.1 mean q -16.688616\n",
      "Episode:  2502 Reward: -200.0 Epsilon 0.1 mean q -16.686932\n",
      "Episode:  2503 Reward: -200.0 Epsilon 0.1 mean q -16.630821\n",
      "Episode:  2504 Reward: -200.0 Epsilon 0.1 mean q -16.680391\n",
      "Episode:  2505 Reward: -200.0 Epsilon 0.1 mean q -16.644684\n",
      "Episode:  2506 Reward: -200.0 Epsilon 0.1 mean q -16.682184\n",
      "Episode:  2507 Reward: -200.0 Epsilon 0.1 mean q -16.687004\n",
      "Episode:  2508 Reward: -200.0 Epsilon 0.1 mean q -16.67755\n",
      "Episode:  2509 Reward: -200.0 Epsilon 0.1 mean q -16.637144\n",
      "Episode:  2510 Reward: -200.0 Epsilon 0.1 mean q -16.66571\n",
      "Episode:  2511 Reward: -200.0 Epsilon 0.1 mean q -16.649145\n",
      "Episode:  2512 Reward: -200.0 Epsilon 0.1 mean q -16.712057\n",
      "Episode:  2513 Reward: -200.0 Epsilon 0.1 mean q -16.653849\n",
      "Episode:  2514 Reward: -200.0 Epsilon 0.1 mean q -16.661657\n",
      "Episode:  2515 Reward: -200.0 Epsilon 0.1 mean q -16.66814\n",
      "Episode:  2516 Reward: -200.0 Epsilon 0.1 mean q -16.68413\n",
      "Episode:  2517 Reward: -200.0 Epsilon 0.1 mean q -16.66374\n",
      "Episode:  2518 Reward: -200.0 Epsilon 0.1 mean q -16.683174\n",
      "Episode:  2519 Reward: -200.0 Epsilon 0.1 mean q -16.647816\n",
      "Episode:  2520 Reward: -200.0 Epsilon 0.1 mean q -16.682423\n",
      "Episode:  2521 Reward: -200.0 Epsilon 0.1 mean q -16.652554\n",
      "Episode:  2522 Reward: -200.0 Epsilon 0.1 mean q -16.66596\n",
      "Episode:  2523 Reward: -200.0 Epsilon 0.1 mean q -16.674122\n",
      "Episode:  2524 Reward: -200.0 Epsilon 0.1 mean q -16.693378\n",
      "Episode:  2525 Reward: -200.0 Epsilon 0.1 mean q -16.677828\n",
      "Episode:  2526 Reward: -200.0 Epsilon 0.1 mean q -16.656832\n",
      "Episode:  2527 Reward: -200.0 Epsilon 0.1 mean q -16.680756\n",
      "Episode:  2528 Reward: -200.0 Epsilon 0.1 mean q -16.66233\n",
      "Episode:  2529 Reward: -200.0 Epsilon 0.1 mean q -16.647049\n",
      "Episode:  2530 Reward: -200.0 Epsilon 0.1 mean q -16.654434\n",
      "Episode:  2531 Reward: -200.0 Epsilon 0.1 mean q -16.655771\n",
      "Episode:  2532 Reward: -200.0 Epsilon 0.1 mean q -16.681768\n",
      "Episode:  2533 Reward: -200.0 Epsilon 0.1 mean q -16.671442\n",
      "Episode:  2534 Reward: -200.0 Epsilon 0.1 mean q -16.667406\n",
      "Episode:  2535 Reward: -200.0 Epsilon 0.1 mean q -16.666151\n",
      "Episode:  2536 Reward: -200.0 Epsilon 0.1 mean q -16.661617\n",
      "Episode:  2537 Reward: -200.0 Epsilon 0.1 mean q -16.67227\n",
      "Episode:  2538 Reward: -200.0 Epsilon 0.1 mean q -16.652224\n",
      "Episode:  2539 Reward: -200.0 Epsilon 0.1 mean q -16.622467\n",
      "Episode:  2540 Reward: -200.0 Epsilon 0.1 mean q -16.678278\n",
      "Episode:  2541 Reward: -200.0 Epsilon 0.1 mean q -16.665524\n",
      "Episode:  2542 Reward: -200.0 Epsilon 0.1 mean q -16.681347\n",
      "Episode:  2543 Reward: -200.0 Epsilon 0.1 mean q -16.650496\n",
      "Episode:  2544 Reward: -200.0 Epsilon 0.1 mean q -16.673098\n",
      "Episode:  2545 Reward: -200.0 Epsilon 0.1 mean q -16.663847\n",
      "Episode:  2546 Reward: -200.0 Epsilon 0.1 mean q -16.671276\n",
      "Episode:  2547 Reward: -200.0 Epsilon 0.1 mean q -16.65109\n",
      "Episode:  2548 Reward: -200.0 Epsilon 0.1 mean q -16.658438\n",
      "Episode:  2549 Reward: -200.0 Epsilon 0.1 mean q -16.639404\n",
      "Episode:  2550 Reward: -200.0 Epsilon 0.1 mean q -16.68888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  2551 Reward: -200.0 Epsilon 0.1 mean q -16.666145\n",
      "Episode:  2552 Reward: -200.0 Epsilon 0.1 mean q -16.68628\n",
      "Episode:  2553 Reward: -200.0 Epsilon 0.1 mean q -16.62091\n",
      "Episode:  2554 Reward: -200.0 Epsilon 0.1 mean q -16.650938\n",
      "Episode:  2555 Reward: -200.0 Epsilon 0.1 mean q -16.664711\n",
      "Episode:  2556 Reward: -200.0 Epsilon 0.1 mean q -16.661993\n",
      "Episode:  2557 Reward: -200.0 Epsilon 0.1 mean q -16.680637\n",
      "Episode:  2558 Reward: -200.0 Epsilon 0.1 mean q -16.655693\n",
      "Episode:  2559 Reward: -200.0 Epsilon 0.1 mean q -16.661383\n",
      "Episode:  2560 Reward: -200.0 Epsilon 0.1 mean q -16.7012\n",
      "Episode:  2561 Reward: -200.0 Epsilon 0.1 mean q -16.658962\n",
      "Episode:  2562 Reward: -200.0 Epsilon 0.1 mean q -16.676888\n",
      "Episode:  2563 Reward: -200.0 Epsilon 0.1 mean q -16.634882\n",
      "Episode:  2564 Reward: -200.0 Epsilon 0.1 mean q -16.665209\n",
      "Episode:  2565 Reward: -200.0 Epsilon 0.1 mean q -16.64604\n",
      "Episode:  2566 Reward: -200.0 Epsilon 0.1 mean q -16.652819\n",
      "Episode:  2567 Reward: -200.0 Epsilon 0.1 mean q -16.671236\n",
      "Episode:  2568 Reward: -200.0 Epsilon 0.1 mean q -16.664225\n",
      "Episode:  2569 Reward: -200.0 Epsilon 0.1 mean q -16.69756\n",
      "Episode:  2570 Reward: -200.0 Epsilon 0.1 mean q -16.677929\n",
      "Episode:  2571 Reward: -200.0 Epsilon 0.1 mean q -16.69619\n",
      "Episode:  2572 Reward: -200.0 Epsilon 0.1 mean q -16.671028\n",
      "Episode:  2573 Reward: -200.0 Epsilon 0.1 mean q -16.674305\n",
      "Episode:  2574 Reward: -200.0 Epsilon 0.1 mean q -16.677996\n",
      "Episode:  2575 Reward: -200.0 Epsilon 0.1 mean q -16.666813\n",
      "Episode:  2576 Reward: -200.0 Epsilon 0.1 mean q -16.683043\n",
      "Episode:  2577 Reward: -200.0 Epsilon 0.1 mean q -16.697865\n",
      "Episode:  2578 Reward: -200.0 Epsilon 0.1 mean q -16.670395\n",
      "Episode:  2579 Reward: -200.0 Epsilon 0.1 mean q -16.641886\n",
      "Episode:  2580 Reward: -200.0 Epsilon 0.1 mean q -16.65681\n",
      "Episode:  2581 Reward: -200.0 Epsilon 0.1 mean q -16.676228\n",
      "Episode:  2582 Reward: -200.0 Epsilon 0.1 mean q -16.688768\n",
      "Episode:  2583 Reward: -200.0 Epsilon 0.1 mean q -16.7071\n",
      "Episode:  2584 Reward: -200.0 Epsilon 0.1 mean q -16.691711\n",
      "Episode:  2585 Reward: -200.0 Epsilon 0.1 mean q -16.679102\n",
      "Episode:  2586 Reward: -200.0 Epsilon 0.1 mean q -16.665434\n",
      "Episode:  2587 Reward: -200.0 Epsilon 0.1 mean q -16.656097\n",
      "Episode:  2588 Reward: -200.0 Epsilon 0.1 mean q -16.66738\n",
      "Episode:  2589 Reward: -200.0 Epsilon 0.1 mean q -16.681063\n",
      "Episode:  2590 Reward: -200.0 Epsilon 0.1 mean q -16.670513\n",
      "Episode:  2591 Reward: -200.0 Epsilon 0.1 mean q -16.71043\n",
      "Episode:  2592 Reward: -200.0 Epsilon 0.1 mean q -16.635046\n",
      "Episode:  2593 Reward: -200.0 Epsilon 0.1 mean q -16.687538\n",
      "Episode:  2594 Reward: -200.0 Epsilon 0.1 mean q -16.68663\n",
      "Episode:  2595 Reward: -200.0 Epsilon 0.1 mean q -16.670538\n",
      "Episode:  2596 Reward: -200.0 Epsilon 0.1 mean q -16.717188\n",
      "Episode:  2597 Reward: -200.0 Epsilon 0.1 mean q -16.664215\n",
      "Episode:  2598 Reward: -200.0 Epsilon 0.1 mean q -16.69264\n",
      "Episode:  2599 Reward: -200.0 Epsilon 0.1 mean q -16.635756\n",
      "Episode:  2600 Reward: -200.0 Epsilon 0.1 mean q -16.664183\n",
      "Episode:  2601 Reward: -200.0 Epsilon 0.1 mean q -16.668243\n",
      "Episode:  2602 Reward: -200.0 Epsilon 0.1 mean q -16.682549\n",
      "Episode:  2603 Reward: -200.0 Epsilon 0.1 mean q -16.667974\n",
      "Episode:  2604 Reward: -200.0 Epsilon 0.1 mean q -16.703747\n",
      "Episode:  2605 Reward: -200.0 Epsilon 0.1 mean q -16.688826\n",
      "Episode:  2606 Reward: -200.0 Epsilon 0.1 mean q -16.640244\n",
      "Episode:  2607 Reward: -200.0 Epsilon 0.1 mean q -16.672142\n",
      "Episode:  2608 Reward: -200.0 Epsilon 0.1 mean q -16.653831\n",
      "Episode:  2609 Reward: -200.0 Epsilon 0.1 mean q -16.639717\n",
      "Episode:  2610 Reward: -200.0 Epsilon 0.1 mean q -16.688068\n",
      "Episode:  2611 Reward: -200.0 Epsilon 0.1 mean q -16.70295\n",
      "Episode:  2612 Reward: -200.0 Epsilon 0.1 mean q -16.664465\n",
      "Episode:  2613 Reward: -200.0 Epsilon 0.1 mean q -16.65165\n",
      "Episode:  2614 Reward: -200.0 Epsilon 0.1 mean q -16.67917\n",
      "Episode:  2615 Reward: -200.0 Epsilon 0.1 mean q -16.641357\n",
      "Episode:  2616 Reward: -200.0 Epsilon 0.1 mean q -16.658146\n",
      "Episode:  2617 Reward: -200.0 Epsilon 0.1 mean q -16.680416\n",
      "Episode:  2618 Reward: -200.0 Epsilon 0.1 mean q -16.674189\n",
      "Episode:  2619 Reward: -200.0 Epsilon 0.1 mean q -16.685364\n",
      "Episode:  2620 Reward: -200.0 Epsilon 0.1 mean q -16.656233\n",
      "Episode:  2621 Reward: -200.0 Epsilon 0.1 mean q -16.629827\n",
      "Episode:  2622 Reward: -200.0 Epsilon 0.1 mean q -16.644348\n",
      "Episode:  2623 Reward: -200.0 Epsilon 0.1 mean q -16.677086\n",
      "Episode:  2624 Reward: -200.0 Epsilon 0.1 mean q -16.659382\n",
      "Episode:  2625 Reward: -200.0 Epsilon 0.1 mean q -16.653044\n",
      "Episode:  2626 Reward: -200.0 Epsilon 0.1 mean q -16.671862\n",
      "Episode:  2627 Reward: -200.0 Epsilon 0.1 mean q -16.677876\n",
      "Episode:  2628 Reward: -200.0 Epsilon 0.1 mean q -16.660568\n",
      "Episode:  2629 Reward: -200.0 Epsilon 0.1 mean q -16.682276\n",
      "Episode:  2630 Reward: -200.0 Epsilon 0.1 mean q -16.675087\n",
      "Episode:  2631 Reward: -200.0 Epsilon 0.1 mean q -16.686663\n",
      "Episode:  2632 Reward: -200.0 Epsilon 0.1 mean q -16.672976\n",
      "Episode:  2633 Reward: -200.0 Epsilon 0.1 mean q -16.672932\n",
      "Episode:  2634 Reward: -200.0 Epsilon 0.1 mean q -16.651915\n",
      "Episode:  2635 Reward: -200.0 Epsilon 0.1 mean q -16.658829\n",
      "Episode:  2636 Reward: -200.0 Epsilon 0.1 mean q -16.681316\n",
      "Episode:  2637 Reward: -200.0 Epsilon 0.1 mean q -16.68673\n",
      "Episode:  2638 Reward: -200.0 Epsilon 0.1 mean q -16.664963\n",
      "Episode:  2639 Reward: -200.0 Epsilon 0.1 mean q -16.712618\n",
      "Episode:  2640 Reward: -200.0 Epsilon 0.1 mean q -16.650888\n",
      "Episode:  2641 Reward: -200.0 Epsilon 0.1 mean q -16.639267\n",
      "Episode:  2642 Reward: -200.0 Epsilon 0.1 mean q -16.683403\n",
      "Episode:  2643 Reward: -200.0 Epsilon 0.1 mean q -16.657848\n",
      "Episode:  2644 Reward: -200.0 Epsilon 0.1 mean q -16.688398\n",
      "Episode:  2645 Reward: -200.0 Epsilon 0.1 mean q -16.657564\n",
      "Episode:  2646 Reward: -200.0 Epsilon 0.1 mean q -16.633484\n",
      "Episode:  2647 Reward: -200.0 Epsilon 0.1 mean q -16.662722\n",
      "Episode:  2648 Reward: -200.0 Epsilon 0.1 mean q -16.662636\n",
      "Episode:  2649 Reward: -200.0 Epsilon 0.1 mean q -16.678326\n",
      "Episode:  2650 Reward: -200.0 Epsilon 0.1 mean q -16.659294\n",
      "Episode:  2651 Reward: -200.0 Epsilon 0.1 mean q -16.680033\n",
      "Episode:  2652 Reward: -200.0 Epsilon 0.1 mean q -16.689938\n",
      "Episode:  2653 Reward: -200.0 Epsilon 0.1 mean q -16.646368\n",
      "Episode:  2654 Reward: -200.0 Epsilon 0.1 mean q -16.698015\n",
      "Episode:  2655 Reward: -200.0 Epsilon 0.1 mean q -16.675966\n",
      "Episode:  2656 Reward: -200.0 Epsilon 0.1 mean q -16.690798\n",
      "Episode:  2657 Reward: -200.0 Epsilon 0.1 mean q -16.651653\n",
      "Episode:  2658 Reward: -200.0 Epsilon 0.1 mean q -16.660963\n",
      "Episode:  2659 Reward: -200.0 Epsilon 0.1 mean q -16.714277\n",
      "Episode:  2660 Reward: -200.0 Epsilon 0.1 mean q -16.688692\n",
      "Episode:  2661 Reward: -200.0 Epsilon 0.1 mean q -16.661715\n",
      "Episode:  2662 Reward: -200.0 Epsilon 0.1 mean q -16.679886\n",
      "Episode:  2663 Reward: -200.0 Epsilon 0.1 mean q -16.68026\n",
      "Episode:  2664 Reward: -200.0 Epsilon 0.1 mean q -16.68936\n",
      "Episode:  2665 Reward: -200.0 Epsilon 0.1 mean q -16.663893\n",
      "Episode:  2666 Reward: -200.0 Epsilon 0.1 mean q -16.631327\n",
      "Episode:  2667 Reward: -200.0 Epsilon 0.1 mean q -16.671272\n",
      "Episode:  2668 Reward: -200.0 Epsilon 0.1 mean q -16.678411\n",
      "Episode:  2669 Reward: -200.0 Epsilon 0.1 mean q -16.672667\n",
      "Episode:  2670 Reward: -200.0 Epsilon 0.1 mean q -16.704496\n",
      "Episode:  2671 Reward: -200.0 Epsilon 0.1 mean q -16.682089\n",
      "Episode:  2672 Reward: -200.0 Epsilon 0.1 mean q -16.628845\n",
      "Episode:  2673 Reward: -200.0 Epsilon 0.1 mean q -16.641655\n",
      "Episode:  2674 Reward: -200.0 Epsilon 0.1 mean q -16.676563\n",
      "Episode:  2675 Reward: -200.0 Epsilon 0.1 mean q -16.6689\n",
      "Episode:  2676 Reward: -200.0 Epsilon 0.1 mean q -16.689425\n",
      "Episode:  2677 Reward: -200.0 Epsilon 0.1 mean q -16.687366\n",
      "Episode:  2678 Reward: -200.0 Epsilon 0.1 mean q -16.670387\n",
      "Episode:  2679 Reward: -200.0 Epsilon 0.1 mean q -16.681025\n",
      "Episode:  2680 Reward: -200.0 Epsilon 0.1 mean q -16.666384\n",
      "Episode:  2681 Reward: -200.0 Epsilon 0.1 mean q -16.676159\n",
      "Episode:  2682 Reward: -200.0 Epsilon 0.1 mean q -16.667027\n",
      "Episode:  2683 Reward: -200.0 Epsilon 0.1 mean q -16.672829\n",
      "Episode:  2684 Reward: -200.0 Epsilon 0.1 mean q -16.638977\n",
      "Episode:  2685 Reward: -200.0 Epsilon 0.1 mean q -16.638256\n",
      "Episode:  2686 Reward: -200.0 Epsilon 0.1 mean q -16.644121\n",
      "Episode:  2687 Reward: -200.0 Epsilon 0.1 mean q -16.648855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  2688 Reward: -200.0 Epsilon 0.1 mean q -16.664906\n",
      "Episode:  2689 Reward: -200.0 Epsilon 0.1 mean q -16.666168\n",
      "Episode:  2690 Reward: -200.0 Epsilon 0.1 mean q -16.686378\n",
      "Episode:  2691 Reward: -200.0 Epsilon 0.1 mean q -16.683407\n",
      "Episode:  2692 Reward: -200.0 Epsilon 0.1 mean q -16.690966\n",
      "Episode:  2693 Reward: -200.0 Epsilon 0.1 mean q -16.659586\n",
      "Episode:  2694 Reward: -200.0 Epsilon 0.1 mean q -16.670292\n",
      "Episode:  2695 Reward: -200.0 Epsilon 0.1 mean q -16.672092\n",
      "Episode:  2696 Reward: -200.0 Epsilon 0.1 mean q -16.671696\n",
      "Episode:  2697 Reward: -200.0 Epsilon 0.1 mean q -16.66921\n",
      "Episode:  2698 Reward: -200.0 Epsilon 0.1 mean q -16.684874\n",
      "Episode:  2699 Reward: -200.0 Epsilon 0.1 mean q -16.650497\n",
      "Episode:  2700 Reward: -200.0 Epsilon 0.1 mean q -16.678213\n",
      "Episode:  2701 Reward: -200.0 Epsilon 0.1 mean q -16.681038\n",
      "Episode:  2702 Reward: -200.0 Epsilon 0.1 mean q -16.66045\n",
      "Episode:  2703 Reward: -200.0 Epsilon 0.1 mean q -16.682768\n",
      "Episode:  2704 Reward: -200.0 Epsilon 0.1 mean q -16.673777\n",
      "Episode:  2705 Reward: -200.0 Epsilon 0.1 mean q -16.633627\n",
      "Episode:  2706 Reward: -200.0 Epsilon 0.1 mean q -16.658642\n",
      "Episode:  2707 Reward: -200.0 Epsilon 0.1 mean q -16.674105\n",
      "Episode:  2708 Reward: -200.0 Epsilon 0.1 mean q -16.67748\n",
      "Episode:  2709 Reward: -200.0 Epsilon 0.1 mean q -16.678993\n",
      "Episode:  2710 Reward: -200.0 Epsilon 0.1 mean q -16.69628\n",
      "Episode:  2711 Reward: -200.0 Epsilon 0.1 mean q -16.666254\n",
      "Episode:  2712 Reward: -200.0 Epsilon 0.1 mean q -16.661547\n",
      "Episode:  2713 Reward: -200.0 Epsilon 0.1 mean q -16.673906\n",
      "Episode:  2714 Reward: -200.0 Epsilon 0.1 mean q -16.67319\n",
      "Episode:  2715 Reward: -200.0 Epsilon 0.1 mean q -16.626131\n",
      "Episode:  2716 Reward: -200.0 Epsilon 0.1 mean q -16.650873\n",
      "Episode:  2717 Reward: -200.0 Epsilon 0.1 mean q -16.651705\n",
      "Episode:  2718 Reward: -200.0 Epsilon 0.1 mean q -16.66888\n",
      "Episode:  2719 Reward: -200.0 Epsilon 0.1 mean q -16.672945\n",
      "Episode:  2720 Reward: -200.0 Epsilon 0.1 mean q -16.653662\n",
      "Episode:  2721 Reward: -200.0 Epsilon 0.1 mean q -16.69628\n",
      "Episode:  2722 Reward: -200.0 Epsilon 0.1 mean q -16.686852\n",
      "Episode:  2723 Reward: -200.0 Epsilon 0.1 mean q -16.676752\n",
      "Episode:  2724 Reward: -200.0 Epsilon 0.1 mean q -16.647923\n",
      "Episode:  2725 Reward: -200.0 Epsilon 0.1 mean q -16.670921\n",
      "Episode:  2726 Reward: -200.0 Epsilon 0.1 mean q -16.681143\n",
      "Episode:  2727 Reward: -200.0 Epsilon 0.1 mean q -16.698105\n",
      "Episode:  2728 Reward: -200.0 Epsilon 0.1 mean q -16.685589\n",
      "Episode:  2729 Reward: -200.0 Epsilon 0.1 mean q -16.707045\n",
      "Episode:  2730 Reward: -200.0 Epsilon 0.1 mean q -16.662712\n",
      "Episode:  2731 Reward: -200.0 Epsilon 0.1 mean q -16.682835\n",
      "Episode:  2732 Reward: -200.0 Epsilon 0.1 mean q -16.669794\n",
      "Episode:  2733 Reward: -200.0 Epsilon 0.1 mean q -16.659224\n",
      "Episode:  2734 Reward: -200.0 Epsilon 0.1 mean q -16.66936\n",
      "Episode:  2735 Reward: -200.0 Epsilon 0.1 mean q -16.71818\n",
      "Episode:  2736 Reward: -200.0 Epsilon 0.1 mean q -16.674738\n",
      "Episode:  2737 Reward: -200.0 Epsilon 0.1 mean q -16.700388\n",
      "Episode:  2738 Reward: -200.0 Epsilon 0.1 mean q -16.673492\n",
      "Episode:  2739 Reward: -200.0 Epsilon 0.1 mean q -16.66986\n",
      "Episode:  2740 Reward: -200.0 Epsilon 0.1 mean q -16.662628\n",
      "Episode:  2741 Reward: -200.0 Epsilon 0.1 mean q -16.660688\n",
      "Episode:  2742 Reward: -200.0 Epsilon 0.1 mean q -16.695023\n",
      "Episode:  2743 Reward: -200.0 Epsilon 0.1 mean q -16.650583\n",
      "Episode:  2744 Reward: -200.0 Epsilon 0.1 mean q -16.646427\n",
      "Episode:  2745 Reward: -200.0 Epsilon 0.1 mean q -16.6182\n",
      "Episode:  2746 Reward: -200.0 Epsilon 0.1 mean q -16.662752\n",
      "Episode:  2747 Reward: -200.0 Epsilon 0.1 mean q -16.662273\n",
      "Episode:  2748 Reward: -200.0 Epsilon 0.1 mean q -16.659945\n",
      "Episode:  2749 Reward: -200.0 Epsilon 0.1 mean q -16.625559\n",
      "Episode:  2750 Reward: -200.0 Epsilon 0.1 mean q -16.664623\n",
      "Episode:  2751 Reward: -200.0 Epsilon 0.1 mean q -16.649677\n",
      "Episode:  2752 Reward: -200.0 Epsilon 0.1 mean q -16.700493\n",
      "Episode:  2753 Reward: -200.0 Epsilon 0.1 mean q -16.646894\n",
      "Episode:  2754 Reward: -200.0 Epsilon 0.1 mean q -16.657621\n",
      "Episode:  2755 Reward: -200.0 Epsilon 0.1 mean q -16.689499\n",
      "Episode:  2756 Reward: -200.0 Epsilon 0.1 mean q -16.676998\n",
      "Episode:  2757 Reward: -200.0 Epsilon 0.1 mean q -16.684767\n",
      "Episode:  2758 Reward: -200.0 Epsilon 0.1 mean q -16.650263\n",
      "Episode:  2759 Reward: -200.0 Epsilon 0.1 mean q -16.673698\n",
      "Episode:  2760 Reward: -200.0 Epsilon 0.1 mean q -16.675371\n",
      "Episode:  2761 Reward: -200.0 Epsilon 0.1 mean q -16.672314\n",
      "Episode:  2762 Reward: -200.0 Epsilon 0.1 mean q -16.668982\n",
      "Episode:  2763 Reward: -200.0 Epsilon 0.1 mean q -16.664326\n",
      "Episode:  2764 Reward: -200.0 Epsilon 0.1 mean q -16.68873\n",
      "Episode:  2765 Reward: -200.0 Epsilon 0.1 mean q -16.68164\n",
      "Episode:  2766 Reward: -200.0 Epsilon 0.1 mean q -16.705912\n",
      "Episode:  2767 Reward: -200.0 Epsilon 0.1 mean q -16.655252\n",
      "Episode:  2768 Reward: -200.0 Epsilon 0.1 mean q -16.688372\n",
      "Episode:  2769 Reward: -200.0 Epsilon 0.1 mean q -16.64528\n",
      "Episode:  2770 Reward: -200.0 Epsilon 0.1 mean q -16.698425\n",
      "Episode:  2771 Reward: -200.0 Epsilon 0.1 mean q -16.624872\n",
      "Episode:  2772 Reward: -200.0 Epsilon 0.1 mean q -16.660776\n",
      "Episode:  2773 Reward: -200.0 Epsilon 0.1 mean q -16.673746\n",
      "Episode:  2774 Reward: -200.0 Epsilon 0.1 mean q -16.678038\n",
      "Episode:  2775 Reward: -200.0 Epsilon 0.1 mean q -16.6661\n",
      "Episode:  2776 Reward: -200.0 Epsilon 0.1 mean q -16.636518\n",
      "Episode:  2777 Reward: -200.0 Epsilon 0.1 mean q -16.678843\n",
      "Episode:  2778 Reward: -200.0 Epsilon 0.1 mean q -16.688871\n",
      "Episode:  2779 Reward: -200.0 Epsilon 0.1 mean q -16.689175\n",
      "Episode:  2780 Reward: -200.0 Epsilon 0.1 mean q -16.680977\n",
      "Episode:  2781 Reward: -200.0 Epsilon 0.1 mean q -16.712814\n",
      "Episode:  2782 Reward: -200.0 Epsilon 0.1 mean q -16.690315\n",
      "Episode:  2783 Reward: -200.0 Epsilon 0.1 mean q -16.663874\n",
      "Episode:  2784 Reward: -200.0 Epsilon 0.1 mean q -16.683456\n",
      "Episode:  2785 Reward: -200.0 Epsilon 0.1 mean q -16.687572\n",
      "Episode:  2786 Reward: -200.0 Epsilon 0.1 mean q -16.653154\n",
      "Episode:  2787 Reward: -200.0 Epsilon 0.1 mean q -16.664248\n",
      "Episode:  2788 Reward: -200.0 Epsilon 0.1 mean q -16.67925\n",
      "Episode:  2789 Reward: -200.0 Epsilon 0.1 mean q -16.651922\n",
      "Episode:  2790 Reward: -200.0 Epsilon 0.1 mean q -16.66013\n",
      "Episode:  2791 Reward: -200.0 Epsilon 0.1 mean q -16.67592\n",
      "Episode:  2792 Reward: -200.0 Epsilon 0.1 mean q -16.663069\n",
      "Episode:  2793 Reward: -200.0 Epsilon 0.1 mean q -16.676823\n",
      "Episode:  2794 Reward: -200.0 Epsilon 0.1 mean q -16.66111\n",
      "Episode:  2795 Reward: -200.0 Epsilon 0.1 mean q -16.63687\n",
      "Episode:  2796 Reward: -200.0 Epsilon 0.1 mean q -16.665731\n",
      "Episode:  2797 Reward: -200.0 Epsilon 0.1 mean q -16.68058\n",
      "Episode:  2798 Reward: -200.0 Epsilon 0.1 mean q -16.681091\n",
      "Episode:  2799 Reward: -200.0 Epsilon 0.1 mean q -16.65778\n",
      "Episode:  2800 Reward: -200.0 Epsilon 0.1 mean q -16.656277\n",
      "Episode:  2801 Reward: -200.0 Epsilon 0.1 mean q -16.65893\n",
      "Episode:  2802 Reward: -200.0 Epsilon 0.1 mean q -16.647535\n",
      "Episode:  2803 Reward: -200.0 Epsilon 0.1 mean q -16.646278\n",
      "Episode:  2804 Reward: -200.0 Epsilon 0.1 mean q -16.676273\n",
      "Episode:  2805 Reward: -200.0 Epsilon 0.1 mean q -16.656666\n",
      "Episode:  2806 Reward: -200.0 Epsilon 0.1 mean q -16.667707\n",
      "Episode:  2807 Reward: -200.0 Epsilon 0.1 mean q -16.665155\n",
      "Episode:  2808 Reward: -200.0 Epsilon 0.1 mean q -16.655142\n",
      "Episode:  2809 Reward: -200.0 Epsilon 0.1 mean q -16.646982\n",
      "Episode:  2810 Reward: -200.0 Epsilon 0.1 mean q -16.671667\n",
      "Episode:  2811 Reward: -200.0 Epsilon 0.1 mean q -16.654282\n",
      "Episode:  2812 Reward: -200.0 Epsilon 0.1 mean q -16.656218\n",
      "Episode:  2813 Reward: -200.0 Epsilon 0.1 mean q -16.663134\n",
      "Episode:  2814 Reward: -200.0 Epsilon 0.1 mean q -16.658419\n",
      "Episode:  2815 Reward: -200.0 Epsilon 0.1 mean q -16.682806\n",
      "Episode:  2816 Reward: -200.0 Epsilon 0.1 mean q -16.66807\n",
      "Episode:  2817 Reward: -200.0 Epsilon 0.1 mean q -16.690102\n",
      "Episode:  2818 Reward: -200.0 Epsilon 0.1 mean q -16.68512\n",
      "Episode:  2819 Reward: -200.0 Epsilon 0.1 mean q -16.674812\n",
      "Episode:  2820 Reward: -200.0 Epsilon 0.1 mean q -16.676952\n",
      "Episode:  2821 Reward: -200.0 Epsilon 0.1 mean q -16.67903\n",
      "Episode:  2822 Reward: -200.0 Epsilon 0.1 mean q -16.652681\n",
      "Episode:  2823 Reward: -200.0 Epsilon 0.1 mean q -16.670668\n",
      "Episode:  2824 Reward: -200.0 Epsilon 0.1 mean q -16.700863\n",
      "Episode:  2825 Reward: -200.0 Epsilon 0.1 mean q -16.666697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  2826 Reward: -200.0 Epsilon 0.1 mean q -16.673018\n",
      "Episode:  2827 Reward: -200.0 Epsilon 0.1 mean q -16.663673\n",
      "Episode:  2828 Reward: -200.0 Epsilon 0.1 mean q -16.659086\n",
      "Episode:  2829 Reward: -200.0 Epsilon 0.1 mean q -16.66135\n",
      "Episode:  2830 Reward: -200.0 Epsilon 0.1 mean q -16.684\n",
      "Episode:  2831 Reward: -200.0 Epsilon 0.1 mean q -16.658873\n",
      "Episode:  2832 Reward: -200.0 Epsilon 0.1 mean q -16.64874\n",
      "Episode:  2833 Reward: -200.0 Epsilon 0.1 mean q -16.6656\n",
      "Episode:  2834 Reward: -200.0 Epsilon 0.1 mean q -16.66526\n",
      "Episode:  2835 Reward: -200.0 Epsilon 0.1 mean q -16.652464\n",
      "Episode:  2836 Reward: -200.0 Epsilon 0.1 mean q -16.669928\n",
      "Episode:  2837 Reward: -200.0 Epsilon 0.1 mean q -16.667683\n",
      "Episode:  2838 Reward: -200.0 Epsilon 0.1 mean q -16.653662\n",
      "Episode:  2839 Reward: -200.0 Epsilon 0.1 mean q -16.674524\n",
      "Episode:  2840 Reward: -200.0 Epsilon 0.1 mean q -16.673769\n",
      "Episode:  2841 Reward: -200.0 Epsilon 0.1 mean q -16.701382\n",
      "Episode:  2842 Reward: -200.0 Epsilon 0.1 mean q -16.65802\n",
      "Episode:  2843 Reward: -200.0 Epsilon 0.1 mean q -16.669111\n",
      "Episode:  2844 Reward: -200.0 Epsilon 0.1 mean q -16.661966\n",
      "Episode:  2845 Reward: -200.0 Epsilon 0.1 mean q -16.66059\n",
      "Episode:  2846 Reward: -200.0 Epsilon 0.1 mean q -16.655212\n",
      "Episode:  2847 Reward: -200.0 Epsilon 0.1 mean q -16.689548\n",
      "Episode:  2848 Reward: -200.0 Epsilon 0.1 mean q -16.68057\n",
      "Episode:  2849 Reward: -200.0 Epsilon 0.1 mean q -16.696451\n",
      "Episode:  2850 Reward: -200.0 Epsilon 0.1 mean q -16.674265\n",
      "Episode:  2851 Reward: -200.0 Epsilon 0.1 mean q -16.685755\n",
      "Episode:  2852 Reward: -200.0 Epsilon 0.1 mean q -16.692286\n",
      "Episode:  2853 Reward: -200.0 Epsilon 0.1 mean q -16.673046\n",
      "Episode:  2854 Reward: -200.0 Epsilon 0.1 mean q -16.669296\n",
      "Episode:  2855 Reward: -200.0 Epsilon 0.1 mean q -16.677078\n",
      "Episode:  2856 Reward: -200.0 Epsilon 0.1 mean q -16.67329\n",
      "Episode:  2857 Reward: -200.0 Epsilon 0.1 mean q -16.682243\n",
      "Episode:  2858 Reward: -200.0 Epsilon 0.1 mean q -16.712032\n",
      "Episode:  2859 Reward: -200.0 Epsilon 0.1 mean q -16.695892\n",
      "Episode:  2860 Reward: -200.0 Epsilon 0.1 mean q -16.671175\n",
      "Episode:  2861 Reward: -200.0 Epsilon 0.1 mean q -16.661453\n",
      "Episode:  2862 Reward: -200.0 Epsilon 0.1 mean q -16.660807\n",
      "Episode:  2863 Reward: -200.0 Epsilon 0.1 mean q -16.667913\n",
      "Episode:  2864 Reward: -200.0 Epsilon 0.1 mean q -16.665455\n",
      "Episode:  2865 Reward: -200.0 Epsilon 0.1 mean q -16.648129\n",
      "Episode:  2866 Reward: -200.0 Epsilon 0.1 mean q -16.665876\n",
      "Episode:  2867 Reward: -200.0 Epsilon 0.1 mean q -16.664335\n",
      "Episode:  2868 Reward: -200.0 Epsilon 0.1 mean q -16.635363\n",
      "Episode:  2869 Reward: -200.0 Epsilon 0.1 mean q -16.664547\n",
      "Episode:  2870 Reward: -200.0 Epsilon 0.1 mean q -16.657055\n",
      "Episode:  2871 Reward: -200.0 Epsilon 0.1 mean q -16.634798\n",
      "Episode:  2872 Reward: -200.0 Epsilon 0.1 mean q -16.674013\n",
      "Episode:  2873 Reward: -200.0 Epsilon 0.1 mean q -16.662096\n",
      "Episode:  2874 Reward: -200.0 Epsilon 0.1 mean q -16.691442\n",
      "Episode:  2875 Reward: -200.0 Epsilon 0.1 mean q -16.655622\n",
      "Episode:  2876 Reward: -200.0 Epsilon 0.1 mean q -16.678198\n",
      "Episode:  2877 Reward: -200.0 Epsilon 0.1 mean q -16.664783\n",
      "Episode:  2878 Reward: -200.0 Epsilon 0.1 mean q -16.653822\n",
      "Episode:  2879 Reward: -200.0 Epsilon 0.1 mean q -16.636387\n",
      "Episode:  2880 Reward: -200.0 Epsilon 0.1 mean q -16.671593\n",
      "Episode:  2881 Reward: -200.0 Epsilon 0.1 mean q -16.6515\n",
      "Episode:  2882 Reward: -200.0 Epsilon 0.1 mean q -16.663399\n",
      "Episode:  2883 Reward: -200.0 Epsilon 0.1 mean q -16.66117\n",
      "Episode:  2884 Reward: -200.0 Epsilon 0.1 mean q -16.688555\n",
      "Episode:  2885 Reward: -200.0 Epsilon 0.1 mean q -16.643612\n",
      "Episode:  2886 Reward: -200.0 Epsilon 0.1 mean q -16.676575\n",
      "Episode:  2887 Reward: -200.0 Epsilon 0.1 mean q -16.675482\n",
      "Episode:  2888 Reward: -200.0 Epsilon 0.1 mean q -16.67798\n",
      "Episode:  2889 Reward: -200.0 Epsilon 0.1 mean q -16.667768\n",
      "Episode:  2890 Reward: -200.0 Epsilon 0.1 mean q -16.657764\n",
      "Episode:  2891 Reward: -200.0 Epsilon 0.1 mean q -16.646534\n",
      "Episode:  2892 Reward: -200.0 Epsilon 0.1 mean q -16.657734\n",
      "Episode:  2893 Reward: -200.0 Epsilon 0.1 mean q -16.705751\n",
      "Episode:  2894 Reward: -200.0 Epsilon 0.1 mean q -16.669428\n",
      "Episode:  2895 Reward: -200.0 Epsilon 0.1 mean q -16.659378\n",
      "Episode:  2896 Reward: -200.0 Epsilon 0.1 mean q -16.659994\n",
      "Episode:  2897 Reward: -200.0 Epsilon 0.1 mean q -16.667208\n",
      "Episode:  2898 Reward: -200.0 Epsilon 0.1 mean q -16.660566\n",
      "Episode:  2899 Reward: -200.0 Epsilon 0.1 mean q -16.682295\n",
      "Episode:  2900 Reward: -200.0 Epsilon 0.1 mean q -16.657656\n",
      "Episode:  2901 Reward: -200.0 Epsilon 0.1 mean q -16.689983\n",
      "Episode:  2902 Reward: -200.0 Epsilon 0.1 mean q -16.686699\n",
      "Episode:  2903 Reward: -200.0 Epsilon 0.1 mean q -16.665432\n",
      "Episode:  2904 Reward: -200.0 Epsilon 0.1 mean q -16.700014\n",
      "Episode:  2905 Reward: -200.0 Epsilon 0.1 mean q -16.675455\n",
      "Episode:  2906 Reward: -200.0 Epsilon 0.1 mean q -16.663353\n",
      "Episode:  2907 Reward: -200.0 Epsilon 0.1 mean q -16.668089\n",
      "Episode:  2908 Reward: -200.0 Epsilon 0.1 mean q -16.669561\n",
      "Episode:  2909 Reward: -200.0 Epsilon 0.1 mean q -16.686989\n",
      "Episode:  2910 Reward: -200.0 Epsilon 0.1 mean q -16.65496\n",
      "Episode:  2911 Reward: -200.0 Epsilon 0.1 mean q -16.696367\n",
      "Episode:  2912 Reward: -200.0 Epsilon 0.1 mean q -16.695742\n",
      "Episode:  2913 Reward: -200.0 Epsilon 0.1 mean q -16.678047\n",
      "Episode:  2914 Reward: -200.0 Epsilon 0.1 mean q -16.63325\n",
      "Episode:  2915 Reward: -200.0 Epsilon 0.1 mean q -16.67111\n",
      "Episode:  2916 Reward: -200.0 Epsilon 0.1 mean q -16.650293\n",
      "Episode:  2917 Reward: -200.0 Epsilon 0.1 mean q -16.664812\n",
      "Episode:  2918 Reward: -200.0 Epsilon 0.1 mean q -16.684122\n",
      "Episode:  2919 Reward: -200.0 Epsilon 0.1 mean q -16.68234\n",
      "Episode:  2920 Reward: -200.0 Epsilon 0.1 mean q -16.661139\n",
      "Episode:  2921 Reward: -200.0 Epsilon 0.1 mean q -16.64898\n",
      "Episode:  2922 Reward: -200.0 Epsilon 0.1 mean q -16.68096\n",
      "Episode:  2923 Reward: -200.0 Epsilon 0.1 mean q -16.680286\n",
      "Episode:  2924 Reward: -200.0 Epsilon 0.1 mean q -16.684805\n",
      "Episode:  2925 Reward: -200.0 Epsilon 0.1 mean q -16.646221\n",
      "Episode:  2926 Reward: -200.0 Epsilon 0.1 mean q -16.640333\n",
      "Episode:  2927 Reward: -200.0 Epsilon 0.1 mean q -16.689207\n",
      "Episode:  2928 Reward: -200.0 Epsilon 0.1 mean q -16.678007\n",
      "Episode:  2929 Reward: -200.0 Epsilon 0.1 mean q -16.652998\n",
      "Episode:  2930 Reward: -200.0 Epsilon 0.1 mean q -16.66499\n",
      "Episode:  2931 Reward: -200.0 Epsilon 0.1 mean q -16.678762\n",
      "Episode:  2932 Reward: -200.0 Epsilon 0.1 mean q -16.642408\n",
      "Episode:  2933 Reward: -200.0 Epsilon 0.1 mean q -16.68577\n",
      "Episode:  2934 Reward: -200.0 Epsilon 0.1 mean q -16.648731\n",
      "Episode:  2935 Reward: -200.0 Epsilon 0.1 mean q -16.677885\n",
      "Episode:  2936 Reward: -200.0 Epsilon 0.1 mean q -16.6715\n",
      "Episode:  2937 Reward: -200.0 Epsilon 0.1 mean q -16.618528\n",
      "Episode:  2938 Reward: -200.0 Epsilon 0.1 mean q -16.668364\n",
      "Episode:  2939 Reward: -200.0 Epsilon 0.1 mean q -16.674023\n",
      "Episode:  2940 Reward: -200.0 Epsilon 0.1 mean q -16.669176\n",
      "Episode:  2941 Reward: -200.0 Epsilon 0.1 mean q -16.676643\n",
      "Episode:  2942 Reward: -200.0 Epsilon 0.1 mean q -16.69369\n",
      "Episode:  2943 Reward: -200.0 Epsilon 0.1 mean q -16.657377\n",
      "Episode:  2944 Reward: -200.0 Epsilon 0.1 mean q -16.681566\n",
      "Episode:  2945 Reward: -200.0 Epsilon 0.1 mean q -16.663046\n",
      "Episode:  2946 Reward: -200.0 Epsilon 0.1 mean q -16.651106\n",
      "Episode:  2947 Reward: -200.0 Epsilon 0.1 mean q -16.680359\n",
      "Episode:  2948 Reward: -200.0 Epsilon 0.1 mean q -16.658201\n",
      "Episode:  2949 Reward: -200.0 Epsilon 0.1 mean q -16.687923\n",
      "Episode:  2950 Reward: -200.0 Epsilon 0.1 mean q -16.65462\n",
      "Episode:  2951 Reward: -200.0 Epsilon 0.1 mean q -16.635414\n",
      "Episode:  2952 Reward: -200.0 Epsilon 0.1 mean q -16.681503\n",
      "Episode:  2953 Reward: -200.0 Epsilon 0.1 mean q -16.642845\n",
      "Episode:  2954 Reward: -200.0 Epsilon 0.1 mean q -16.651522\n",
      "Episode:  2955 Reward: -200.0 Epsilon 0.1 mean q -16.671713\n",
      "Episode:  2956 Reward: -200.0 Epsilon 0.1 mean q -16.65823\n",
      "Episode:  2957 Reward: -200.0 Epsilon 0.1 mean q -16.6449\n",
      "Episode:  2958 Reward: -200.0 Epsilon 0.1 mean q -16.657696\n",
      "Episode:  2959 Reward: -200.0 Epsilon 0.1 mean q -16.65706\n",
      "Episode:  2960 Reward: -200.0 Epsilon 0.1 mean q -16.674816\n",
      "Episode:  2961 Reward: -200.0 Epsilon 0.1 mean q -16.666367\n",
      "Episode:  2962 Reward: -200.0 Epsilon 0.1 mean q -16.65982\n",
      "Episode:  2963 Reward: -200.0 Epsilon 0.1 mean q -16.637022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  2964 Reward: -200.0 Epsilon 0.1 mean q -16.623901\n",
      "Episode:  2965 Reward: -200.0 Epsilon 0.1 mean q -16.647322\n",
      "Episode:  2966 Reward: -200.0 Epsilon 0.1 mean q -16.644636\n",
      "Episode:  2967 Reward: -200.0 Epsilon 0.1 mean q -16.655266\n",
      "Episode:  2968 Reward: -200.0 Epsilon 0.1 mean q -16.65878\n",
      "Episode:  2969 Reward: -200.0 Epsilon 0.1 mean q -16.657845\n",
      "Episode:  2970 Reward: -200.0 Epsilon 0.1 mean q -16.616686\n",
      "Episode:  2971 Reward: -200.0 Epsilon 0.1 mean q -16.671852\n",
      "Episode:  2972 Reward: -200.0 Epsilon 0.1 mean q -16.616457\n",
      "Episode:  2973 Reward: -200.0 Epsilon 0.1 mean q -16.647572\n",
      "Episode:  2974 Reward: -200.0 Epsilon 0.1 mean q -16.691477\n",
      "Episode:  2975 Reward: -200.0 Epsilon 0.1 mean q -16.701214\n",
      "Episode:  2976 Reward: -200.0 Epsilon 0.1 mean q -16.676796\n",
      "Episode:  2977 Reward: -200.0 Epsilon 0.1 mean q -16.682669\n",
      "Episode:  2978 Reward: -200.0 Epsilon 0.1 mean q -16.67259\n",
      "Episode:  2979 Reward: -200.0 Epsilon 0.1 mean q -16.646276\n",
      "Episode:  2980 Reward: -200.0 Epsilon 0.1 mean q -16.693594\n",
      "Episode:  2981 Reward: -200.0 Epsilon 0.1 mean q -16.636305\n",
      "Episode:  2982 Reward: -200.0 Epsilon 0.1 mean q -16.67154\n",
      "Episode:  2983 Reward: -200.0 Epsilon 0.1 mean q -16.62161\n",
      "Episode:  2984 Reward: -200.0 Epsilon 0.1 mean q -16.65326\n",
      "Episode:  2985 Reward: -200.0 Epsilon 0.1 mean q -16.698017\n",
      "Episode:  2986 Reward: -200.0 Epsilon 0.1 mean q -16.665\n",
      "Episode:  2987 Reward: -200.0 Epsilon 0.1 mean q -16.668274\n",
      "Episode:  2988 Reward: -200.0 Epsilon 0.1 mean q -16.662106\n",
      "Episode:  2989 Reward: -200.0 Epsilon 0.1 mean q -16.653471\n",
      "Episode:  2990 Reward: -200.0 Epsilon 0.1 mean q -16.706861\n",
      "Episode:  2991 Reward: -200.0 Epsilon 0.1 mean q -16.683672\n",
      "Episode:  2992 Reward: -200.0 Epsilon 0.1 mean q -16.695917\n",
      "Episode:  2993 Reward: -200.0 Epsilon 0.1 mean q -16.657042\n",
      "Episode:  2994 Reward: -200.0 Epsilon 0.1 mean q -16.663757\n",
      "Episode:  2995 Reward: -200.0 Epsilon 0.1 mean q -16.675976\n",
      "Episode:  2996 Reward: -200.0 Epsilon 0.1 mean q -16.647726\n",
      "Episode:  2997 Reward: -200.0 Epsilon 0.1 mean q -16.655384\n",
      "Episode:  2998 Reward: -200.0 Epsilon 0.1 mean q -16.66761\n",
      "Episode:  2999 Reward: -200.0 Epsilon 0.1 mean q -16.631952\n",
      "Episode:  3000 Reward: -200.0 Epsilon 0.1 mean q -16.631573\n",
      "Episode:  3001 Reward: -200.0 Epsilon 0.1 mean q -16.668488\n",
      "Episode:  3002 Reward: -200.0 Epsilon 0.1 mean q -16.62319\n",
      "Episode:  3003 Reward: -200.0 Epsilon 0.1 mean q -16.675566\n",
      "Episode:  3004 Reward: -200.0 Epsilon 0.1 mean q -16.652416\n",
      "Episode:  3005 Reward: -200.0 Epsilon 0.1 mean q -16.673948\n",
      "Episode:  3006 Reward: -200.0 Epsilon 0.1 mean q -16.689358\n",
      "Episode:  3007 Reward: -200.0 Epsilon 0.1 mean q -16.667208\n",
      "Episode:  3008 Reward: -200.0 Epsilon 0.1 mean q -16.66115\n",
      "Episode:  3009 Reward: -200.0 Epsilon 0.1 mean q -16.659353\n",
      "Episode:  3010 Reward: -200.0 Epsilon 0.1 mean q -16.65198\n",
      "Episode:  3011 Reward: -200.0 Epsilon 0.1 mean q -16.61483\n",
      "Episode:  3012 Reward: -200.0 Epsilon 0.1 mean q -16.645111\n",
      "Episode:  3013 Reward: -200.0 Epsilon 0.1 mean q -16.648643\n",
      "Episode:  3014 Reward: -200.0 Epsilon 0.1 mean q -16.676615\n",
      "Episode:  3015 Reward: -200.0 Epsilon 0.1 mean q -16.669102\n",
      "Episode:  3016 Reward: -200.0 Epsilon 0.1 mean q -16.665094\n",
      "Episode:  3017 Reward: -200.0 Epsilon 0.1 mean q -16.633429\n",
      "Episode:  3018 Reward: -200.0 Epsilon 0.1 mean q -16.662958\n",
      "Episode:  3019 Reward: -200.0 Epsilon 0.1 mean q -16.66646\n",
      "Episode:  3020 Reward: -200.0 Epsilon 0.1 mean q -16.639896\n",
      "Episode:  3021 Reward: -200.0 Epsilon 0.1 mean q -16.657095\n",
      "Episode:  3022 Reward: -200.0 Epsilon 0.1 mean q -16.715315\n",
      "Episode:  3023 Reward: -200.0 Epsilon 0.1 mean q -16.622223\n",
      "Episode:  3024 Reward: -200.0 Epsilon 0.1 mean q -16.68186\n",
      "Episode:  3025 Reward: -200.0 Epsilon 0.1 mean q -16.676975\n",
      "Episode:  3026 Reward: -200.0 Epsilon 0.1 mean q -16.687849\n",
      "Episode:  3027 Reward: -200.0 Epsilon 0.1 mean q -16.678438\n",
      "Episode:  3028 Reward: -200.0 Epsilon 0.1 mean q -16.651442\n",
      "Episode:  3029 Reward: -200.0 Epsilon 0.1 mean q -16.663647\n",
      "Episode:  3030 Reward: -200.0 Epsilon 0.1 mean q -16.677338\n",
      "Episode:  3031 Reward: -200.0 Epsilon 0.1 mean q -16.662233\n",
      "Episode:  3032 Reward: -200.0 Epsilon 0.1 mean q -16.64044\n",
      "Episode:  3033 Reward: -200.0 Epsilon 0.1 mean q -16.678944\n",
      "Episode:  3034 Reward: -200.0 Epsilon 0.1 mean q -16.687155\n",
      "Episode:  3035 Reward: -200.0 Epsilon 0.1 mean q -16.647898\n",
      "Episode:  3036 Reward: -200.0 Epsilon 0.1 mean q -16.689175\n",
      "Episode:  3037 Reward: -200.0 Epsilon 0.1 mean q -16.707125\n",
      "Episode:  3038 Reward: -200.0 Epsilon 0.1 mean q -16.665115\n",
      "Episode:  3039 Reward: -200.0 Epsilon 0.1 mean q -16.655401\n",
      "Episode:  3040 Reward: -200.0 Epsilon 0.1 mean q -16.694452\n",
      "Episode:  3041 Reward: -200.0 Epsilon 0.1 mean q -16.665098\n",
      "Episode:  3042 Reward: -200.0 Epsilon 0.1 mean q -16.679768\n",
      "Episode:  3043 Reward: -200.0 Epsilon 0.1 mean q -16.656523\n",
      "Episode:  3044 Reward: -200.0 Epsilon 0.1 mean q -16.648651\n",
      "Episode:  3045 Reward: -200.0 Epsilon 0.1 mean q -16.625631\n",
      "Episode:  3046 Reward: -200.0 Epsilon 0.1 mean q -16.638847\n",
      "Episode:  3047 Reward: -200.0 Epsilon 0.1 mean q -16.665012\n",
      "Episode:  3048 Reward: -200.0 Epsilon 0.1 mean q -16.640602\n",
      "Episode:  3049 Reward: -200.0 Epsilon 0.1 mean q -16.686218\n",
      "Episode:  3050 Reward: -200.0 Epsilon 0.1 mean q -16.665495\n",
      "Episode:  3051 Reward: -200.0 Epsilon 0.1 mean q -16.713587\n",
      "Episode:  3052 Reward: -200.0 Epsilon 0.1 mean q -16.71393\n",
      "Episode:  3053 Reward: -200.0 Epsilon 0.1 mean q -16.728558\n",
      "Episode:  3054 Reward: -200.0 Epsilon 0.1 mean q -16.674004\n",
      "Episode:  3055 Reward: -200.0 Epsilon 0.1 mean q -16.647589\n",
      "Episode:  3056 Reward: -200.0 Epsilon 0.1 mean q -16.700182\n",
      "Episode:  3057 Reward: -200.0 Epsilon 0.1 mean q -16.670074\n",
      "Episode:  3058 Reward: -200.0 Epsilon 0.1 mean q -16.655312\n",
      "Episode:  3059 Reward: -200.0 Epsilon 0.1 mean q -16.690512\n",
      "Episode:  3060 Reward: -200.0 Epsilon 0.1 mean q -16.699858\n",
      "Episode:  3061 Reward: -200.0 Epsilon 0.1 mean q -16.68071\n",
      "Episode:  3062 Reward: -200.0 Epsilon 0.1 mean q -16.68311\n",
      "Episode:  3063 Reward: -200.0 Epsilon 0.1 mean q -16.684248\n",
      "Episode:  3064 Reward: -200.0 Epsilon 0.1 mean q -16.664412\n",
      "Episode:  3065 Reward: -200.0 Epsilon 0.1 mean q -16.674063\n",
      "Episode:  3066 Reward: -200.0 Epsilon 0.1 mean q -16.645502\n",
      "Episode:  3067 Reward: -200.0 Epsilon 0.1 mean q -16.665033\n",
      "Episode:  3068 Reward: -200.0 Epsilon 0.1 mean q -16.695414\n",
      "Episode:  3069 Reward: -200.0 Epsilon 0.1 mean q -16.696802\n",
      "Episode:  3070 Reward: -200.0 Epsilon 0.1 mean q -16.650635\n",
      "Episode:  3071 Reward: -200.0 Epsilon 0.1 mean q -16.676022\n",
      "Episode:  3072 Reward: -200.0 Epsilon 0.1 mean q -16.66297\n",
      "Episode:  3073 Reward: -200.0 Epsilon 0.1 mean q -16.696114\n",
      "Episode:  3074 Reward: -200.0 Epsilon 0.1 mean q -16.662252\n",
      "Episode:  3075 Reward: -200.0 Epsilon 0.1 mean q -16.678598\n",
      "Episode:  3076 Reward: -200.0 Epsilon 0.1 mean q -16.68178\n",
      "Episode:  3077 Reward: -200.0 Epsilon 0.1 mean q -16.666286\n",
      "Episode:  3078 Reward: -200.0 Epsilon 0.1 mean q -16.66936\n",
      "Episode:  3079 Reward: -200.0 Epsilon 0.1 mean q -16.637642\n",
      "Episode:  3080 Reward: -200.0 Epsilon 0.1 mean q -16.665827\n",
      "Episode:  3081 Reward: -200.0 Epsilon 0.1 mean q -16.630997\n",
      "Episode:  3082 Reward: -200.0 Epsilon 0.1 mean q -16.664034\n",
      "Episode:  3083 Reward: -200.0 Epsilon 0.1 mean q -16.698402\n",
      "Episode:  3084 Reward: -200.0 Epsilon 0.1 mean q -16.644197\n",
      "Episode:  3085 Reward: -200.0 Epsilon 0.1 mean q -16.64659\n",
      "Episode:  3086 Reward: -200.0 Epsilon 0.1 mean q -16.643297\n",
      "Episode:  3087 Reward: -200.0 Epsilon 0.1 mean q -16.695105\n",
      "Episode:  3088 Reward: -200.0 Epsilon 0.1 mean q -16.661129\n",
      "Episode:  3089 Reward: -200.0 Epsilon 0.1 mean q -16.703701\n",
      "Episode:  3090 Reward: -200.0 Epsilon 0.1 mean q -16.665651\n",
      "Episode:  3091 Reward: -200.0 Epsilon 0.1 mean q -16.673283\n",
      "Episode:  3092 Reward: -200.0 Epsilon 0.1 mean q -16.664886\n",
      "Episode:  3093 Reward: -200.0 Epsilon 0.1 mean q -16.67815\n",
      "Episode:  3094 Reward: -200.0 Epsilon 0.1 mean q -16.678883\n",
      "Episode:  3095 Reward: -200.0 Epsilon 0.1 mean q -16.650518\n",
      "Episode:  3096 Reward: -200.0 Epsilon 0.1 mean q -16.655258\n",
      "Episode:  3097 Reward: -200.0 Epsilon 0.1 mean q -16.676195\n",
      "Episode:  3098 Reward: -200.0 Epsilon 0.1 mean q -16.662144\n",
      "Episode:  3099 Reward: -200.0 Epsilon 0.1 mean q -16.64224\n",
      "Episode:  3100 Reward: -200.0 Epsilon 0.1 mean q -16.651144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  3101 Reward: -200.0 Epsilon 0.1 mean q -16.667751\n",
      "Episode:  3102 Reward: -200.0 Epsilon 0.1 mean q -16.670027\n",
      "Episode:  3103 Reward: -200.0 Epsilon 0.1 mean q -16.672073\n",
      "Episode:  3104 Reward: -200.0 Epsilon 0.1 mean q -16.65731\n",
      "Episode:  3105 Reward: -200.0 Epsilon 0.1 mean q -16.679893\n",
      "Episode:  3106 Reward: -200.0 Epsilon 0.1 mean q -16.640297\n",
      "Episode:  3107 Reward: -200.0 Epsilon 0.1 mean q -16.634165\n",
      "Episode:  3108 Reward: -200.0 Epsilon 0.1 mean q -16.649519\n",
      "Episode:  3109 Reward: -200.0 Epsilon 0.1 mean q -16.66235\n",
      "Episode:  3110 Reward: -200.0 Epsilon 0.1 mean q -16.67719\n",
      "Episode:  3111 Reward: -200.0 Epsilon 0.1 mean q -16.66374\n",
      "Episode:  3112 Reward: -200.0 Epsilon 0.1 mean q -16.672731\n",
      "Episode:  3113 Reward: -200.0 Epsilon 0.1 mean q -16.660517\n",
      "Episode:  3114 Reward: -200.0 Epsilon 0.1 mean q -16.637552\n",
      "Episode:  3115 Reward: -200.0 Epsilon 0.1 mean q -16.675425\n",
      "Episode:  3116 Reward: -200.0 Epsilon 0.1 mean q -16.703428\n",
      "Episode:  3117 Reward: -200.0 Epsilon 0.1 mean q -16.63243\n",
      "Episode:  3118 Reward: -200.0 Epsilon 0.1 mean q -16.704294\n",
      "Episode:  3119 Reward: -200.0 Epsilon 0.1 mean q -16.64559\n",
      "Episode:  3120 Reward: -200.0 Epsilon 0.1 mean q -16.687973\n",
      "Episode:  3121 Reward: -200.0 Epsilon 0.1 mean q -16.675926\n",
      "Episode:  3122 Reward: -200.0 Epsilon 0.1 mean q -16.678146\n",
      "Episode:  3123 Reward: -200.0 Epsilon 0.1 mean q -16.671852\n",
      "Episode:  3124 Reward: -200.0 Epsilon 0.1 mean q -16.694704\n",
      "Episode:  3125 Reward: -200.0 Epsilon 0.1 mean q -16.664837\n",
      "Episode:  3126 Reward: -200.0 Epsilon 0.1 mean q -16.689028\n",
      "Episode:  3127 Reward: -200.0 Epsilon 0.1 mean q -16.673906\n",
      "Episode:  3128 Reward: -200.0 Epsilon 0.1 mean q -16.666885\n",
      "Episode:  3129 Reward: -200.0 Epsilon 0.1 mean q -16.68875\n",
      "Episode:  3130 Reward: -200.0 Epsilon 0.1 mean q -16.670095\n",
      "Episode:  3131 Reward: -200.0 Epsilon 0.1 mean q -16.644247\n",
      "Episode:  3132 Reward: -200.0 Epsilon 0.1 mean q -16.651094\n",
      "Episode:  3133 Reward: -200.0 Epsilon 0.1 mean q -16.671833\n",
      "Episode:  3134 Reward: -200.0 Epsilon 0.1 mean q -16.654757\n",
      "Episode:  3135 Reward: -200.0 Epsilon 0.1 mean q -16.670742\n",
      "Episode:  3136 Reward: -200.0 Epsilon 0.1 mean q -16.675768\n",
      "Episode:  3137 Reward: -200.0 Epsilon 0.1 mean q -16.681341\n",
      "Episode:  3138 Reward: -200.0 Epsilon 0.1 mean q -16.69297\n",
      "Episode:  3139 Reward: -200.0 Epsilon 0.1 mean q -16.644915\n",
      "Episode:  3140 Reward: -200.0 Epsilon 0.1 mean q -16.666948\n",
      "Episode:  3141 Reward: -200.0 Epsilon 0.1 mean q -16.716028\n",
      "Episode:  3142 Reward: -200.0 Epsilon 0.1 mean q -16.680166\n",
      "Episode:  3143 Reward: -200.0 Epsilon 0.1 mean q -16.65989\n",
      "Episode:  3144 Reward: -200.0 Epsilon 0.1 mean q -16.6709\n",
      "Episode:  3145 Reward: -200.0 Epsilon 0.1 mean q -16.668474\n",
      "Episode:  3146 Reward: -200.0 Epsilon 0.1 mean q -16.687279\n",
      "Episode:  3147 Reward: -200.0 Epsilon 0.1 mean q -16.651394\n",
      "Episode:  3148 Reward: -200.0 Epsilon 0.1 mean q -16.692526\n",
      "Episode:  3149 Reward: -200.0 Epsilon 0.1 mean q -16.676435\n",
      "Episode:  3150 Reward: -200.0 Epsilon 0.1 mean q -16.654457\n",
      "Episode:  3151 Reward: -200.0 Epsilon 0.1 mean q -16.692598\n",
      "Episode:  3152 Reward: -200.0 Epsilon 0.1 mean q -16.688158\n",
      "Episode:  3153 Reward: -200.0 Epsilon 0.1 mean q -16.666641\n",
      "Episode:  3154 Reward: -200.0 Epsilon 0.1 mean q -16.6652\n",
      "Episode:  3155 Reward: -200.0 Epsilon 0.1 mean q -16.654444\n",
      "Episode:  3156 Reward: -200.0 Epsilon 0.1 mean q -16.637135\n",
      "Episode:  3157 Reward: -200.0 Epsilon 0.1 mean q -16.667053\n",
      "Episode:  3158 Reward: -200.0 Epsilon 0.1 mean q -16.677752\n",
      "Episode:  3159 Reward: -200.0 Epsilon 0.1 mean q -16.69274\n",
      "Episode:  3160 Reward: -200.0 Epsilon 0.1 mean q -16.695993\n",
      "Episode:  3161 Reward: -200.0 Epsilon 0.1 mean q -16.671133\n",
      "Episode:  3162 Reward: -200.0 Epsilon 0.1 mean q -16.64416\n",
      "Episode:  3163 Reward: -200.0 Epsilon 0.1 mean q -16.657257\n",
      "Episode:  3164 Reward: -200.0 Epsilon 0.1 mean q -16.647291\n",
      "Episode:  3165 Reward: -200.0 Epsilon 0.1 mean q -16.670876\n",
      "Episode:  3166 Reward: -200.0 Epsilon 0.1 mean q -16.680084\n",
      "Episode:  3167 Reward: -200.0 Epsilon 0.1 mean q -16.6385\n",
      "Episode:  3168 Reward: -200.0 Epsilon 0.1 mean q -16.681675\n",
      "Episode:  3169 Reward: -200.0 Epsilon 0.1 mean q -16.657698\n",
      "Episode:  3170 Reward: -200.0 Epsilon 0.1 mean q -16.630001\n",
      "Episode:  3171 Reward: -200.0 Epsilon 0.1 mean q -16.659737\n",
      "Episode:  3172 Reward: -200.0 Epsilon 0.1 mean q -16.67468\n",
      "Episode:  3173 Reward: -200.0 Epsilon 0.1 mean q -16.650892\n",
      "Episode:  3174 Reward: -200.0 Epsilon 0.1 mean q -16.684147\n",
      "Episode:  3175 Reward: -200.0 Epsilon 0.1 mean q -16.682203\n",
      "Episode:  3176 Reward: -200.0 Epsilon 0.1 mean q -16.668673\n",
      "Episode:  3177 Reward: -200.0 Epsilon 0.1 mean q -16.662912\n",
      "Episode:  3178 Reward: -200.0 Epsilon 0.1 mean q -16.668884\n",
      "Episode:  3179 Reward: -200.0 Epsilon 0.1 mean q -16.67664\n",
      "Episode:  3180 Reward: -200.0 Epsilon 0.1 mean q -16.68481\n",
      "Episode:  3181 Reward: -200.0 Epsilon 0.1 mean q -16.658327\n",
      "Episode:  3182 Reward: -200.0 Epsilon 0.1 mean q -16.665321\n",
      "Episode:  3183 Reward: -200.0 Epsilon 0.1 mean q -16.643774\n",
      "Episode:  3184 Reward: -200.0 Epsilon 0.1 mean q -16.637897\n",
      "Episode:  3185 Reward: -200.0 Epsilon 0.1 mean q -16.662073\n",
      "Episode:  3186 Reward: -200.0 Epsilon 0.1 mean q -16.662975\n",
      "Episode:  3187 Reward: -200.0 Epsilon 0.1 mean q -16.687252\n",
      "Episode:  3188 Reward: -200.0 Epsilon 0.1 mean q -16.651403\n",
      "Episode:  3189 Reward: -200.0 Epsilon 0.1 mean q -16.673323\n",
      "Episode:  3190 Reward: -200.0 Epsilon 0.1 mean q -16.65271\n",
      "Episode:  3191 Reward: -200.0 Epsilon 0.1 mean q -16.672943\n",
      "Episode:  3192 Reward: -200.0 Epsilon 0.1 mean q -16.68088\n",
      "Episode:  3193 Reward: -200.0 Epsilon 0.1 mean q -16.661835\n",
      "Episode:  3194 Reward: -200.0 Epsilon 0.1 mean q -16.710274\n",
      "Episode:  3195 Reward: -200.0 Epsilon 0.1 mean q -16.7135\n",
      "Episode:  3196 Reward: -200.0 Epsilon 0.1 mean q -16.666416\n",
      "Episode:  3197 Reward: -200.0 Epsilon 0.1 mean q -16.673534\n",
      "Episode:  3198 Reward: -200.0 Epsilon 0.1 mean q -16.66964\n",
      "Episode:  3199 Reward: -200.0 Epsilon 0.1 mean q -16.635836\n",
      "Episode:  3200 Reward: -200.0 Epsilon 0.1 mean q -16.667278\n",
      "Episode:  3201 Reward: -200.0 Epsilon 0.1 mean q -16.666288\n",
      "Episode:  3202 Reward: -200.0 Epsilon 0.1 mean q -16.653324\n",
      "Episode:  3203 Reward: -200.0 Epsilon 0.1 mean q -16.653725\n",
      "Episode:  3204 Reward: -200.0 Epsilon 0.1 mean q -16.66878\n",
      "Episode:  3205 Reward: -200.0 Epsilon 0.1 mean q -16.668198\n",
      "Episode:  3206 Reward: -200.0 Epsilon 0.1 mean q -16.698654\n",
      "Episode:  3207 Reward: -200.0 Epsilon 0.1 mean q -16.700043\n",
      "Episode:  3208 Reward: -200.0 Epsilon 0.1 mean q -16.671076\n",
      "Episode:  3209 Reward: -200.0 Epsilon 0.1 mean q -16.68329\n",
      "Episode:  3210 Reward: -200.0 Epsilon 0.1 mean q -16.65489\n",
      "Episode:  3211 Reward: -200.0 Epsilon 0.1 mean q -16.691923\n",
      "Episode:  3212 Reward: -200.0 Epsilon 0.1 mean q -16.666527\n",
      "Episode:  3213 Reward: -200.0 Epsilon 0.1 mean q -16.687328\n",
      "Episode:  3214 Reward: -200.0 Epsilon 0.1 mean q -16.702856\n",
      "Episode:  3215 Reward: -200.0 Epsilon 0.1 mean q -16.671087\n",
      "Episode:  3216 Reward: -200.0 Epsilon 0.1 mean q -16.666641\n",
      "Episode:  3217 Reward: -200.0 Epsilon 0.1 mean q -16.630524\n",
      "Episode:  3218 Reward: -200.0 Epsilon 0.1 mean q -16.668253\n",
      "Episode:  3219 Reward: -200.0 Epsilon 0.1 mean q -16.672726\n",
      "Episode:  3220 Reward: -200.0 Epsilon 0.1 mean q -16.69099\n",
      "Episode:  3221 Reward: -200.0 Epsilon 0.1 mean q -16.684769\n",
      "Episode:  3222 Reward: -200.0 Epsilon 0.1 mean q -16.679996\n",
      "Episode:  3223 Reward: -200.0 Epsilon 0.1 mean q -16.637718\n",
      "Episode:  3224 Reward: -200.0 Epsilon 0.1 mean q -16.667654\n",
      "Episode:  3225 Reward: -200.0 Epsilon 0.1 mean q -16.654034\n",
      "Episode:  3226 Reward: -200.0 Epsilon 0.1 mean q -16.635489\n",
      "Episode:  3227 Reward: -200.0 Epsilon 0.1 mean q -16.618998\n",
      "Episode:  3228 Reward: -200.0 Epsilon 0.1 mean q -16.65298\n",
      "Episode:  3229 Reward: -200.0 Epsilon 0.1 mean q -16.652767\n",
      "Episode:  3230 Reward: -200.0 Epsilon 0.1 mean q -16.683887\n",
      "Episode:  3231 Reward: -200.0 Epsilon 0.1 mean q -16.675379\n",
      "Episode:  3232 Reward: -200.0 Epsilon 0.1 mean q -16.672678\n",
      "Episode:  3233 Reward: -200.0 Epsilon 0.1 mean q -16.669083\n",
      "Episode:  3234 Reward: -200.0 Epsilon 0.1 mean q -16.695963\n",
      "Episode:  3235 Reward: -200.0 Epsilon 0.1 mean q -16.642876\n",
      "Episode:  3236 Reward: -200.0 Epsilon 0.1 mean q -16.66035\n",
      "Episode:  3237 Reward: -200.0 Epsilon 0.1 mean q -16.659704\n",
      "Episode:  3238 Reward: -200.0 Epsilon 0.1 mean q -16.68264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  3239 Reward: -200.0 Epsilon 0.1 mean q -16.6636\n",
      "Episode:  3240 Reward: -200.0 Epsilon 0.1 mean q -16.656038\n",
      "Episode:  3241 Reward: -200.0 Epsilon 0.1 mean q -16.631441\n",
      "Episode:  3242 Reward: -200.0 Epsilon 0.1 mean q -16.67098\n",
      "Episode:  3243 Reward: -200.0 Epsilon 0.1 mean q -16.671852\n",
      "Episode:  3244 Reward: -200.0 Epsilon 0.1 mean q -16.676107\n",
      "Episode:  3245 Reward: -200.0 Epsilon 0.1 mean q -16.641676\n",
      "Episode:  3246 Reward: -200.0 Epsilon 0.1 mean q -16.680841\n",
      "Episode:  3247 Reward: -200.0 Epsilon 0.1 mean q -16.679173\n",
      "Episode:  3248 Reward: -200.0 Epsilon 0.1 mean q -16.678638\n",
      "Episode:  3249 Reward: -200.0 Epsilon 0.1 mean q -16.651802\n",
      "Episode:  3250 Reward: -200.0 Epsilon 0.1 mean q -16.688953\n",
      "Episode:  3251 Reward: -200.0 Epsilon 0.1 mean q -16.651152\n",
      "Episode:  3252 Reward: -200.0 Epsilon 0.1 mean q -16.68509\n",
      "Episode:  3253 Reward: -200.0 Epsilon 0.1 mean q -16.670078\n",
      "Episode:  3254 Reward: -200.0 Epsilon 0.1 mean q -16.724113\n",
      "Episode:  3255 Reward: -200.0 Epsilon 0.1 mean q -16.674242\n",
      "Episode:  3256 Reward: -200.0 Epsilon 0.1 mean q -16.672995\n",
      "Episode:  3257 Reward: -200.0 Epsilon 0.1 mean q -16.6709\n",
      "Episode:  3258 Reward: -200.0 Epsilon 0.1 mean q -16.682253\n",
      "Episode:  3259 Reward: -200.0 Epsilon 0.1 mean q -16.681204\n",
      "Episode:  3260 Reward: -200.0 Epsilon 0.1 mean q -16.68807\n",
      "Episode:  3261 Reward: -200.0 Epsilon 0.1 mean q -16.621298\n",
      "Episode:  3262 Reward: -200.0 Epsilon 0.1 mean q -16.646357\n",
      "Episode:  3263 Reward: -200.0 Epsilon 0.1 mean q -16.672857\n",
      "Episode:  3264 Reward: -200.0 Epsilon 0.1 mean q -16.623457\n",
      "Episode:  3265 Reward: -200.0 Epsilon 0.1 mean q -16.679258\n",
      "Episode:  3266 Reward: -200.0 Epsilon 0.1 mean q -16.700504\n",
      "Episode:  3267 Reward: -200.0 Epsilon 0.1 mean q -16.660553\n",
      "Episode:  3268 Reward: -200.0 Epsilon 0.1 mean q -16.660751\n",
      "Episode:  3269 Reward: -200.0 Epsilon 0.1 mean q -16.687586\n",
      "Episode:  3270 Reward: -200.0 Epsilon 0.1 mean q -16.639013\n",
      "Episode:  3271 Reward: -200.0 Epsilon 0.1 mean q -16.686207\n",
      "Episode:  3272 Reward: -200.0 Epsilon 0.1 mean q -16.64934\n",
      "Episode:  3273 Reward: -200.0 Epsilon 0.1 mean q -16.63581\n",
      "Episode:  3274 Reward: -200.0 Epsilon 0.1 mean q -16.68505\n",
      "Episode:  3275 Reward: -200.0 Epsilon 0.1 mean q -16.669199\n",
      "Episode:  3276 Reward: -200.0 Epsilon 0.1 mean q -16.64904\n",
      "Episode:  3277 Reward: -200.0 Epsilon 0.1 mean q -16.651989\n",
      "Episode:  3278 Reward: -200.0 Epsilon 0.1 mean q -16.668125\n",
      "Episode:  3279 Reward: -200.0 Epsilon 0.1 mean q -16.683184\n",
      "Episode:  3280 Reward: -200.0 Epsilon 0.1 mean q -16.664726\n",
      "Episode:  3281 Reward: -200.0 Epsilon 0.1 mean q -16.685873\n",
      "Episode:  3282 Reward: -200.0 Epsilon 0.1 mean q -16.675095\n",
      "Episode:  3283 Reward: -200.0 Epsilon 0.1 mean q -16.658264\n",
      "Episode:  3284 Reward: -200.0 Epsilon 0.1 mean q -16.664068\n",
      "Episode:  3285 Reward: -200.0 Epsilon 0.1 mean q -16.64538\n",
      "Episode:  3286 Reward: -200.0 Epsilon 0.1 mean q -16.657478\n",
      "Episode:  3287 Reward: -200.0 Epsilon 0.1 mean q -16.689247\n",
      "Episode:  3288 Reward: -200.0 Epsilon 0.1 mean q -16.672758\n",
      "Episode:  3289 Reward: -200.0 Epsilon 0.1 mean q -16.697737\n",
      "Episode:  3290 Reward: -200.0 Epsilon 0.1 mean q -16.688795\n",
      "Episode:  3291 Reward: -200.0 Epsilon 0.1 mean q -16.674536\n",
      "Episode:  3292 Reward: -200.0 Epsilon 0.1 mean q -16.685814\n",
      "Episode:  3293 Reward: -200.0 Epsilon 0.1 mean q -16.640179\n",
      "Episode:  3294 Reward: -200.0 Epsilon 0.1 mean q -16.7085\n",
      "Episode:  3295 Reward: -200.0 Epsilon 0.1 mean q -16.630684\n",
      "Episode:  3296 Reward: -200.0 Epsilon 0.1 mean q -16.673018\n",
      "Episode:  3297 Reward: -200.0 Epsilon 0.1 mean q -16.668262\n",
      "Episode:  3298 Reward: -200.0 Epsilon 0.1 mean q -16.669014\n",
      "Episode:  3299 Reward: -200.0 Epsilon 0.1 mean q -16.642372\n",
      "Episode:  3300 Reward: -200.0 Epsilon 0.1 mean q -16.664436\n",
      "Episode:  3301 Reward: -200.0 Epsilon 0.1 mean q -16.683952\n",
      "Episode:  3302 Reward: -200.0 Epsilon 0.1 mean q -16.663128\n",
      "Episode:  3303 Reward: -200.0 Epsilon 0.1 mean q -16.675758\n",
      "Episode:  3304 Reward: -200.0 Epsilon 0.1 mean q -16.690668\n",
      "Episode:  3305 Reward: -200.0 Epsilon 0.1 mean q -16.685091\n",
      "Episode:  3306 Reward: -200.0 Epsilon 0.1 mean q -16.66967\n",
      "Episode:  3307 Reward: -200.0 Epsilon 0.1 mean q -16.677574\n",
      "Episode:  3308 Reward: -200.0 Epsilon 0.1 mean q -16.675142\n",
      "Episode:  3309 Reward: -200.0 Epsilon 0.1 mean q -16.646566\n",
      "Episode:  3310 Reward: -200.0 Epsilon 0.1 mean q -16.676704\n",
      "Episode:  3311 Reward: -200.0 Epsilon 0.1 mean q -16.679281\n",
      "Episode:  3312 Reward: -200.0 Epsilon 0.1 mean q -16.68062\n",
      "Episode:  3313 Reward: -200.0 Epsilon 0.1 mean q -16.669039\n",
      "Episode:  3314 Reward: -200.0 Epsilon 0.1 mean q -16.680582\n",
      "Episode:  3315 Reward: -200.0 Epsilon 0.1 mean q -16.688543\n",
      "Episode:  3316 Reward: -200.0 Epsilon 0.1 mean q -16.677181\n",
      "Episode:  3317 Reward: -200.0 Epsilon 0.1 mean q -16.66344\n",
      "Episode:  3318 Reward: -200.0 Epsilon 0.1 mean q -16.680843\n",
      "Episode:  3319 Reward: -200.0 Epsilon 0.1 mean q -16.62064\n",
      "Episode:  3320 Reward: -200.0 Epsilon 0.1 mean q -16.653118\n",
      "Episode:  3321 Reward: -200.0 Epsilon 0.1 mean q -16.686152\n",
      "Episode:  3322 Reward: -200.0 Epsilon 0.1 mean q -16.653425\n",
      "Episode:  3323 Reward: -200.0 Epsilon 0.1 mean q -16.66069\n",
      "Episode:  3324 Reward: -200.0 Epsilon 0.1 mean q -16.659119\n",
      "Episode:  3325 Reward: -200.0 Epsilon 0.1 mean q -16.673038\n",
      "Episode:  3326 Reward: -200.0 Epsilon 0.1 mean q -16.666935\n",
      "Episode:  3327 Reward: -200.0 Epsilon 0.1 mean q -16.66603\n",
      "Episode:  3328 Reward: -200.0 Epsilon 0.1 mean q -16.676231\n",
      "Episode:  3329 Reward: -200.0 Epsilon 0.1 mean q -16.659523\n",
      "Episode:  3330 Reward: -200.0 Epsilon 0.1 mean q -16.675274\n",
      "Episode:  3331 Reward: -200.0 Epsilon 0.1 mean q -16.636345\n",
      "Episode:  3332 Reward: -200.0 Epsilon 0.1 mean q -16.699753\n",
      "Episode:  3333 Reward: -200.0 Epsilon 0.1 mean q -16.646877\n",
      "Episode:  3334 Reward: -200.0 Epsilon 0.1 mean q -16.694296\n",
      "Episode:  3335 Reward: -200.0 Epsilon 0.1 mean q -16.682575\n",
      "Episode:  3336 Reward: -200.0 Epsilon 0.1 mean q -16.656878\n",
      "Episode:  3337 Reward: -200.0 Epsilon 0.1 mean q -16.691088\n",
      "Episode:  3338 Reward: -200.0 Epsilon 0.1 mean q -16.68183\n",
      "Episode:  3339 Reward: -200.0 Epsilon 0.1 mean q -16.640287\n",
      "Episode:  3340 Reward: -200.0 Epsilon 0.1 mean q -16.617981\n",
      "Episode:  3341 Reward: -200.0 Epsilon 0.1 mean q -16.639593\n",
      "Episode:  3342 Reward: -200.0 Epsilon 0.1 mean q -16.679707\n",
      "Episode:  3343 Reward: -200.0 Epsilon 0.1 mean q -16.656878\n",
      "Episode:  3344 Reward: -200.0 Epsilon 0.1 mean q -16.664412\n",
      "Episode:  3345 Reward: -200.0 Epsilon 0.1 mean q -16.659184\n",
      "Episode:  3346 Reward: -200.0 Epsilon 0.1 mean q -16.658161\n",
      "Episode:  3347 Reward: -200.0 Epsilon 0.1 mean q -16.635725\n",
      "Episode:  3348 Reward: -200.0 Epsilon 0.1 mean q -16.650099\n",
      "Episode:  3349 Reward: -200.0 Epsilon 0.1 mean q -16.68138\n",
      "Episode:  3350 Reward: -200.0 Epsilon 0.1 mean q -16.649767\n",
      "Episode:  3351 Reward: -200.0 Epsilon 0.1 mean q -16.685804\n",
      "Episode:  3352 Reward: -200.0 Epsilon 0.1 mean q -16.664257\n",
      "Episode:  3353 Reward: -200.0 Epsilon 0.1 mean q -16.679047\n",
      "Episode:  3354 Reward: -200.0 Epsilon 0.1 mean q -16.647175\n",
      "Episode:  3355 Reward: -200.0 Epsilon 0.1 mean q -16.662958\n",
      "Episode:  3356 Reward: -200.0 Epsilon 0.1 mean q -16.68931\n",
      "Episode:  3357 Reward: -200.0 Epsilon 0.1 mean q -16.68616\n",
      "Episode:  3358 Reward: -200.0 Epsilon 0.1 mean q -16.652796\n",
      "Episode:  3359 Reward: -200.0 Epsilon 0.1 mean q -16.648106\n",
      "Episode:  3360 Reward: -200.0 Epsilon 0.1 mean q -16.691498\n",
      "Episode:  3361 Reward: -200.0 Epsilon 0.1 mean q -16.674578\n",
      "Episode:  3362 Reward: -200.0 Epsilon 0.1 mean q -16.673542\n",
      "Episode:  3363 Reward: -200.0 Epsilon 0.1 mean q -16.63749\n",
      "Episode:  3364 Reward: -200.0 Epsilon 0.1 mean q -16.657232\n",
      "Episode:  3365 Reward: -200.0 Epsilon 0.1 mean q -16.674612\n",
      "Episode:  3366 Reward: -200.0 Epsilon 0.1 mean q -16.680025\n",
      "Episode:  3367 Reward: -200.0 Epsilon 0.1 mean q -16.657837\n",
      "Episode:  3368 Reward: -200.0 Epsilon 0.1 mean q -16.657986\n",
      "Episode:  3369 Reward: -200.0 Epsilon 0.1 mean q -16.67765\n",
      "Episode:  3370 Reward: -200.0 Epsilon 0.1 mean q -16.696281\n",
      "Episode:  3371 Reward: -200.0 Epsilon 0.1 mean q -16.663948\n",
      "Episode:  3372 Reward: -200.0 Epsilon 0.1 mean q -16.687029\n",
      "Episode:  3373 Reward: -200.0 Epsilon 0.1 mean q -16.665794\n",
      "Episode:  3374 Reward: -200.0 Epsilon 0.1 mean q -16.651157\n",
      "Episode:  3375 Reward: -200.0 Epsilon 0.1 mean q -16.682997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  3376 Reward: -200.0 Epsilon 0.1 mean q -16.6474\n",
      "Episode:  3377 Reward: -200.0 Epsilon 0.1 mean q -16.67106\n",
      "Episode:  3378 Reward: -200.0 Epsilon 0.1 mean q -16.660234\n",
      "Episode:  3379 Reward: -200.0 Epsilon 0.1 mean q -16.648443\n",
      "Episode:  3380 Reward: -200.0 Epsilon 0.1 mean q -16.679482\n",
      "Episode:  3381 Reward: -200.0 Epsilon 0.1 mean q -16.643732\n",
      "Episode:  3382 Reward: -200.0 Epsilon 0.1 mean q -16.697987\n",
      "Episode:  3383 Reward: -200.0 Epsilon 0.1 mean q -16.681204\n",
      "Episode:  3384 Reward: -200.0 Epsilon 0.1 mean q -16.650614\n",
      "Episode:  3385 Reward: -200.0 Epsilon 0.1 mean q -16.67774\n",
      "Episode:  3386 Reward: -200.0 Epsilon 0.1 mean q -16.668682\n",
      "Episode:  3387 Reward: -200.0 Epsilon 0.1 mean q -16.655449\n",
      "Episode:  3388 Reward: -200.0 Epsilon 0.1 mean q -16.686666\n",
      "Episode:  3389 Reward: -200.0 Epsilon 0.1 mean q -16.651072\n",
      "Episode:  3390 Reward: -200.0 Epsilon 0.1 mean q -16.649944\n",
      "Episode:  3391 Reward: -200.0 Epsilon 0.1 mean q -16.675087\n",
      "Episode:  3392 Reward: -200.0 Epsilon 0.1 mean q -16.66636\n",
      "Episode:  3393 Reward: -200.0 Epsilon 0.1 mean q -16.6398\n",
      "Episode:  3394 Reward: -200.0 Epsilon 0.1 mean q -16.653505\n",
      "Episode:  3395 Reward: -200.0 Epsilon 0.1 mean q -16.648466\n",
      "Episode:  3396 Reward: -200.0 Epsilon 0.1 mean q -16.67678\n",
      "Episode:  3397 Reward: -200.0 Epsilon 0.1 mean q -16.66264\n",
      "Episode:  3398 Reward: -200.0 Epsilon 0.1 mean q -16.640722\n",
      "Episode:  3399 Reward: -200.0 Epsilon 0.1 mean q -16.662434\n",
      "Episode:  3400 Reward: -200.0 Epsilon 0.1 mean q -16.644361\n",
      "Episode:  3401 Reward: -200.0 Epsilon 0.1 mean q -16.623867\n",
      "Episode:  3402 Reward: -200.0 Epsilon 0.1 mean q -16.666643\n",
      "Episode:  3403 Reward: -200.0 Epsilon 0.1 mean q -16.68974\n",
      "Episode:  3404 Reward: -200.0 Epsilon 0.1 mean q -16.690617\n",
      "Episode:  3405 Reward: -200.0 Epsilon 0.1 mean q -16.637445\n",
      "Episode:  3406 Reward: -200.0 Epsilon 0.1 mean q -16.664232\n",
      "Episode:  3407 Reward: -200.0 Epsilon 0.1 mean q -16.701107\n",
      "Episode:  3408 Reward: -200.0 Epsilon 0.1 mean q -16.660526\n",
      "Episode:  3409 Reward: -200.0 Epsilon 0.1 mean q -16.656403\n",
      "Episode:  3410 Reward: -200.0 Epsilon 0.1 mean q -16.647562\n",
      "Episode:  3411 Reward: -200.0 Epsilon 0.1 mean q -16.67161\n",
      "Episode:  3412 Reward: -200.0 Epsilon 0.1 mean q -16.675709\n",
      "Episode:  3413 Reward: -200.0 Epsilon 0.1 mean q -16.656578\n",
      "Episode:  3414 Reward: -200.0 Epsilon 0.1 mean q -16.690948\n",
      "Episode:  3415 Reward: -200.0 Epsilon 0.1 mean q -16.672747\n",
      "Episode:  3416 Reward: -200.0 Epsilon 0.1 mean q -16.657532\n",
      "Episode:  3417 Reward: -200.0 Epsilon 0.1 mean q -16.6755\n",
      "Episode:  3418 Reward: -200.0 Epsilon 0.1 mean q -16.679228\n",
      "Episode:  3419 Reward: -200.0 Epsilon 0.1 mean q -16.674028\n",
      "Episode:  3420 Reward: -200.0 Epsilon 0.1 mean q -16.664522\n",
      "Episode:  3421 Reward: -200.0 Epsilon 0.1 mean q -16.666231\n",
      "Episode:  3422 Reward: -200.0 Epsilon 0.1 mean q -16.667038\n",
      "Episode:  3423 Reward: -200.0 Epsilon 0.1 mean q -16.629522\n",
      "Episode:  3424 Reward: -200.0 Epsilon 0.1 mean q -16.663754\n",
      "Episode:  3425 Reward: -200.0 Epsilon 0.1 mean q -16.629553\n",
      "Episode:  3426 Reward: -200.0 Epsilon 0.1 mean q -16.68673\n",
      "Episode:  3427 Reward: -200.0 Epsilon 0.1 mean q -16.684975\n",
      "Episode:  3428 Reward: -200.0 Epsilon 0.1 mean q -16.643826\n",
      "Episode:  3429 Reward: -200.0 Epsilon 0.1 mean q -16.677351\n",
      "Episode:  3430 Reward: -200.0 Epsilon 0.1 mean q -16.675426\n",
      "Episode:  3431 Reward: -200.0 Epsilon 0.1 mean q -16.674795\n",
      "Episode:  3432 Reward: -200.0 Epsilon 0.1 mean q -16.676983\n",
      "Episode:  3433 Reward: -200.0 Epsilon 0.1 mean q -16.656317\n",
      "Episode:  3434 Reward: -200.0 Epsilon 0.1 mean q -16.66061\n",
      "Episode:  3435 Reward: -200.0 Epsilon 0.1 mean q -16.663645\n",
      "Episode:  3436 Reward: -200.0 Epsilon 0.1 mean q -16.661694\n",
      "Episode:  3437 Reward: -200.0 Epsilon 0.1 mean q -16.642384\n",
      "Episode:  3438 Reward: -200.0 Epsilon 0.1 mean q -16.666187\n",
      "Episode:  3439 Reward: -200.0 Epsilon 0.1 mean q -16.661663\n",
      "Episode:  3440 Reward: -200.0 Epsilon 0.1 mean q -16.668447\n",
      "Episode:  3441 Reward: -200.0 Epsilon 0.1 mean q -16.637245\n",
      "Episode:  3442 Reward: -200.0 Epsilon 0.1 mean q -16.676693\n",
      "Episode:  3443 Reward: -200.0 Epsilon 0.1 mean q -16.659895\n",
      "Episode:  3444 Reward: -200.0 Epsilon 0.1 mean q -16.650032\n",
      "Episode:  3445 Reward: -200.0 Epsilon 0.1 mean q -16.666262\n",
      "Episode:  3446 Reward: -200.0 Epsilon 0.1 mean q -16.648493\n",
      "Episode:  3447 Reward: -200.0 Epsilon 0.1 mean q -16.665787\n",
      "Episode:  3448 Reward: -200.0 Epsilon 0.1 mean q -16.61193\n",
      "Episode:  3449 Reward: -200.0 Epsilon 0.1 mean q -16.659416\n",
      "Episode:  3450 Reward: -200.0 Epsilon 0.1 mean q -16.677296\n",
      "Episode:  3451 Reward: -200.0 Epsilon 0.1 mean q -16.678934\n",
      "Episode:  3452 Reward: -200.0 Epsilon 0.1 mean q -16.664112\n",
      "Episode:  3453 Reward: -200.0 Epsilon 0.1 mean q -16.673658\n",
      "Episode:  3454 Reward: -200.0 Epsilon 0.1 mean q -16.653728\n",
      "Episode:  3455 Reward: -200.0 Epsilon 0.1 mean q -16.650463\n",
      "Episode:  3456 Reward: -200.0 Epsilon 0.1 mean q -16.671383\n",
      "Episode:  3457 Reward: -200.0 Epsilon 0.1 mean q -16.678797\n",
      "Episode:  3458 Reward: -200.0 Epsilon 0.1 mean q -16.665321\n",
      "Episode:  3459 Reward: -200.0 Epsilon 0.1 mean q -16.680164\n",
      "Episode:  3460 Reward: -200.0 Epsilon 0.1 mean q -16.647451\n",
      "Episode:  3461 Reward: -200.0 Epsilon 0.1 mean q -16.671524\n",
      "Episode:  3462 Reward: -200.0 Epsilon 0.1 mean q -16.714466\n",
      "Episode:  3463 Reward: -200.0 Epsilon 0.1 mean q -16.665474\n",
      "Episode:  3464 Reward: -200.0 Epsilon 0.1 mean q -16.694284\n",
      "Episode:  3465 Reward: -200.0 Epsilon 0.1 mean q -16.674423\n",
      "Episode:  3466 Reward: -200.0 Epsilon 0.1 mean q -16.671753\n",
      "Episode:  3467 Reward: -200.0 Epsilon 0.1 mean q -16.653925\n",
      "Episode:  3468 Reward: -200.0 Epsilon 0.1 mean q -16.681778\n",
      "Episode:  3469 Reward: -200.0 Epsilon 0.1 mean q -16.645563\n",
      "Episode:  3470 Reward: -200.0 Epsilon 0.1 mean q -16.631275\n",
      "Episode:  3471 Reward: -200.0 Epsilon 0.1 mean q -16.661713\n",
      "Episode:  3472 Reward: -200.0 Epsilon 0.1 mean q -16.637548\n",
      "Episode:  3473 Reward: -200.0 Epsilon 0.1 mean q -16.678913\n",
      "Episode:  3474 Reward: -200.0 Epsilon 0.1 mean q -16.652729\n",
      "Episode:  3475 Reward: -200.0 Epsilon 0.1 mean q -16.65556\n",
      "Episode:  3476 Reward: -200.0 Epsilon 0.1 mean q -16.655558\n",
      "Episode:  3477 Reward: -200.0 Epsilon 0.1 mean q -16.663317\n",
      "Episode:  3478 Reward: -200.0 Epsilon 0.1 mean q -16.662104\n",
      "Episode:  3479 Reward: -200.0 Epsilon 0.1 mean q -16.685446\n",
      "Episode:  3480 Reward: -200.0 Epsilon 0.1 mean q -16.679338\n",
      "Episode:  3481 Reward: -200.0 Epsilon 0.1 mean q -16.655273\n",
      "Episode:  3482 Reward: -200.0 Epsilon 0.1 mean q -16.635542\n",
      "Episode:  3483 Reward: -200.0 Epsilon 0.1 mean q -16.676407\n",
      "Episode:  3484 Reward: -200.0 Epsilon 0.1 mean q -16.719927\n",
      "Episode:  3485 Reward: -200.0 Epsilon 0.1 mean q -16.677053\n",
      "Episode:  3486 Reward: -200.0 Epsilon 0.1 mean q -16.653906\n",
      "Episode:  3487 Reward: -200.0 Epsilon 0.1 mean q -16.704462\n",
      "Episode:  3488 Reward: -200.0 Epsilon 0.1 mean q -16.643862\n",
      "Episode:  3489 Reward: -200.0 Epsilon 0.1 mean q -16.688915\n",
      "Episode:  3490 Reward: -200.0 Epsilon 0.1 mean q -16.641638\n",
      "Episode:  3491 Reward: -200.0 Epsilon 0.1 mean q -16.640697\n",
      "Episode:  3492 Reward: -200.0 Epsilon 0.1 mean q -16.691187\n",
      "Episode:  3493 Reward: -200.0 Epsilon 0.1 mean q -16.723701\n",
      "Episode:  3494 Reward: -200.0 Epsilon 0.1 mean q -16.664602\n",
      "Episode:  3495 Reward: -200.0 Epsilon 0.1 mean q -16.678768\n",
      "Episode:  3496 Reward: -200.0 Epsilon 0.1 mean q -16.655909\n",
      "Episode:  3497 Reward: -200.0 Epsilon 0.1 mean q -16.6661\n",
      "Episode:  3498 Reward: -200.0 Epsilon 0.1 mean q -16.710655\n",
      "Episode:  3499 Reward: -200.0 Epsilon 0.1 mean q -16.689522\n",
      "Episode:  3500 Reward: -200.0 Epsilon 0.1 mean q -16.660912\n",
      "Episode:  3501 Reward: -200.0 Epsilon 0.1 mean q -16.67999\n",
      "Episode:  3502 Reward: -200.0 Epsilon 0.1 mean q -16.683647\n",
      "Episode:  3503 Reward: -200.0 Epsilon 0.1 mean q -16.665817\n",
      "Episode:  3504 Reward: -200.0 Epsilon 0.1 mean q -16.676353\n",
      "Episode:  3505 Reward: -200.0 Epsilon 0.1 mean q -16.665495\n",
      "Episode:  3506 Reward: -200.0 Epsilon 0.1 mean q -16.650452\n",
      "Episode:  3507 Reward: -200.0 Epsilon 0.1 mean q -16.704775\n",
      "Episode:  3508 Reward: -200.0 Epsilon 0.1 mean q -16.666899\n",
      "Episode:  3509 Reward: -200.0 Epsilon 0.1 mean q -16.65325\n",
      "Episode:  3510 Reward: -200.0 Epsilon 0.1 mean q -16.66217\n",
      "Episode:  3511 Reward: -200.0 Epsilon 0.1 mean q -16.696224\n",
      "Episode:  3512 Reward: -200.0 Epsilon 0.1 mean q -16.654016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  3513 Reward: -200.0 Epsilon 0.1 mean q -16.654514\n",
      "Episode:  3514 Reward: -200.0 Epsilon 0.1 mean q -16.63766\n",
      "Episode:  3515 Reward: -200.0 Epsilon 0.1 mean q -16.671257\n",
      "Episode:  3516 Reward: -200.0 Epsilon 0.1 mean q -16.66612\n",
      "Episode:  3517 Reward: -200.0 Epsilon 0.1 mean q -16.664457\n",
      "Episode:  3518 Reward: -200.0 Epsilon 0.1 mean q -16.635674\n",
      "Episode:  3519 Reward: -200.0 Epsilon 0.1 mean q -16.658737\n",
      "Episode:  3520 Reward: -200.0 Epsilon 0.1 mean q -16.678804\n",
      "Episode:  3521 Reward: -200.0 Epsilon 0.1 mean q -16.644464\n",
      "Episode:  3522 Reward: -200.0 Epsilon 0.1 mean q -16.689983\n",
      "Episode:  3523 Reward: -200.0 Epsilon 0.1 mean q -16.665333\n",
      "Episode:  3524 Reward: -200.0 Epsilon 0.1 mean q -16.635313\n",
      "Episode:  3525 Reward: -200.0 Epsilon 0.1 mean q -16.662725\n",
      "Episode:  3526 Reward: -200.0 Epsilon 0.1 mean q -16.675419\n",
      "Episode:  3527 Reward: -200.0 Epsilon 0.1 mean q -16.68291\n",
      "Episode:  3528 Reward: -200.0 Epsilon 0.1 mean q -16.681597\n",
      "Episode:  3529 Reward: -200.0 Epsilon 0.1 mean q -16.665356\n",
      "Episode:  3530 Reward: -200.0 Epsilon 0.1 mean q -16.65694\n",
      "Episode:  3531 Reward: -200.0 Epsilon 0.1 mean q -16.615473\n",
      "Episode:  3532 Reward: -200.0 Epsilon 0.1 mean q -16.640131\n",
      "Episode:  3533 Reward: -200.0 Epsilon 0.1 mean q -16.654236\n",
      "Episode:  3534 Reward: -200.0 Epsilon 0.1 mean q -16.649319\n",
      "Episode:  3535 Reward: -200.0 Epsilon 0.1 mean q -16.680977\n",
      "Episode:  3536 Reward: -200.0 Epsilon 0.1 mean q -16.645565\n",
      "Episode:  3537 Reward: -200.0 Epsilon 0.1 mean q -16.659716\n",
      "Episode:  3538 Reward: -200.0 Epsilon 0.1 mean q -16.64621\n",
      "Episode:  3539 Reward: -200.0 Epsilon 0.1 mean q -16.682968\n",
      "Episode:  3540 Reward: -200.0 Epsilon 0.1 mean q -16.675156\n",
      "Episode:  3541 Reward: -200.0 Epsilon 0.1 mean q -16.63535\n",
      "Episode:  3542 Reward: -200.0 Epsilon 0.1 mean q -16.636986\n",
      "Episode:  3543 Reward: -200.0 Epsilon 0.1 mean q -16.662987\n",
      "Episode:  3544 Reward: -200.0 Epsilon 0.1 mean q -16.68488\n",
      "Episode:  3545 Reward: -200.0 Epsilon 0.1 mean q -16.645723\n",
      "Episode:  3546 Reward: -200.0 Epsilon 0.1 mean q -16.664675\n",
      "Episode:  3547 Reward: -200.0 Epsilon 0.1 mean q -16.697113\n",
      "Episode:  3548 Reward: -200.0 Epsilon 0.1 mean q -16.657763\n",
      "Episode:  3549 Reward: -200.0 Epsilon 0.1 mean q -16.676996\n",
      "Episode:  3550 Reward: -200.0 Epsilon 0.1 mean q -16.68914\n",
      "Episode:  3551 Reward: -200.0 Epsilon 0.1 mean q -16.678785\n",
      "Episode:  3552 Reward: -200.0 Epsilon 0.1 mean q -16.622969\n",
      "Episode:  3553 Reward: -200.0 Epsilon 0.1 mean q -16.650488\n",
      "Episode:  3554 Reward: -200.0 Epsilon 0.1 mean q -16.698603\n",
      "Episode:  3555 Reward: -200.0 Epsilon 0.1 mean q -16.699287\n",
      "Episode:  3556 Reward: -200.0 Epsilon 0.1 mean q -16.695124\n",
      "Episode:  3557 Reward: -200.0 Epsilon 0.1 mean q -16.67048\n",
      "Episode:  3558 Reward: -200.0 Epsilon 0.1 mean q -16.654102\n",
      "Episode:  3559 Reward: -200.0 Epsilon 0.1 mean q -16.669384\n",
      "Episode:  3560 Reward: -200.0 Epsilon 0.1 mean q -16.646582\n",
      "Episode:  3561 Reward: -200.0 Epsilon 0.1 mean q -16.641481\n",
      "Episode:  3562 Reward: -200.0 Epsilon 0.1 mean q -16.6858\n",
      "Episode:  3563 Reward: -200.0 Epsilon 0.1 mean q -16.684034\n",
      "Episode:  3564 Reward: -200.0 Epsilon 0.1 mean q -16.669765\n",
      "Episode:  3565 Reward: -200.0 Epsilon 0.1 mean q -16.65228\n",
      "Episode:  3566 Reward: -200.0 Epsilon 0.1 mean q -16.701365\n",
      "Episode:  3567 Reward: -200.0 Epsilon 0.1 mean q -16.62801\n",
      "Episode:  3568 Reward: -200.0 Epsilon 0.1 mean q -16.633425\n",
      "Episode:  3569 Reward: -200.0 Epsilon 0.1 mean q -16.678072\n",
      "Episode:  3570 Reward: -200.0 Epsilon 0.1 mean q -16.673395\n",
      "Episode:  3571 Reward: -200.0 Epsilon 0.1 mean q -16.666374\n",
      "Episode:  3572 Reward: -200.0 Epsilon 0.1 mean q -16.668507\n",
      "Episode:  3573 Reward: -200.0 Epsilon 0.1 mean q -16.645222\n",
      "Episode:  3574 Reward: -200.0 Epsilon 0.1 mean q -16.697638\n",
      "Episode:  3575 Reward: -200.0 Epsilon 0.1 mean q -16.669706\n",
      "Episode:  3576 Reward: -200.0 Epsilon 0.1 mean q -16.622871\n",
      "Episode:  3577 Reward: -200.0 Epsilon 0.1 mean q -16.685816\n",
      "Episode:  3578 Reward: -200.0 Epsilon 0.1 mean q -16.684776\n",
      "Episode:  3579 Reward: -200.0 Epsilon 0.1 mean q -16.665869\n",
      "Episode:  3580 Reward: -200.0 Epsilon 0.1 mean q -16.640741\n",
      "Episode:  3581 Reward: -200.0 Epsilon 0.1 mean q -16.681688\n",
      "Episode:  3582 Reward: -200.0 Epsilon 0.1 mean q -16.681347\n",
      "Episode:  3583 Reward: -200.0 Epsilon 0.1 mean q -16.635954\n",
      "Episode:  3584 Reward: -200.0 Epsilon 0.1 mean q -16.693949\n",
      "Episode:  3585 Reward: -200.0 Epsilon 0.1 mean q -16.653131\n",
      "Episode:  3586 Reward: -200.0 Epsilon 0.1 mean q -16.658417\n",
      "Episode:  3587 Reward: -200.0 Epsilon 0.1 mean q -16.654987\n",
      "Episode:  3588 Reward: -200.0 Epsilon 0.1 mean q -16.66481\n",
      "Episode:  3589 Reward: -200.0 Epsilon 0.1 mean q -16.652697\n",
      "Episode:  3590 Reward: -200.0 Epsilon 0.1 mean q -16.659052\n",
      "Episode:  3591 Reward: -200.0 Epsilon 0.1 mean q -16.662722\n",
      "Episode:  3592 Reward: -200.0 Epsilon 0.1 mean q -16.685654\n",
      "Episode:  3593 Reward: -200.0 Epsilon 0.1 mean q -16.694487\n",
      "Episode:  3594 Reward: -200.0 Epsilon 0.1 mean q -16.666681\n",
      "Episode:  3595 Reward: -200.0 Epsilon 0.1 mean q -16.658226\n",
      "Episode:  3596 Reward: -200.0 Epsilon 0.1 mean q -16.680342\n",
      "Episode:  3597 Reward: -200.0 Epsilon 0.1 mean q -16.675531\n",
      "Episode:  3598 Reward: -200.0 Epsilon 0.1 mean q -16.687786\n",
      "Episode:  3599 Reward: -200.0 Epsilon 0.1 mean q -16.686588\n",
      "Episode:  3600 Reward: -200.0 Epsilon 0.1 mean q -16.674088\n",
      "Episode:  3601 Reward: -200.0 Epsilon 0.1 mean q -16.696222\n",
      "Episode:  3602 Reward: -200.0 Epsilon 0.1 mean q -16.701225\n",
      "Episode:  3603 Reward: -200.0 Epsilon 0.1 mean q -16.652298\n",
      "Episode:  3604 Reward: -200.0 Epsilon 0.1 mean q -16.706293\n",
      "Episode:  3605 Reward: -200.0 Epsilon 0.1 mean q -16.632715\n",
      "Episode:  3606 Reward: -200.0 Epsilon 0.1 mean q -16.663073\n",
      "Episode:  3607 Reward: -200.0 Epsilon 0.1 mean q -16.672848\n",
      "Episode:  3608 Reward: -200.0 Epsilon 0.1 mean q -16.647175\n",
      "Episode:  3609 Reward: -200.0 Epsilon 0.1 mean q -16.693718\n",
      "Episode:  3610 Reward: -200.0 Epsilon 0.1 mean q -16.684298\n",
      "Episode:  3611 Reward: -200.0 Epsilon 0.1 mean q -16.65697\n",
      "Episode:  3612 Reward: -200.0 Epsilon 0.1 mean q -16.669687\n",
      "Episode:  3613 Reward: -200.0 Epsilon 0.1 mean q -16.647942\n",
      "Episode:  3614 Reward: -200.0 Epsilon 0.1 mean q -16.661243\n",
      "Episode:  3615 Reward: -200.0 Epsilon 0.1 mean q -16.683523\n",
      "Episode:  3616 Reward: -200.0 Epsilon 0.1 mean q -16.686602\n",
      "Episode:  3617 Reward: -200.0 Epsilon 0.1 mean q -16.69208\n",
      "Episode:  3618 Reward: -200.0 Epsilon 0.1 mean q -16.669525\n",
      "Episode:  3619 Reward: -200.0 Epsilon 0.1 mean q -16.644844\n",
      "Episode:  3620 Reward: -200.0 Epsilon 0.1 mean q -16.645185\n",
      "Episode:  3621 Reward: -200.0 Epsilon 0.1 mean q -16.682468\n",
      "Episode:  3622 Reward: -200.0 Epsilon 0.1 mean q -16.647223\n",
      "Episode:  3623 Reward: -200.0 Epsilon 0.1 mean q -16.666054\n",
      "Episode:  3624 Reward: -200.0 Epsilon 0.1 mean q -16.685236\n",
      "Episode:  3625 Reward: -200.0 Epsilon 0.1 mean q -16.692516\n",
      "Episode:  3626 Reward: -200.0 Epsilon 0.1 mean q -16.66217\n",
      "Episode:  3627 Reward: -200.0 Epsilon 0.1 mean q -16.691109\n",
      "Episode:  3628 Reward: -200.0 Epsilon 0.1 mean q -16.639774\n",
      "Episode:  3629 Reward: -200.0 Epsilon 0.1 mean q -16.6564\n",
      "Episode:  3630 Reward: -200.0 Epsilon 0.1 mean q -16.64983\n",
      "Episode:  3631 Reward: -200.0 Epsilon 0.1 mean q -16.689991\n",
      "Episode:  3632 Reward: -200.0 Epsilon 0.1 mean q -16.687065\n",
      "Episode:  3633 Reward: -200.0 Epsilon 0.1 mean q -16.64475\n",
      "Episode:  3634 Reward: -200.0 Epsilon 0.1 mean q -16.634472\n",
      "Episode:  3635 Reward: -200.0 Epsilon 0.1 mean q -16.649088\n",
      "Episode:  3636 Reward: -200.0 Epsilon 0.1 mean q -16.66612\n",
      "Episode:  3637 Reward: -200.0 Epsilon 0.1 mean q -16.63028\n",
      "Episode:  3638 Reward: -200.0 Epsilon 0.1 mean q -16.649546\n",
      "Episode:  3639 Reward: -200.0 Epsilon 0.1 mean q -16.664413\n",
      "Episode:  3640 Reward: -200.0 Epsilon 0.1 mean q -16.615736\n",
      "Episode:  3641 Reward: -200.0 Epsilon 0.1 mean q -16.676996\n",
      "Episode:  3642 Reward: -200.0 Epsilon 0.1 mean q -16.692972\n",
      "Episode:  3643 Reward: -200.0 Epsilon 0.1 mean q -16.680399\n",
      "Episode:  3644 Reward: -200.0 Epsilon 0.1 mean q -16.685808\n",
      "Episode:  3645 Reward: -200.0 Epsilon 0.1 mean q -16.654032\n",
      "Episode:  3646 Reward: -200.0 Epsilon 0.1 mean q -16.686764\n",
      "Episode:  3647 Reward: -200.0 Epsilon 0.1 mean q -16.65489\n",
      "Episode:  3648 Reward: -200.0 Epsilon 0.1 mean q -16.650772\n",
      "Episode:  3649 Reward: -200.0 Epsilon 0.1 mean q -16.696152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  3650 Reward: -200.0 Epsilon 0.1 mean q -16.661995\n",
      "Episode:  3651 Reward: -200.0 Epsilon 0.1 mean q -16.65986\n",
      "Episode:  3652 Reward: -200.0 Epsilon 0.1 mean q -16.673885\n",
      "Episode:  3653 Reward: -200.0 Epsilon 0.1 mean q -16.672342\n",
      "Episode:  3654 Reward: -200.0 Epsilon 0.1 mean q -16.710186\n",
      "Episode:  3655 Reward: -200.0 Epsilon 0.1 mean q -16.691597\n",
      "Episode:  3656 Reward: -200.0 Epsilon 0.1 mean q -16.663527\n",
      "Episode:  3657 Reward: -200.0 Epsilon 0.1 mean q -16.644648\n",
      "Episode:  3658 Reward: -200.0 Epsilon 0.1 mean q -16.67053\n",
      "Episode:  3659 Reward: -200.0 Epsilon 0.1 mean q -16.655403\n",
      "Episode:  3660 Reward: -200.0 Epsilon 0.1 mean q -16.643038\n",
      "Episode:  3661 Reward: -200.0 Epsilon 0.1 mean q -16.70589\n",
      "Episode:  3662 Reward: -200.0 Epsilon 0.1 mean q -16.65702\n",
      "Episode:  3663 Reward: -200.0 Epsilon 0.1 mean q -16.644022\n",
      "Episode:  3664 Reward: -200.0 Epsilon 0.1 mean q -16.652313\n",
      "Episode:  3665 Reward: -200.0 Epsilon 0.1 mean q -16.693693\n",
      "Episode:  3666 Reward: -200.0 Epsilon 0.1 mean q -16.645147\n",
      "Episode:  3667 Reward: -200.0 Epsilon 0.1 mean q -16.65028\n",
      "Episode:  3668 Reward: -200.0 Epsilon 0.1 mean q -16.637451\n",
      "Episode:  3669 Reward: -200.0 Epsilon 0.1 mean q -16.656149\n",
      "Episode:  3670 Reward: -200.0 Epsilon 0.1 mean q -16.642706\n",
      "Episode:  3671 Reward: -200.0 Epsilon 0.1 mean q -16.68382\n",
      "Episode:  3672 Reward: -200.0 Epsilon 0.1 mean q -16.662365\n",
      "Episode:  3673 Reward: -200.0 Epsilon 0.1 mean q -16.684418\n",
      "Episode:  3674 Reward: -200.0 Epsilon 0.1 mean q -16.672722\n",
      "Episode:  3675 Reward: -200.0 Epsilon 0.1 mean q -16.654049\n",
      "Episode:  3676 Reward: -200.0 Epsilon 0.1 mean q -16.649813\n",
      "Episode:  3677 Reward: -200.0 Epsilon 0.1 mean q -16.657402\n",
      "Episode:  3678 Reward: -200.0 Epsilon 0.1 mean q -16.668295\n",
      "Episode:  3679 Reward: -200.0 Epsilon 0.1 mean q -16.648005\n",
      "Episode:  3680 Reward: -200.0 Epsilon 0.1 mean q -16.665098\n",
      "Episode:  3681 Reward: -200.0 Epsilon 0.1 mean q -16.669733\n",
      "Episode:  3682 Reward: -200.0 Epsilon 0.1 mean q -16.66952\n",
      "Episode:  3683 Reward: -200.0 Epsilon 0.1 mean q -16.686357\n",
      "Episode:  3684 Reward: -200.0 Epsilon 0.1 mean q -16.703627\n",
      "Episode:  3685 Reward: -200.0 Epsilon 0.1 mean q -16.644037\n",
      "Episode:  3686 Reward: -200.0 Epsilon 0.1 mean q -16.671831\n",
      "Episode:  3687 Reward: -200.0 Epsilon 0.1 mean q -16.637802\n",
      "Episode:  3688 Reward: -200.0 Epsilon 0.1 mean q -16.681637\n",
      "Episode:  3689 Reward: -200.0 Epsilon 0.1 mean q -16.665161\n",
      "Episode:  3690 Reward: -200.0 Epsilon 0.1 mean q -16.671013\n",
      "Episode:  3691 Reward: -200.0 Epsilon 0.1 mean q -16.64015\n",
      "Episode:  3692 Reward: -200.0 Epsilon 0.1 mean q -16.654118\n",
      "Episode:  3693 Reward: -200.0 Epsilon 0.1 mean q -16.661856\n",
      "Episode:  3694 Reward: -200.0 Epsilon 0.1 mean q -16.656677\n",
      "Episode:  3695 Reward: -200.0 Epsilon 0.1 mean q -16.675758\n",
      "Episode:  3696 Reward: -200.0 Epsilon 0.1 mean q -16.629362\n",
      "Episode:  3697 Reward: -200.0 Epsilon 0.1 mean q -16.6992\n",
      "Episode:  3698 Reward: -200.0 Epsilon 0.1 mean q -16.639326\n",
      "Episode:  3699 Reward: -200.0 Epsilon 0.1 mean q -16.655691\n",
      "Episode:  3700 Reward: -200.0 Epsilon 0.1 mean q -16.634407\n",
      "Episode:  3701 Reward: -200.0 Epsilon 0.1 mean q -16.646988\n",
      "Episode:  3702 Reward: -200.0 Epsilon 0.1 mean q -16.641851\n",
      "Episode:  3703 Reward: -200.0 Epsilon 0.1 mean q -16.66933\n",
      "Episode:  3704 Reward: -200.0 Epsilon 0.1 mean q -16.704876\n",
      "Episode:  3705 Reward: -200.0 Epsilon 0.1 mean q -16.681602\n",
      "Episode:  3706 Reward: -200.0 Epsilon 0.1 mean q -16.660097\n",
      "Episode:  3707 Reward: -200.0 Epsilon 0.1 mean q -16.676754\n",
      "Episode:  3708 Reward: -200.0 Epsilon 0.1 mean q -16.666964\n",
      "Episode:  3709 Reward: -200.0 Epsilon 0.1 mean q -16.660885\n",
      "Episode:  3710 Reward: -200.0 Epsilon 0.1 mean q -16.660717\n",
      "Episode:  3711 Reward: -200.0 Epsilon 0.1 mean q -16.683859\n",
      "Episode:  3712 Reward: -200.0 Epsilon 0.1 mean q -16.665405\n",
      "Episode:  3713 Reward: -200.0 Epsilon 0.1 mean q -16.655468\n",
      "Episode:  3714 Reward: -200.0 Epsilon 0.1 mean q -16.633652\n",
      "Episode:  3715 Reward: -200.0 Epsilon 0.1 mean q -16.689596\n",
      "Episode:  3716 Reward: -200.0 Epsilon 0.1 mean q -16.702682\n",
      "Episode:  3717 Reward: -200.0 Epsilon 0.1 mean q -16.67656\n",
      "Episode:  3718 Reward: -200.0 Epsilon 0.1 mean q -16.659372\n",
      "Episode:  3719 Reward: -200.0 Epsilon 0.1 mean q -16.649185\n",
      "Episode:  3720 Reward: -200.0 Epsilon 0.1 mean q -16.695763\n",
      "Episode:  3721 Reward: -200.0 Epsilon 0.1 mean q -16.694277\n",
      "Episode:  3722 Reward: -200.0 Epsilon 0.1 mean q -16.669283\n",
      "Episode:  3723 Reward: -200.0 Epsilon 0.1 mean q -16.684708\n",
      "Episode:  3724 Reward: -200.0 Epsilon 0.1 mean q -16.659908\n",
      "Episode:  3725 Reward: -200.0 Epsilon 0.1 mean q -16.68211\n",
      "Episode:  3726 Reward: -200.0 Epsilon 0.1 mean q -16.655457\n",
      "Episode:  3727 Reward: -200.0 Epsilon 0.1 mean q -16.672194\n",
      "Episode:  3728 Reward: -200.0 Epsilon 0.1 mean q -16.65024\n",
      "Episode:  3729 Reward: -200.0 Epsilon 0.1 mean q -16.66598\n",
      "Episode:  3730 Reward: -200.0 Epsilon 0.1 mean q -16.675837\n",
      "Episode:  3731 Reward: -200.0 Epsilon 0.1 mean q -16.67477\n",
      "Episode:  3732 Reward: -200.0 Epsilon 0.1 mean q -16.642126\n",
      "Episode:  3733 Reward: -200.0 Epsilon 0.1 mean q -16.621588\n",
      "Episode:  3734 Reward: -200.0 Epsilon 0.1 mean q -16.652445\n",
      "Episode:  3735 Reward: -200.0 Epsilon 0.1 mean q -16.651838\n",
      "Episode:  3736 Reward: -200.0 Epsilon 0.1 mean q -16.68656\n",
      "Episode:  3737 Reward: -200.0 Epsilon 0.1 mean q -16.666317\n",
      "Episode:  3738 Reward: -200.0 Epsilon 0.1 mean q -16.699205\n",
      "Episode:  3739 Reward: -200.0 Epsilon 0.1 mean q -16.675459\n",
      "Episode:  3740 Reward: -200.0 Epsilon 0.1 mean q -16.668015\n",
      "Episode:  3741 Reward: -200.0 Epsilon 0.1 mean q -16.66557\n",
      "Episode:  3742 Reward: -200.0 Epsilon 0.1 mean q -16.667852\n",
      "Episode:  3743 Reward: -200.0 Epsilon 0.1 mean q -16.660341\n",
      "Episode:  3744 Reward: -200.0 Epsilon 0.1 mean q -16.68098\n",
      "Episode:  3745 Reward: -200.0 Epsilon 0.1 mean q -16.6526\n",
      "Episode:  3746 Reward: -200.0 Epsilon 0.1 mean q -16.66168\n",
      "Episode:  3747 Reward: -200.0 Epsilon 0.1 mean q -16.688574\n",
      "Episode:  3748 Reward: -200.0 Epsilon 0.1 mean q -16.653206\n",
      "Episode:  3749 Reward: -200.0 Epsilon 0.1 mean q -16.66842\n",
      "Episode:  3750 Reward: -200.0 Epsilon 0.1 mean q -16.65907\n",
      "Episode:  3751 Reward: -200.0 Epsilon 0.1 mean q -16.683847\n",
      "Episode:  3752 Reward: -200.0 Epsilon 0.1 mean q -16.673376\n",
      "Episode:  3753 Reward: -200.0 Epsilon 0.1 mean q -16.661316\n",
      "Episode:  3754 Reward: -200.0 Epsilon 0.1 mean q -16.65837\n",
      "Episode:  3755 Reward: -200.0 Epsilon 0.1 mean q -16.665178\n",
      "Episode:  3756 Reward: -200.0 Epsilon 0.1 mean q -16.652184\n",
      "Episode:  3757 Reward: -200.0 Epsilon 0.1 mean q -16.666485\n",
      "Episode:  3758 Reward: -200.0 Epsilon 0.1 mean q -16.651138\n",
      "Episode:  3759 Reward: -200.0 Epsilon 0.1 mean q -16.649513\n",
      "Episode:  3760 Reward: -200.0 Epsilon 0.1 mean q -16.622145\n",
      "Episode:  3761 Reward: -200.0 Epsilon 0.1 mean q -16.679157\n",
      "Episode:  3762 Reward: -200.0 Epsilon 0.1 mean q -16.634401\n",
      "Episode:  3763 Reward: -200.0 Epsilon 0.1 mean q -16.6622\n",
      "Episode:  3764 Reward: -200.0 Epsilon 0.1 mean q -16.68839\n",
      "Episode:  3765 Reward: -200.0 Epsilon 0.1 mean q -16.661434\n",
      "Episode:  3766 Reward: -200.0 Epsilon 0.1 mean q -16.689285\n",
      "Episode:  3767 Reward: -200.0 Epsilon 0.1 mean q -16.652575\n",
      "Episode:  3768 Reward: -200.0 Epsilon 0.1 mean q -16.698048\n",
      "Episode:  3769 Reward: -200.0 Epsilon 0.1 mean q -16.662695\n",
      "Episode:  3770 Reward: -200.0 Epsilon 0.1 mean q -16.664557\n",
      "Episode:  3771 Reward: -200.0 Epsilon 0.1 mean q -16.637379\n",
      "Episode:  3772 Reward: -200.0 Epsilon 0.1 mean q -16.658964\n",
      "Episode:  3773 Reward: -200.0 Epsilon 0.1 mean q -16.658094\n",
      "Episode:  3774 Reward: -200.0 Epsilon 0.1 mean q -16.648369\n",
      "Episode:  3775 Reward: -200.0 Epsilon 0.1 mean q -16.63342\n",
      "Episode:  3776 Reward: -200.0 Epsilon 0.1 mean q -16.643314\n",
      "Episode:  3777 Reward: -200.0 Epsilon 0.1 mean q -16.692915\n",
      "Episode:  3778 Reward: -200.0 Epsilon 0.1 mean q -16.664717\n",
      "Episode:  3779 Reward: -200.0 Epsilon 0.1 mean q -16.66065\n",
      "Episode:  3780 Reward: -200.0 Epsilon 0.1 mean q -16.638271\n",
      "Episode:  3781 Reward: -200.0 Epsilon 0.1 mean q -16.686283\n",
      "Episode:  3782 Reward: -200.0 Epsilon 0.1 mean q -16.682632\n",
      "Episode:  3783 Reward: -200.0 Epsilon 0.1 mean q -16.651571\n",
      "Episode:  3784 Reward: -200.0 Epsilon 0.1 mean q -16.658453\n",
      "Episode:  3785 Reward: -200.0 Epsilon 0.1 mean q -16.64994\n",
      "Episode:  3786 Reward: -200.0 Epsilon 0.1 mean q -16.694641\n",
      "Episode:  3787 Reward: -200.0 Epsilon 0.1 mean q -16.643421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  3788 Reward: -200.0 Epsilon 0.1 mean q -16.673496\n",
      "Episode:  3789 Reward: -200.0 Epsilon 0.1 mean q -16.66151\n",
      "Episode:  3790 Reward: -200.0 Epsilon 0.1 mean q -16.66056\n",
      "Episode:  3791 Reward: -200.0 Epsilon 0.1 mean q -16.654928\n",
      "Episode:  3792 Reward: -200.0 Epsilon 0.1 mean q -16.656157\n",
      "Episode:  3793 Reward: -200.0 Epsilon 0.1 mean q -16.65295\n",
      "Episode:  3794 Reward: -200.0 Epsilon 0.1 mean q -16.687256\n",
      "Episode:  3795 Reward: -200.0 Epsilon 0.1 mean q -16.643282\n",
      "Episode:  3796 Reward: -200.0 Epsilon 0.1 mean q -16.654993\n",
      "Episode:  3797 Reward: -200.0 Epsilon 0.1 mean q -16.65385\n",
      "Episode:  3798 Reward: -200.0 Epsilon 0.1 mean q -16.664003\n",
      "Episode:  3799 Reward: -200.0 Epsilon 0.1 mean q -16.664555\n",
      "Episode:  3800 Reward: -200.0 Epsilon 0.1 mean q -16.653805\n",
      "Episode:  3801 Reward: -200.0 Epsilon 0.1 mean q -16.690046\n",
      "Episode:  3802 Reward: -200.0 Epsilon 0.1 mean q -16.648853\n",
      "Episode:  3803 Reward: -200.0 Epsilon 0.1 mean q -16.660494\n",
      "Episode:  3804 Reward: -200.0 Epsilon 0.1 mean q -16.688177\n",
      "Episode:  3805 Reward: -200.0 Epsilon 0.1 mean q -16.656372\n",
      "Episode:  3806 Reward: -200.0 Epsilon 0.1 mean q -16.645868\n",
      "Episode:  3807 Reward: -200.0 Epsilon 0.1 mean q -16.687082\n",
      "Episode:  3808 Reward: -200.0 Epsilon 0.1 mean q -16.653463\n",
      "Episode:  3809 Reward: -200.0 Epsilon 0.1 mean q -16.67565\n",
      "Episode:  3810 Reward: -200.0 Epsilon 0.1 mean q -16.687809\n",
      "Episode:  3811 Reward: -200.0 Epsilon 0.1 mean q -16.675318\n",
      "Episode:  3812 Reward: -200.0 Epsilon 0.1 mean q -16.68622\n",
      "Episode:  3813 Reward: -200.0 Epsilon 0.1 mean q -16.672844\n",
      "Episode:  3814 Reward: -200.0 Epsilon 0.1 mean q -16.661146\n",
      "Episode:  3815 Reward: -200.0 Epsilon 0.1 mean q -16.676153\n",
      "Episode:  3816 Reward: -200.0 Epsilon 0.1 mean q -16.69098\n",
      "Episode:  3817 Reward: -200.0 Epsilon 0.1 mean q -16.697283\n",
      "Episode:  3818 Reward: -200.0 Epsilon 0.1 mean q -16.658083\n",
      "Episode:  3819 Reward: -200.0 Epsilon 0.1 mean q -16.65859\n",
      "Episode:  3820 Reward: -200.0 Epsilon 0.1 mean q -16.656235\n",
      "Episode:  3821 Reward: -200.0 Epsilon 0.1 mean q -16.700615\n",
      "Episode:  3822 Reward: -200.0 Epsilon 0.1 mean q -16.650112\n",
      "Episode:  3823 Reward: -200.0 Epsilon 0.1 mean q -16.65836\n",
      "Episode:  3824 Reward: -200.0 Epsilon 0.1 mean q -16.67971\n",
      "Episode:  3825 Reward: -200.0 Epsilon 0.1 mean q -16.685846\n",
      "Episode:  3826 Reward: -200.0 Epsilon 0.1 mean q -16.691547\n",
      "Episode:  3827 Reward: -200.0 Epsilon 0.1 mean q -16.679764\n",
      "Episode:  3828 Reward: -200.0 Epsilon 0.1 mean q -16.658495\n",
      "Episode:  3829 Reward: -200.0 Epsilon 0.1 mean q -16.667545\n",
      "Episode:  3830 Reward: -200.0 Epsilon 0.1 mean q -16.654278\n",
      "Episode:  3831 Reward: -200.0 Epsilon 0.1 mean q -16.648977\n",
      "Episode:  3832 Reward: -200.0 Epsilon 0.1 mean q -16.66964\n",
      "Episode:  3833 Reward: -200.0 Epsilon 0.1 mean q -16.642996\n",
      "Episode:  3834 Reward: -200.0 Epsilon 0.1 mean q -16.685219\n",
      "Episode:  3835 Reward: -200.0 Epsilon 0.1 mean q -16.685596\n",
      "Episode:  3836 Reward: -200.0 Epsilon 0.1 mean q -16.627466\n",
      "Episode:  3837 Reward: -200.0 Epsilon 0.1 mean q -16.632605\n",
      "Episode:  3838 Reward: -200.0 Epsilon 0.1 mean q -16.655224\n",
      "Episode:  3839 Reward: -200.0 Epsilon 0.1 mean q -16.682966\n",
      "Episode:  3840 Reward: -200.0 Epsilon 0.1 mean q -16.643103\n",
      "Episode:  3841 Reward: -200.0 Epsilon 0.1 mean q -16.697792\n",
      "Episode:  3842 Reward: -200.0 Epsilon 0.1 mean q -16.665998\n",
      "Episode:  3843 Reward: -200.0 Epsilon 0.1 mean q -16.643951\n",
      "Episode:  3844 Reward: -200.0 Epsilon 0.1 mean q -16.621927\n",
      "Episode:  3845 Reward: -200.0 Epsilon 0.1 mean q -16.656443\n",
      "Episode:  3846 Reward: -200.0 Epsilon 0.1 mean q -16.6754\n",
      "Episode:  3847 Reward: -200.0 Epsilon 0.1 mean q -16.669056\n",
      "Episode:  3848 Reward: -200.0 Epsilon 0.1 mean q -16.701515\n",
      "Episode:  3849 Reward: -200.0 Epsilon 0.1 mean q -16.661882\n",
      "Episode:  3850 Reward: -200.0 Epsilon 0.1 mean q -16.681622\n",
      "Episode:  3851 Reward: -200.0 Epsilon 0.1 mean q -16.652405\n",
      "Episode:  3852 Reward: -200.0 Epsilon 0.1 mean q -16.673735\n",
      "Episode:  3853 Reward: -200.0 Epsilon 0.1 mean q -16.68245\n",
      "Episode:  3854 Reward: -200.0 Epsilon 0.1 mean q -16.700432\n",
      "Episode:  3855 Reward: -200.0 Epsilon 0.1 mean q -16.646523\n",
      "Episode:  3856 Reward: -200.0 Epsilon 0.1 mean q -16.692204\n",
      "Episode:  3857 Reward: -200.0 Epsilon 0.1 mean q -16.672367\n",
      "Episode:  3858 Reward: -200.0 Epsilon 0.1 mean q -16.688692\n",
      "Episode:  3859 Reward: -200.0 Epsilon 0.1 mean q -16.649008\n",
      "Episode:  3860 Reward: -200.0 Epsilon 0.1 mean q -16.652054\n",
      "Episode:  3861 Reward: -200.0 Epsilon 0.1 mean q -16.660465\n",
      "Episode:  3862 Reward: -200.0 Epsilon 0.1 mean q -16.643984\n",
      "Episode:  3863 Reward: -200.0 Epsilon 0.1 mean q -16.643126\n",
      "Episode:  3864 Reward: -200.0 Epsilon 0.1 mean q -16.681574\n",
      "Episode:  3865 Reward: -200.0 Epsilon 0.1 mean q -16.683533\n",
      "Episode:  3866 Reward: -200.0 Epsilon 0.1 mean q -16.681469\n",
      "Episode:  3867 Reward: -200.0 Epsilon 0.1 mean q -16.634733\n",
      "Episode:  3868 Reward: -200.0 Epsilon 0.1 mean q -16.624907\n",
      "Episode:  3869 Reward: -200.0 Epsilon 0.1 mean q -16.67276\n",
      "Episode:  3870 Reward: -200.0 Epsilon 0.1 mean q -16.661173\n",
      "Episode:  3871 Reward: -200.0 Epsilon 0.1 mean q -16.667553\n",
      "Episode:  3872 Reward: -200.0 Epsilon 0.1 mean q -16.676142\n",
      "Episode:  3873 Reward: -200.0 Epsilon 0.1 mean q -16.657032\n",
      "Episode:  3874 Reward: -200.0 Epsilon 0.1 mean q -16.672136\n",
      "Episode:  3875 Reward: -200.0 Epsilon 0.1 mean q -16.687565\n",
      "Episode:  3876 Reward: -200.0 Epsilon 0.1 mean q -16.644598\n",
      "Episode:  3877 Reward: -200.0 Epsilon 0.1 mean q -16.678959\n",
      "Episode:  3878 Reward: -200.0 Epsilon 0.1 mean q -16.683977\n",
      "Episode:  3879 Reward: -200.0 Epsilon 0.1 mean q -16.682245\n",
      "Episode:  3880 Reward: -200.0 Epsilon 0.1 mean q -16.653805\n",
      "Episode:  3881 Reward: -200.0 Epsilon 0.1 mean q -16.69967\n",
      "Episode:  3882 Reward: -200.0 Epsilon 0.1 mean q -16.680202\n",
      "Episode:  3883 Reward: -200.0 Epsilon 0.1 mean q -16.710047\n",
      "Episode:  3884 Reward: -200.0 Epsilon 0.1 mean q -16.665426\n",
      "Episode:  3885 Reward: -200.0 Epsilon 0.1 mean q -16.66163\n",
      "Episode:  3886 Reward: -200.0 Epsilon 0.1 mean q -16.642237\n",
      "Episode:  3887 Reward: -200.0 Epsilon 0.1 mean q -16.67335\n",
      "Episode:  3888 Reward: -200.0 Epsilon 0.1 mean q -16.688833\n",
      "Episode:  3889 Reward: -200.0 Epsilon 0.1 mean q -16.722729\n",
      "Episode:  3890 Reward: -200.0 Epsilon 0.1 mean q -16.674828\n",
      "Episode:  3891 Reward: -200.0 Epsilon 0.1 mean q -16.671589\n",
      "Episode:  3892 Reward: -200.0 Epsilon 0.1 mean q -16.70384\n",
      "Episode:  3893 Reward: -200.0 Epsilon 0.1 mean q -16.629353\n",
      "Episode:  3894 Reward: -200.0 Epsilon 0.1 mean q -16.673336\n",
      "Episode:  3895 Reward: -200.0 Epsilon 0.1 mean q -16.66272\n",
      "Episode:  3896 Reward: -200.0 Epsilon 0.1 mean q -16.678972\n",
      "Episode:  3897 Reward: -200.0 Epsilon 0.1 mean q -16.636858\n",
      "Episode:  3898 Reward: -200.0 Epsilon 0.1 mean q -16.661419\n",
      "Episode:  3899 Reward: -200.0 Epsilon 0.1 mean q -16.67958\n",
      "Episode:  3900 Reward: -200.0 Epsilon 0.1 mean q -16.664509\n",
      "Episode:  3901 Reward: -200.0 Epsilon 0.1 mean q -16.662575\n",
      "Episode:  3902 Reward: -200.0 Epsilon 0.1 mean q -16.667385\n",
      "Episode:  3903 Reward: -200.0 Epsilon 0.1 mean q -16.671926\n",
      "Episode:  3904 Reward: -200.0 Epsilon 0.1 mean q -16.685408\n",
      "Episode:  3905 Reward: -200.0 Epsilon 0.1 mean q -16.678955\n",
      "Episode:  3906 Reward: -200.0 Epsilon 0.1 mean q -16.656322\n",
      "Episode:  3907 Reward: -200.0 Epsilon 0.1 mean q -16.648174\n",
      "Episode:  3908 Reward: -200.0 Epsilon 0.1 mean q -16.636536\n",
      "Episode:  3909 Reward: -200.0 Epsilon 0.1 mean q -16.689573\n",
      "Episode:  3910 Reward: -200.0 Epsilon 0.1 mean q -16.658571\n",
      "Episode:  3911 Reward: -200.0 Epsilon 0.1 mean q -16.702358\n",
      "Episode:  3912 Reward: -200.0 Epsilon 0.1 mean q -16.641201\n",
      "Episode:  3913 Reward: -200.0 Epsilon 0.1 mean q -16.636768\n",
      "Episode:  3914 Reward: -200.0 Epsilon 0.1 mean q -16.689655\n",
      "Episode:  3915 Reward: -200.0 Epsilon 0.1 mean q -16.67405\n",
      "Episode:  3916 Reward: -200.0 Epsilon 0.1 mean q -16.689648\n",
      "Episode:  3917 Reward: -200.0 Epsilon 0.1 mean q -16.6815\n",
      "Episode:  3918 Reward: -200.0 Epsilon 0.1 mean q -16.669203\n",
      "Episode:  3919 Reward: -200.0 Epsilon 0.1 mean q -16.663649\n",
      "Episode:  3920 Reward: -200.0 Epsilon 0.1 mean q -16.692442\n",
      "Episode:  3921 Reward: -200.0 Epsilon 0.1 mean q -16.657022\n",
      "Episode:  3922 Reward: -200.0 Epsilon 0.1 mean q -16.660551\n",
      "Episode:  3923 Reward: -200.0 Epsilon 0.1 mean q -16.624987\n",
      "Episode:  3924 Reward: -200.0 Epsilon 0.1 mean q -16.658651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  3925 Reward: -200.0 Epsilon 0.1 mean q -16.656858\n",
      "Episode:  3926 Reward: -200.0 Epsilon 0.1 mean q -16.689817\n",
      "Episode:  3927 Reward: -200.0 Epsilon 0.1 mean q -16.660566\n",
      "Episode:  3928 Reward: -200.0 Epsilon 0.1 mean q -16.690748\n",
      "Episode:  3929 Reward: -200.0 Epsilon 0.1 mean q -16.636545\n",
      "Episode:  3930 Reward: -200.0 Epsilon 0.1 mean q -16.670748\n",
      "Episode:  3931 Reward: -200.0 Epsilon 0.1 mean q -16.658264\n",
      "Episode:  3932 Reward: -200.0 Epsilon 0.1 mean q -16.66023\n",
      "Episode:  3933 Reward: -200.0 Epsilon 0.1 mean q -16.652046\n",
      "Episode:  3934 Reward: -200.0 Epsilon 0.1 mean q -16.655931\n",
      "Episode:  3935 Reward: -200.0 Epsilon 0.1 mean q -16.670757\n",
      "Episode:  3936 Reward: -200.0 Epsilon 0.1 mean q -16.633669\n",
      "Episode:  3937 Reward: -200.0 Epsilon 0.1 mean q -16.67516\n",
      "Episode:  3938 Reward: -200.0 Epsilon 0.1 mean q -16.632187\n",
      "Episode:  3939 Reward: -200.0 Epsilon 0.1 mean q -16.659395\n",
      "Episode:  3940 Reward: -200.0 Epsilon 0.1 mean q -16.674633\n",
      "Episode:  3941 Reward: -200.0 Epsilon 0.1 mean q -16.641289\n",
      "Episode:  3942 Reward: -200.0 Epsilon 0.1 mean q -16.672998\n",
      "Episode:  3943 Reward: -200.0 Epsilon 0.1 mean q -16.713213\n",
      "Episode:  3944 Reward: -200.0 Epsilon 0.1 mean q -16.680666\n",
      "Episode:  3945 Reward: -200.0 Epsilon 0.1 mean q -16.665915\n",
      "Episode:  3946 Reward: -200.0 Epsilon 0.1 mean q -16.652704\n",
      "Episode:  3947 Reward: -200.0 Epsilon 0.1 mean q -16.68773\n",
      "Episode:  3948 Reward: -200.0 Epsilon 0.1 mean q -16.669855\n",
      "Episode:  3949 Reward: -200.0 Epsilon 0.1 mean q -16.661634\n",
      "Episode:  3950 Reward: -200.0 Epsilon 0.1 mean q -16.70124\n",
      "Episode:  3951 Reward: -200.0 Epsilon 0.1 mean q -16.64236\n",
      "Episode:  3952 Reward: -200.0 Epsilon 0.1 mean q -16.664225\n",
      "Episode:  3953 Reward: -200.0 Epsilon 0.1 mean q -16.698082\n",
      "Episode:  3954 Reward: -200.0 Epsilon 0.1 mean q -16.690601\n",
      "Episode:  3955 Reward: -200.0 Epsilon 0.1 mean q -16.66701\n",
      "Episode:  3956 Reward: -200.0 Epsilon 0.1 mean q -16.650824\n",
      "Episode:  3957 Reward: -200.0 Epsilon 0.1 mean q -16.674555\n",
      "Episode:  3958 Reward: -200.0 Epsilon 0.1 mean q -16.66055\n",
      "Episode:  3959 Reward: -200.0 Epsilon 0.1 mean q -16.661842\n",
      "Episode:  3960 Reward: -200.0 Epsilon 0.1 mean q -16.641325\n",
      "Episode:  3961 Reward: -200.0 Epsilon 0.1 mean q -16.652395\n",
      "Episode:  3962 Reward: -200.0 Epsilon 0.1 mean q -16.63415\n",
      "Episode:  3963 Reward: -200.0 Epsilon 0.1 mean q -16.624588\n",
      "Episode:  3964 Reward: -200.0 Epsilon 0.1 mean q -16.684883\n",
      "Episode:  3965 Reward: -200.0 Epsilon 0.1 mean q -16.65762\n",
      "Episode:  3966 Reward: -200.0 Epsilon 0.1 mean q -16.674023\n",
      "Episode:  3967 Reward: -200.0 Epsilon 0.1 mean q -16.677359\n",
      "Episode:  3968 Reward: -200.0 Epsilon 0.1 mean q -16.66413\n",
      "Episode:  3969 Reward: -200.0 Epsilon 0.1 mean q -16.668468\n",
      "Episode:  3970 Reward: -200.0 Epsilon 0.1 mean q -16.639578\n",
      "Episode:  3971 Reward: -200.0 Epsilon 0.1 mean q -16.684855\n",
      "Episode:  3972 Reward: -200.0 Epsilon 0.1 mean q -16.681515\n",
      "Episode:  3973 Reward: -200.0 Epsilon 0.1 mean q -16.658867\n",
      "Episode:  3974 Reward: -200.0 Epsilon 0.1 mean q -16.6824\n",
      "Episode:  3975 Reward: -200.0 Epsilon 0.1 mean q -16.658823\n",
      "Episode:  3976 Reward: -200.0 Epsilon 0.1 mean q -16.669876\n",
      "Episode:  3977 Reward: -200.0 Epsilon 0.1 mean q -16.65251\n",
      "Episode:  3978 Reward: -200.0 Epsilon 0.1 mean q -16.634993\n",
      "Episode:  3979 Reward: -200.0 Epsilon 0.1 mean q -16.666176\n",
      "Episode:  3980 Reward: -200.0 Epsilon 0.1 mean q -16.679379\n",
      "Episode:  3981 Reward: -200.0 Epsilon 0.1 mean q -16.674625\n",
      "Episode:  3982 Reward: -200.0 Epsilon 0.1 mean q -16.69058\n",
      "Episode:  3983 Reward: -200.0 Epsilon 0.1 mean q -16.661552\n",
      "Episode:  3984 Reward: -200.0 Epsilon 0.1 mean q -16.637949\n",
      "Episode:  3985 Reward: -200.0 Epsilon 0.1 mean q -16.651081\n",
      "Episode:  3986 Reward: -200.0 Epsilon 0.1 mean q -16.65572\n",
      "Episode:  3987 Reward: -200.0 Epsilon 0.1 mean q -16.66681\n",
      "Episode:  3988 Reward: -200.0 Epsilon 0.1 mean q -16.65124\n",
      "Episode:  3989 Reward: -200.0 Epsilon 0.1 mean q -16.696133\n",
      "Episode:  3990 Reward: -200.0 Epsilon 0.1 mean q -16.718388\n",
      "Episode:  3991 Reward: -200.0 Epsilon 0.1 mean q -16.654158\n",
      "Episode:  3992 Reward: -200.0 Epsilon 0.1 mean q -16.68776\n",
      "Episode:  3993 Reward: -200.0 Epsilon 0.1 mean q -16.648811\n",
      "Episode:  3994 Reward: -200.0 Epsilon 0.1 mean q -16.65337\n",
      "Episode:  3995 Reward: -200.0 Epsilon 0.1 mean q -16.67451\n",
      "Episode:  3996 Reward: -200.0 Epsilon 0.1 mean q -16.683617\n",
      "Episode:  3997 Reward: -200.0 Epsilon 0.1 mean q -16.673847\n",
      "Episode:  3998 Reward: -200.0 Epsilon 0.1 mean q -16.656513\n",
      "Episode:  3999 Reward: -200.0 Epsilon 0.1 mean q -16.674898\n",
      "Episode:  4000 Reward: -200.0 Epsilon 0.1 mean q -16.68016\n",
      "Episode:  4001 Reward: -200.0 Epsilon 0.1 mean q -16.673368\n",
      "Episode:  4002 Reward: -200.0 Epsilon 0.1 mean q -16.675177\n",
      "Episode:  4003 Reward: -200.0 Epsilon 0.1 mean q -16.687887\n",
      "Episode:  4004 Reward: -200.0 Epsilon 0.1 mean q -16.675667\n",
      "Episode:  4005 Reward: -200.0 Epsilon 0.1 mean q -16.651442\n",
      "Episode:  4006 Reward: -200.0 Epsilon 0.1 mean q -16.682878\n",
      "Episode:  4007 Reward: -200.0 Epsilon 0.1 mean q -16.673395\n",
      "Episode:  4008 Reward: -200.0 Epsilon 0.1 mean q -16.642023\n",
      "Episode:  4009 Reward: -200.0 Epsilon 0.1 mean q -16.687628\n",
      "Episode:  4010 Reward: -200.0 Epsilon 0.1 mean q -16.70469\n",
      "Episode:  4011 Reward: -200.0 Epsilon 0.1 mean q -16.669548\n",
      "Episode:  4012 Reward: -200.0 Epsilon 0.1 mean q -16.664373\n",
      "Episode:  4013 Reward: -200.0 Epsilon 0.1 mean q -16.654716\n",
      "Episode:  4014 Reward: -200.0 Epsilon 0.1 mean q -16.661377\n",
      "Episode:  4015 Reward: -200.0 Epsilon 0.1 mean q -16.610401\n",
      "Episode:  4016 Reward: -200.0 Epsilon 0.1 mean q -16.671099\n",
      "Episode:  4017 Reward: -200.0 Epsilon 0.1 mean q -16.666742\n",
      "Episode:  4018 Reward: -200.0 Epsilon 0.1 mean q -16.661583\n",
      "Episode:  4019 Reward: -200.0 Epsilon 0.1 mean q -16.63927\n",
      "Episode:  4020 Reward: -200.0 Epsilon 0.1 mean q -16.67005\n",
      "Episode:  4021 Reward: -200.0 Epsilon 0.1 mean q -16.659609\n",
      "Episode:  4022 Reward: -200.0 Epsilon 0.1 mean q -16.6884\n",
      "Episode:  4023 Reward: -200.0 Epsilon 0.1 mean q -16.659155\n",
      "Episode:  4024 Reward: -200.0 Epsilon 0.1 mean q -16.655869\n",
      "Episode:  4025 Reward: -200.0 Epsilon 0.1 mean q -16.670582\n",
      "Episode:  4026 Reward: -200.0 Epsilon 0.1 mean q -16.700975\n",
      "Episode:  4027 Reward: -200.0 Epsilon 0.1 mean q -16.655165\n",
      "Episode:  4028 Reward: -200.0 Epsilon 0.1 mean q -16.697186\n",
      "Episode:  4029 Reward: -200.0 Epsilon 0.1 mean q -16.651615\n",
      "Episode:  4030 Reward: -200.0 Epsilon 0.1 mean q -16.678417\n",
      "Episode:  4031 Reward: -200.0 Epsilon 0.1 mean q -16.665897\n",
      "Episode:  4032 Reward: -200.0 Epsilon 0.1 mean q -16.674261\n",
      "Episode:  4033 Reward: -200.0 Epsilon 0.1 mean q -16.69492\n",
      "Episode:  4034 Reward: -200.0 Epsilon 0.1 mean q -16.679821\n",
      "Episode:  4035 Reward: -200.0 Epsilon 0.1 mean q -16.663485\n",
      "Episode:  4036 Reward: -200.0 Epsilon 0.1 mean q -16.684326\n",
      "Episode:  4037 Reward: -200.0 Epsilon 0.1 mean q -16.669903\n",
      "Episode:  4038 Reward: -200.0 Epsilon 0.1 mean q -16.713207\n",
      "Episode:  4039 Reward: -200.0 Epsilon 0.1 mean q -16.701002\n",
      "Episode:  4040 Reward: -200.0 Epsilon 0.1 mean q -16.68108\n",
      "Episode:  4041 Reward: -200.0 Epsilon 0.1 mean q -16.63814\n",
      "Episode:  4042 Reward: -200.0 Epsilon 0.1 mean q -16.681864\n",
      "Episode:  4043 Reward: -200.0 Epsilon 0.1 mean q -16.675169\n",
      "Episode:  4044 Reward: -200.0 Epsilon 0.1 mean q -16.695694\n",
      "Episode:  4045 Reward: -200.0 Epsilon 0.1 mean q -16.672672\n",
      "Episode:  4046 Reward: -200.0 Epsilon 0.1 mean q -16.689941\n",
      "Episode:  4047 Reward: -200.0 Epsilon 0.1 mean q -16.656511\n",
      "Episode:  4048 Reward: -200.0 Epsilon 0.1 mean q -16.674255\n",
      "Episode:  4049 Reward: -200.0 Epsilon 0.1 mean q -16.635576\n",
      "Episode:  4050 Reward: -200.0 Epsilon 0.1 mean q -16.648964\n",
      "Episode:  4051 Reward: -200.0 Epsilon 0.1 mean q -16.649765\n",
      "Episode:  4052 Reward: -200.0 Epsilon 0.1 mean q -16.642685\n",
      "Episode:  4053 Reward: -200.0 Epsilon 0.1 mean q -16.672503\n",
      "Episode:  4054 Reward: -200.0 Epsilon 0.1 mean q -16.688112\n",
      "Episode:  4055 Reward: -200.0 Epsilon 0.1 mean q -16.654188\n",
      "Episode:  4056 Reward: -200.0 Epsilon 0.1 mean q -16.62718\n",
      "Episode:  4057 Reward: -200.0 Epsilon 0.1 mean q -16.631943\n",
      "Episode:  4058 Reward: -200.0 Epsilon 0.1 mean q -16.664436\n",
      "Episode:  4059 Reward: -200.0 Epsilon 0.1 mean q -16.674736\n",
      "Episode:  4060 Reward: -200.0 Epsilon 0.1 mean q -16.68242\n",
      "Episode:  4061 Reward: -200.0 Epsilon 0.1 mean q -16.669434\n",
      "Episode:  4062 Reward: -200.0 Epsilon 0.1 mean q -16.65387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  4063 Reward: -200.0 Epsilon 0.1 mean q -16.680693\n",
      "Episode:  4064 Reward: -200.0 Epsilon 0.1 mean q -16.654512\n",
      "Episode:  4065 Reward: -200.0 Epsilon 0.1 mean q -16.681715\n",
      "Episode:  4066 Reward: -200.0 Epsilon 0.1 mean q -16.690693\n",
      "Episode:  4067 Reward: -200.0 Epsilon 0.1 mean q -16.652317\n",
      "Episode:  4068 Reward: -200.0 Epsilon 0.1 mean q -16.67851\n",
      "Episode:  4069 Reward: -200.0 Epsilon 0.1 mean q -16.65462\n",
      "Episode:  4070 Reward: -200.0 Epsilon 0.1 mean q -16.696331\n",
      "Episode:  4071 Reward: -200.0 Epsilon 0.1 mean q -16.670315\n",
      "Episode:  4072 Reward: -200.0 Epsilon 0.1 mean q -16.63721\n",
      "Episode:  4073 Reward: -200.0 Epsilon 0.1 mean q -16.655083\n",
      "Episode:  4074 Reward: -200.0 Epsilon 0.1 mean q -16.671839\n",
      "Episode:  4075 Reward: -200.0 Epsilon 0.1 mean q -16.639784\n",
      "Episode:  4076 Reward: -200.0 Epsilon 0.1 mean q -16.637667\n",
      "Episode:  4077 Reward: -200.0 Epsilon 0.1 mean q -16.638662\n",
      "Episode:  4078 Reward: -200.0 Epsilon 0.1 mean q -16.641577\n",
      "Episode:  4079 Reward: -200.0 Epsilon 0.1 mean q -16.67821\n",
      "Episode:  4080 Reward: -200.0 Epsilon 0.1 mean q -16.669617\n",
      "Episode:  4081 Reward: -200.0 Epsilon 0.1 mean q -16.672705\n",
      "Episode:  4082 Reward: -200.0 Epsilon 0.1 mean q -16.679169\n",
      "Episode:  4083 Reward: -200.0 Epsilon 0.1 mean q -16.630936\n",
      "Episode:  4084 Reward: -200.0 Epsilon 0.1 mean q -16.672468\n",
      "Episode:  4085 Reward: -200.0 Epsilon 0.1 mean q -16.659641\n",
      "Episode:  4086 Reward: -200.0 Epsilon 0.1 mean q -16.661037\n",
      "Episode:  4087 Reward: -200.0 Epsilon 0.1 mean q -16.629333\n",
      "Episode:  4088 Reward: -200.0 Epsilon 0.1 mean q -16.652847\n",
      "Episode:  4089 Reward: -200.0 Epsilon 0.1 mean q -16.683474\n",
      "Episode:  4090 Reward: -200.0 Epsilon 0.1 mean q -16.668072\n",
      "Episode:  4091 Reward: -200.0 Epsilon 0.1 mean q -16.655977\n",
      "Episode:  4092 Reward: -200.0 Epsilon 0.1 mean q -16.689436\n",
      "Episode:  4093 Reward: -200.0 Epsilon 0.1 mean q -16.668364\n",
      "Episode:  4094 Reward: -200.0 Epsilon 0.1 mean q -16.665178\n",
      "Episode:  4095 Reward: -200.0 Epsilon 0.1 mean q -16.665838\n",
      "Episode:  4096 Reward: -200.0 Epsilon 0.1 mean q -16.689226\n",
      "Episode:  4097 Reward: -200.0 Epsilon 0.1 mean q -16.673288\n",
      "Episode:  4098 Reward: -200.0 Epsilon 0.1 mean q -16.674107\n",
      "Episode:  4099 Reward: -200.0 Epsilon 0.1 mean q -16.644796\n",
      "Episode:  4100 Reward: -200.0 Epsilon 0.1 mean q -16.677044\n",
      "Episode:  4101 Reward: -200.0 Epsilon 0.1 mean q -16.67962\n",
      "Episode:  4102 Reward: -200.0 Epsilon 0.1 mean q -16.677841\n",
      "Episode:  4103 Reward: -200.0 Epsilon 0.1 mean q -16.63953\n",
      "Episode:  4104 Reward: -200.0 Epsilon 0.1 mean q -16.681978\n",
      "Episode:  4105 Reward: -200.0 Epsilon 0.1 mean q -16.656628\n",
      "Episode:  4106 Reward: -200.0 Epsilon 0.1 mean q -16.620476\n",
      "Episode:  4107 Reward: -200.0 Epsilon 0.1 mean q -16.689592\n",
      "Episode:  4108 Reward: -200.0 Epsilon 0.1 mean q -16.660795\n",
      "Episode:  4109 Reward: -200.0 Epsilon 0.1 mean q -16.67316\n",
      "Episode:  4110 Reward: -200.0 Epsilon 0.1 mean q -16.657465\n",
      "Episode:  4111 Reward: -200.0 Epsilon 0.1 mean q -16.64679\n",
      "Episode:  4112 Reward: -200.0 Epsilon 0.1 mean q -16.659447\n",
      "Episode:  4113 Reward: -200.0 Epsilon 0.1 mean q -16.665113\n",
      "Episode:  4114 Reward: -200.0 Epsilon 0.1 mean q -16.677109\n",
      "Episode:  4115 Reward: -200.0 Epsilon 0.1 mean q -16.68273\n",
      "Episode:  4116 Reward: -200.0 Epsilon 0.1 mean q -16.66979\n",
      "Episode:  4117 Reward: -200.0 Epsilon 0.1 mean q -16.632275\n",
      "Episode:  4118 Reward: -200.0 Epsilon 0.1 mean q -16.669464\n",
      "Episode:  4119 Reward: -200.0 Epsilon 0.1 mean q -16.671019\n",
      "Episode:  4120 Reward: -200.0 Epsilon 0.1 mean q -16.701149\n",
      "Episode:  4121 Reward: -200.0 Epsilon 0.1 mean q -16.669037\n",
      "Episode:  4122 Reward: -200.0 Epsilon 0.1 mean q -16.676657\n",
      "Episode:  4123 Reward: -200.0 Epsilon 0.1 mean q -16.674322\n",
      "Episode:  4124 Reward: -200.0 Epsilon 0.1 mean q -16.659313\n",
      "Episode:  4125 Reward: -200.0 Epsilon 0.1 mean q -16.684473\n",
      "Episode:  4126 Reward: -200.0 Epsilon 0.1 mean q -16.673334\n",
      "Episode:  4127 Reward: -200.0 Epsilon 0.1 mean q -16.674864\n",
      "Episode:  4128 Reward: -200.0 Epsilon 0.1 mean q -16.684668\n",
      "Episode:  4129 Reward: -200.0 Epsilon 0.1 mean q -16.690422\n",
      "Episode:  4130 Reward: -200.0 Epsilon 0.1 mean q -16.621513\n",
      "Episode:  4131 Reward: -200.0 Epsilon 0.1 mean q -16.639206\n",
      "Episode:  4132 Reward: -200.0 Epsilon 0.1 mean q -16.667768\n",
      "Episode:  4133 Reward: -200.0 Epsilon 0.1 mean q -16.679476\n",
      "Episode:  4134 Reward: -200.0 Epsilon 0.1 mean q -16.686205\n",
      "Episode:  4135 Reward: -200.0 Epsilon 0.1 mean q -16.674335\n",
      "Episode:  4136 Reward: -200.0 Epsilon 0.1 mean q -16.660004\n",
      "Episode:  4137 Reward: -200.0 Epsilon 0.1 mean q -16.670328\n",
      "Episode:  4138 Reward: -200.0 Epsilon 0.1 mean q -16.671743\n",
      "Episode:  4139 Reward: -200.0 Epsilon 0.1 mean q -16.671284\n",
      "Episode:  4140 Reward: -200.0 Epsilon 0.1 mean q -16.64438\n",
      "Episode:  4141 Reward: -200.0 Epsilon 0.1 mean q -16.686611\n",
      "Episode:  4142 Reward: -200.0 Epsilon 0.1 mean q -16.685722\n",
      "Episode:  4143 Reward: -200.0 Epsilon 0.1 mean q -16.684345\n",
      "Episode:  4144 Reward: -200.0 Epsilon 0.1 mean q -16.668762\n",
      "Episode:  4145 Reward: -200.0 Epsilon 0.1 mean q -16.653349\n",
      "Episode:  4146 Reward: -200.0 Epsilon 0.1 mean q -16.67262\n",
      "Episode:  4147 Reward: -200.0 Epsilon 0.1 mean q -16.700182\n",
      "Episode:  4148 Reward: -200.0 Epsilon 0.1 mean q -16.659197\n",
      "Episode:  4149 Reward: -200.0 Epsilon 0.1 mean q -16.677385\n",
      "Episode:  4150 Reward: -200.0 Epsilon 0.1 mean q -16.693125\n",
      "Episode:  4151 Reward: -200.0 Epsilon 0.1 mean q -16.657808\n",
      "Episode:  4152 Reward: -200.0 Epsilon 0.1 mean q -16.66631\n",
      "Episode:  4153 Reward: -200.0 Epsilon 0.1 mean q -16.676458\n",
      "Episode:  4154 Reward: -200.0 Epsilon 0.1 mean q -16.660639\n",
      "Episode:  4155 Reward: -200.0 Epsilon 0.1 mean q -16.70146\n",
      "Episode:  4156 Reward: -200.0 Epsilon 0.1 mean q -16.67007\n",
      "Episode:  4157 Reward: -200.0 Epsilon 0.1 mean q -16.637354\n",
      "Episode:  4158 Reward: -200.0 Epsilon 0.1 mean q -16.668877\n",
      "Episode:  4159 Reward: -200.0 Epsilon 0.1 mean q -16.645208\n",
      "Episode:  4160 Reward: -200.0 Epsilon 0.1 mean q -16.6347\n",
      "Episode:  4161 Reward: -200.0 Epsilon 0.1 mean q -16.694912\n",
      "Episode:  4162 Reward: -200.0 Epsilon 0.1 mean q -16.664284\n",
      "Episode:  4163 Reward: -200.0 Epsilon 0.1 mean q -16.65428\n",
      "Episode:  4164 Reward: -200.0 Epsilon 0.1 mean q -16.650692\n",
      "Episode:  4165 Reward: -200.0 Epsilon 0.1 mean q -16.65515\n",
      "Episode:  4166 Reward: -200.0 Epsilon 0.1 mean q -16.664785\n",
      "Episode:  4167 Reward: -200.0 Epsilon 0.1 mean q -16.664606\n",
      "Episode:  4168 Reward: -200.0 Epsilon 0.1 mean q -16.652803\n",
      "Episode:  4169 Reward: -200.0 Epsilon 0.1 mean q -16.670134\n",
      "Episode:  4170 Reward: -200.0 Epsilon 0.1 mean q -16.647305\n",
      "Episode:  4171 Reward: -200.0 Epsilon 0.1 mean q -16.687162\n",
      "Episode:  4172 Reward: -200.0 Epsilon 0.1 mean q -16.655098\n",
      "Episode:  4173 Reward: -200.0 Epsilon 0.1 mean q -16.688711\n",
      "Episode:  4174 Reward: -200.0 Epsilon 0.1 mean q -16.659977\n",
      "Episode:  4175 Reward: -200.0 Epsilon 0.1 mean q -16.694206\n",
      "Episode:  4176 Reward: -200.0 Epsilon 0.1 mean q -16.676664\n",
      "Episode:  4177 Reward: -200.0 Epsilon 0.1 mean q -16.663483\n",
      "Episode:  4178 Reward: -200.0 Epsilon 0.1 mean q -16.664091\n",
      "Episode:  4179 Reward: -200.0 Epsilon 0.1 mean q -16.642088\n",
      "Episode:  4180 Reward: -200.0 Epsilon 0.1 mean q -16.694632\n",
      "Episode:  4181 Reward: -200.0 Epsilon 0.1 mean q -16.654722\n",
      "Episode:  4182 Reward: -200.0 Epsilon 0.1 mean q -16.65401\n",
      "Episode:  4183 Reward: -200.0 Epsilon 0.1 mean q -16.689707\n",
      "Episode:  4184 Reward: -200.0 Epsilon 0.1 mean q -16.687885\n",
      "Episode:  4185 Reward: -200.0 Epsilon 0.1 mean q -16.679209\n",
      "Episode:  4186 Reward: -200.0 Epsilon 0.1 mean q -16.639\n",
      "Episode:  4187 Reward: -200.0 Epsilon 0.1 mean q -16.67348\n",
      "Episode:  4188 Reward: -200.0 Epsilon 0.1 mean q -16.64701\n",
      "Episode:  4189 Reward: -200.0 Epsilon 0.1 mean q -16.645515\n",
      "Episode:  4190 Reward: -200.0 Epsilon 0.1 mean q -16.659367\n",
      "Episode:  4191 Reward: -200.0 Epsilon 0.1 mean q -16.699678\n",
      "Episode:  4192 Reward: -200.0 Epsilon 0.1 mean q -16.648743\n",
      "Episode:  4193 Reward: -200.0 Epsilon 0.1 mean q -16.659418\n",
      "Episode:  4194 Reward: -200.0 Epsilon 0.1 mean q -16.682384\n",
      "Episode:  4195 Reward: -200.0 Epsilon 0.1 mean q -16.671494\n",
      "Episode:  4196 Reward: -200.0 Epsilon 0.1 mean q -16.644218\n",
      "Episode:  4197 Reward: -200.0 Epsilon 0.1 mean q -16.660828\n",
      "Episode:  4198 Reward: -200.0 Epsilon 0.1 mean q -16.660942\n",
      "Episode:  4199 Reward: -200.0 Epsilon 0.1 mean q -16.641674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  4200 Reward: -200.0 Epsilon 0.1 mean q -16.687395\n",
      "Episode:  4201 Reward: -200.0 Epsilon 0.1 mean q -16.669916\n",
      "Episode:  4202 Reward: -200.0 Epsilon 0.1 mean q -16.633125\n",
      "Episode:  4203 Reward: -200.0 Epsilon 0.1 mean q -16.663342\n",
      "Episode:  4204 Reward: -200.0 Epsilon 0.1 mean q -16.687044\n",
      "Episode:  4205 Reward: -200.0 Epsilon 0.1 mean q -16.65391\n",
      "Episode:  4206 Reward: -200.0 Epsilon 0.1 mean q -16.672447\n",
      "Episode:  4207 Reward: -200.0 Epsilon 0.1 mean q -16.670898\n",
      "Episode:  4208 Reward: -200.0 Epsilon 0.1 mean q -16.652803\n",
      "Episode:  4209 Reward: -200.0 Epsilon 0.1 mean q -16.64151\n",
      "Episode:  4210 Reward: -200.0 Epsilon 0.1 mean q -16.681107\n",
      "Episode:  4211 Reward: -200.0 Epsilon 0.1 mean q -16.6916\n",
      "Episode:  4212 Reward: -200.0 Epsilon 0.1 mean q -16.710983\n",
      "Episode:  4213 Reward: -200.0 Epsilon 0.1 mean q -16.661724\n",
      "Episode:  4214 Reward: -200.0 Epsilon 0.1 mean q -16.66702\n",
      "Episode:  4215 Reward: -200.0 Epsilon 0.1 mean q -16.667204\n",
      "Episode:  4216 Reward: -200.0 Epsilon 0.1 mean q -16.691862\n",
      "Episode:  4217 Reward: -200.0 Epsilon 0.1 mean q -16.660309\n",
      "Episode:  4218 Reward: -200.0 Epsilon 0.1 mean q -16.64426\n",
      "Episode:  4219 Reward: -200.0 Epsilon 0.1 mean q -16.661238\n",
      "Episode:  4220 Reward: -200.0 Epsilon 0.1 mean q -16.676296\n",
      "Episode:  4221 Reward: -200.0 Epsilon 0.1 mean q -16.634264\n",
      "Episode:  4222 Reward: -200.0 Epsilon 0.1 mean q -16.66706\n",
      "Episode:  4223 Reward: -200.0 Epsilon 0.1 mean q -16.64804\n",
      "Episode:  4224 Reward: -200.0 Epsilon 0.1 mean q -16.672705\n",
      "Episode:  4225 Reward: -200.0 Epsilon 0.1 mean q -16.66515\n",
      "Episode:  4226 Reward: -200.0 Epsilon 0.1 mean q -16.644625\n",
      "Episode:  4227 Reward: -200.0 Epsilon 0.1 mean q -16.674685\n",
      "Episode:  4228 Reward: -200.0 Epsilon 0.1 mean q -16.65631\n",
      "Episode:  4229 Reward: -200.0 Epsilon 0.1 mean q -16.680918\n",
      "Episode:  4230 Reward: -200.0 Epsilon 0.1 mean q -16.658766\n",
      "Episode:  4231 Reward: -200.0 Epsilon 0.1 mean q -16.702868\n",
      "Episode:  4232 Reward: -200.0 Epsilon 0.1 mean q -16.649565\n",
      "Episode:  4233 Reward: -200.0 Epsilon 0.1 mean q -16.655182\n",
      "Episode:  4234 Reward: -200.0 Epsilon 0.1 mean q -16.683353\n",
      "Episode:  4235 Reward: -200.0 Epsilon 0.1 mean q -16.641054\n",
      "Episode:  4236 Reward: -200.0 Epsilon 0.1 mean q -16.687538\n",
      "Episode:  4237 Reward: -200.0 Epsilon 0.1 mean q -16.703814\n",
      "Episode:  4238 Reward: -200.0 Epsilon 0.1 mean q -16.641699\n",
      "Episode:  4239 Reward: -200.0 Epsilon 0.1 mean q -16.648031\n",
      "Episode:  4240 Reward: -200.0 Epsilon 0.1 mean q -16.693756\n",
      "Episode:  4241 Reward: -200.0 Epsilon 0.1 mean q -16.649607\n",
      "Episode:  4242 Reward: -200.0 Epsilon 0.1 mean q -16.68861\n",
      "Episode:  4243 Reward: -200.0 Epsilon 0.1 mean q -16.671604\n",
      "Episode:  4244 Reward: -200.0 Epsilon 0.1 mean q -16.664774\n",
      "Episode:  4245 Reward: -200.0 Epsilon 0.1 mean q -16.657604\n",
      "Episode:  4246 Reward: -200.0 Epsilon 0.1 mean q -16.68721\n",
      "Episode:  4247 Reward: -200.0 Epsilon 0.1 mean q -16.658157\n",
      "Episode:  4248 Reward: -200.0 Epsilon 0.1 mean q -16.68341\n",
      "Episode:  4249 Reward: -200.0 Epsilon 0.1 mean q -16.706926\n",
      "Episode:  4250 Reward: -200.0 Epsilon 0.1 mean q -16.662249\n",
      "Episode:  4251 Reward: -200.0 Epsilon 0.1 mean q -16.6789\n",
      "Episode:  4252 Reward: -200.0 Epsilon 0.1 mean q -16.651442\n",
      "Episode:  4253 Reward: -200.0 Epsilon 0.1 mean q -16.68217\n",
      "Episode:  4254 Reward: -200.0 Epsilon 0.1 mean q -16.70984\n",
      "Episode:  4255 Reward: -200.0 Epsilon 0.1 mean q -16.678946\n",
      "Episode:  4256 Reward: -200.0 Epsilon 0.1 mean q -16.634869\n",
      "Episode:  4257 Reward: -200.0 Epsilon 0.1 mean q -16.627691\n",
      "Episode:  4258 Reward: -200.0 Epsilon 0.1 mean q -16.671505\n",
      "Episode:  4259 Reward: -200.0 Epsilon 0.1 mean q -16.644867\n",
      "Episode:  4260 Reward: -200.0 Epsilon 0.1 mean q -16.672476\n",
      "Episode:  4261 Reward: -200.0 Epsilon 0.1 mean q -16.650316\n",
      "Episode:  4262 Reward: -200.0 Epsilon 0.1 mean q -16.654343\n",
      "Episode:  4263 Reward: -200.0 Epsilon 0.1 mean q -16.63888\n",
      "Episode:  4264 Reward: -200.0 Epsilon 0.1 mean q -16.684746\n",
      "Episode:  4265 Reward: -200.0 Epsilon 0.1 mean q -16.677187\n",
      "Episode:  4266 Reward: -200.0 Epsilon 0.1 mean q -16.697805\n",
      "Episode:  4267 Reward: -200.0 Epsilon 0.1 mean q -16.73545\n",
      "Episode:  4268 Reward: -200.0 Epsilon 0.1 mean q -16.653635\n",
      "Episode:  4269 Reward: -200.0 Epsilon 0.1 mean q -16.686937\n",
      "Episode:  4270 Reward: -200.0 Epsilon 0.1 mean q -16.67056\n",
      "Episode:  4271 Reward: -200.0 Epsilon 0.1 mean q -16.661217\n",
      "Episode:  4272 Reward: -200.0 Epsilon 0.1 mean q -16.667526\n",
      "Episode:  4273 Reward: -200.0 Epsilon 0.1 mean q -16.679605\n",
      "Episode:  4274 Reward: -200.0 Epsilon 0.1 mean q -16.675085\n",
      "Episode:  4275 Reward: -200.0 Epsilon 0.1 mean q -16.68573\n",
      "Episode:  4276 Reward: -200.0 Epsilon 0.1 mean q -16.661764\n",
      "Episode:  4277 Reward: -200.0 Epsilon 0.1 mean q -16.675264\n",
      "Episode:  4278 Reward: -200.0 Epsilon 0.1 mean q -16.692142\n",
      "Episode:  4279 Reward: -200.0 Epsilon 0.1 mean q -16.67487\n",
      "Episode:  4280 Reward: -200.0 Epsilon 0.1 mean q -16.679892\n",
      "Episode:  4281 Reward: -200.0 Epsilon 0.1 mean q -16.69603\n",
      "Episode:  4282 Reward: -200.0 Epsilon 0.1 mean q -16.643269\n",
      "Episode:  4283 Reward: -200.0 Epsilon 0.1 mean q -16.670681\n",
      "Episode:  4284 Reward: -200.0 Epsilon 0.1 mean q -16.679098\n",
      "Episode:  4285 Reward: -200.0 Epsilon 0.1 mean q -16.638956\n",
      "Episode:  4286 Reward: -200.0 Epsilon 0.1 mean q -16.677454\n",
      "Episode:  4287 Reward: -200.0 Epsilon 0.1 mean q -16.666431\n",
      "Episode:  4288 Reward: -200.0 Epsilon 0.1 mean q -16.668175\n",
      "Episode:  4289 Reward: -200.0 Epsilon 0.1 mean q -16.644308\n",
      "Episode:  4290 Reward: -200.0 Epsilon 0.1 mean q -16.690348\n",
      "Episode:  4291 Reward: -200.0 Epsilon 0.1 mean q -16.659256\n",
      "Episode:  4292 Reward: -200.0 Epsilon 0.1 mean q -16.654373\n",
      "Episode:  4293 Reward: -200.0 Epsilon 0.1 mean q -16.635185\n",
      "Episode:  4294 Reward: -200.0 Epsilon 0.1 mean q -16.680084\n",
      "Episode:  4295 Reward: -200.0 Epsilon 0.1 mean q -16.658382\n",
      "Episode:  4296 Reward: -200.0 Epsilon 0.1 mean q -16.705858\n",
      "Episode:  4297 Reward: -200.0 Epsilon 0.1 mean q -16.652933\n",
      "Episode:  4298 Reward: -200.0 Epsilon 0.1 mean q -16.688614\n",
      "Episode:  4299 Reward: -200.0 Epsilon 0.1 mean q -16.67774\n",
      "Episode:  4300 Reward: -200.0 Epsilon 0.1 mean q -16.655409\n",
      "Episode:  4301 Reward: -200.0 Epsilon 0.1 mean q -16.646631\n",
      "Episode:  4302 Reward: -200.0 Epsilon 0.1 mean q -16.648655\n",
      "Episode:  4303 Reward: -200.0 Epsilon 0.1 mean q -16.659204\n",
      "Episode:  4304 Reward: -200.0 Epsilon 0.1 mean q -16.646338\n",
      "Episode:  4305 Reward: -200.0 Epsilon 0.1 mean q -16.651726\n",
      "Episode:  4306 Reward: -200.0 Epsilon 0.1 mean q -16.66496\n",
      "Episode:  4307 Reward: -200.0 Epsilon 0.1 mean q -16.658724\n",
      "Episode:  4308 Reward: -200.0 Epsilon 0.1 mean q -16.653643\n",
      "Episode:  4309 Reward: -200.0 Epsilon 0.1 mean q -16.66901\n",
      "Episode:  4310 Reward: -200.0 Epsilon 0.1 mean q -16.653164\n",
      "Episode:  4311 Reward: -200.0 Epsilon 0.1 mean q -16.658031\n",
      "Episode:  4312 Reward: -200.0 Epsilon 0.1 mean q -16.670115\n",
      "Episode:  4313 Reward: -200.0 Epsilon 0.1 mean q -16.619028\n",
      "Episode:  4314 Reward: -200.0 Epsilon 0.1 mean q -16.665707\n",
      "Episode:  4315 Reward: -200.0 Epsilon 0.1 mean q -16.691765\n",
      "Episode:  4316 Reward: -200.0 Epsilon 0.1 mean q -16.699821\n",
      "Episode:  4317 Reward: -200.0 Epsilon 0.1 mean q -16.653048\n",
      "Episode:  4318 Reward: -200.0 Epsilon 0.1 mean q -16.681656\n",
      "Episode:  4319 Reward: -200.0 Epsilon 0.1 mean q -16.689404\n",
      "Episode:  4320 Reward: -200.0 Epsilon 0.1 mean q -16.70471\n",
      "Episode:  4321 Reward: -200.0 Epsilon 0.1 mean q -16.706238\n",
      "Episode:  4322 Reward: -200.0 Epsilon 0.1 mean q -16.655252\n",
      "Episode:  4323 Reward: -200.0 Epsilon 0.1 mean q -16.708073\n",
      "Episode:  4324 Reward: -200.0 Epsilon 0.1 mean q -16.676195\n",
      "Episode:  4325 Reward: -200.0 Epsilon 0.1 mean q -16.647783\n",
      "Episode:  4326 Reward: -200.0 Epsilon 0.1 mean q -16.6724\n",
      "Episode:  4327 Reward: -200.0 Epsilon 0.1 mean q -16.653692\n",
      "Episode:  4328 Reward: -200.0 Epsilon 0.1 mean q -16.666498\n",
      "Episode:  4329 Reward: -200.0 Epsilon 0.1 mean q -16.678099\n",
      "Episode:  4330 Reward: -200.0 Epsilon 0.1 mean q -16.692345\n",
      "Episode:  4331 Reward: -200.0 Epsilon 0.1 mean q -16.679152\n",
      "Episode:  4332 Reward: -200.0 Epsilon 0.1 mean q -16.714525\n",
      "Episode:  4333 Reward: -200.0 Epsilon 0.1 mean q -16.662428\n",
      "Episode:  4334 Reward: -200.0 Epsilon 0.1 mean q -16.648434\n",
      "Episode:  4335 Reward: -200.0 Epsilon 0.1 mean q -16.637455\n",
      "Episode:  4336 Reward: -200.0 Epsilon 0.1 mean q -16.641047\n",
      "Episode:  4337 Reward: -200.0 Epsilon 0.1 mean q -16.698624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  4338 Reward: -200.0 Epsilon 0.1 mean q -16.638994\n",
      "Episode:  4339 Reward: -200.0 Epsilon 0.1 mean q -16.653992\n",
      "Episode:  4340 Reward: -200.0 Epsilon 0.1 mean q -16.645456\n",
      "Episode:  4341 Reward: -200.0 Epsilon 0.1 mean q -16.660362\n",
      "Episode:  4342 Reward: -200.0 Epsilon 0.1 mean q -16.66446\n",
      "Episode:  4343 Reward: -200.0 Epsilon 0.1 mean q -16.644646\n",
      "Episode:  4344 Reward: -200.0 Epsilon 0.1 mean q -16.638334\n",
      "Episode:  4345 Reward: -200.0 Epsilon 0.1 mean q -16.631256\n",
      "Episode:  4346 Reward: -200.0 Epsilon 0.1 mean q -16.668417\n",
      "Episode:  4347 Reward: -200.0 Epsilon 0.1 mean q -16.709866\n",
      "Episode:  4348 Reward: -200.0 Epsilon 0.1 mean q -16.664116\n",
      "Episode:  4349 Reward: -200.0 Epsilon 0.1 mean q -16.690098\n",
      "Episode:  4350 Reward: -200.0 Epsilon 0.1 mean q -16.680653\n",
      "Episode:  4351 Reward: -200.0 Epsilon 0.1 mean q -16.66519\n",
      "Episode:  4352 Reward: -200.0 Epsilon 0.1 mean q -16.673008\n",
      "Episode:  4353 Reward: -200.0 Epsilon 0.1 mean q -16.661352\n",
      "Episode:  4354 Reward: -200.0 Epsilon 0.1 mean q -16.646526\n",
      "Episode:  4355 Reward: -200.0 Epsilon 0.1 mean q -16.690279\n",
      "Episode:  4356 Reward: -200.0 Epsilon 0.1 mean q -16.629454\n",
      "Episode:  4357 Reward: -200.0 Epsilon 0.1 mean q -16.6757\n",
      "Episode:  4358 Reward: -200.0 Epsilon 0.1 mean q -16.669926\n",
      "Episode:  4359 Reward: -200.0 Epsilon 0.1 mean q -16.66054\n",
      "Episode:  4360 Reward: -200.0 Epsilon 0.1 mean q -16.685\n",
      "Episode:  4361 Reward: -200.0 Epsilon 0.1 mean q -16.69111\n",
      "Episode:  4362 Reward: -200.0 Epsilon 0.1 mean q -16.658672\n",
      "Episode:  4363 Reward: -200.0 Epsilon 0.1 mean q -16.652985\n",
      "Episode:  4364 Reward: -200.0 Epsilon 0.1 mean q -16.665472\n",
      "Episode:  4365 Reward: -200.0 Epsilon 0.1 mean q -16.653187\n",
      "Episode:  4366 Reward: -200.0 Epsilon 0.1 mean q -16.680336\n",
      "Episode:  4367 Reward: -200.0 Epsilon 0.1 mean q -16.650303\n",
      "Episode:  4368 Reward: -200.0 Epsilon 0.1 mean q -16.675932\n",
      "Episode:  4369 Reward: -200.0 Epsilon 0.1 mean q -16.671227\n",
      "Episode:  4370 Reward: -200.0 Epsilon 0.1 mean q -16.677422\n",
      "Episode:  4371 Reward: -200.0 Epsilon 0.1 mean q -16.670458\n",
      "Episode:  4372 Reward: -200.0 Epsilon 0.1 mean q -16.701178\n",
      "Episode:  4373 Reward: -200.0 Epsilon 0.1 mean q -16.66099\n",
      "Episode:  4374 Reward: -200.0 Epsilon 0.1 mean q -16.661333\n",
      "Episode:  4375 Reward: -200.0 Epsilon 0.1 mean q -16.660242\n",
      "Episode:  4376 Reward: -200.0 Epsilon 0.1 mean q -16.697567\n",
      "Episode:  4377 Reward: -200.0 Epsilon 0.1 mean q -16.663412\n",
      "Episode:  4378 Reward: -200.0 Epsilon 0.1 mean q -16.660336\n",
      "Episode:  4379 Reward: -200.0 Epsilon 0.1 mean q -16.67359\n",
      "Episode:  4380 Reward: -200.0 Epsilon 0.1 mean q -16.658846\n",
      "Episode:  4381 Reward: -200.0 Epsilon 0.1 mean q -16.668175\n",
      "Episode:  4382 Reward: -200.0 Epsilon 0.1 mean q -16.688679\n",
      "Episode:  4383 Reward: -200.0 Epsilon 0.1 mean q -16.640186\n",
      "Episode:  4384 Reward: -200.0 Epsilon 0.1 mean q -16.661552\n",
      "Episode:  4385 Reward: -200.0 Epsilon 0.1 mean q -16.695385\n",
      "Episode:  4386 Reward: -200.0 Epsilon 0.1 mean q -16.650719\n",
      "Episode:  4387 Reward: -200.0 Epsilon 0.1 mean q -16.655052\n",
      "Episode:  4388 Reward: -200.0 Epsilon 0.1 mean q -16.655052\n",
      "Episode:  4389 Reward: -200.0 Epsilon 0.1 mean q -16.650347\n",
      "Episode:  4390 Reward: -200.0 Epsilon 0.1 mean q -16.665874\n",
      "Episode:  4391 Reward: -200.0 Epsilon 0.1 mean q -16.658623\n",
      "Episode:  4392 Reward: -200.0 Epsilon 0.1 mean q -16.638025\n",
      "Episode:  4393 Reward: -200.0 Epsilon 0.1 mean q -16.654388\n",
      "Episode:  4394 Reward: -200.0 Epsilon 0.1 mean q -16.638668\n",
      "Episode:  4395 Reward: -200.0 Epsilon 0.1 mean q -16.641407\n",
      "Episode:  4396 Reward: -200.0 Epsilon 0.1 mean q -16.635973\n",
      "Episode:  4397 Reward: -200.0 Epsilon 0.1 mean q -16.624697\n",
      "Episode:  4398 Reward: -200.0 Epsilon 0.1 mean q -16.669239\n",
      "Episode:  4399 Reward: -200.0 Epsilon 0.1 mean q -16.640257\n",
      "Episode:  4400 Reward: -200.0 Epsilon 0.1 mean q -16.660496\n",
      "Episode:  4401 Reward: -200.0 Epsilon 0.1 mean q -16.66347\n",
      "Episode:  4402 Reward: -200.0 Epsilon 0.1 mean q -16.651117\n",
      "Episode:  4403 Reward: -200.0 Epsilon 0.1 mean q -16.700045\n",
      "Episode:  4404 Reward: -200.0 Epsilon 0.1 mean q -16.685617\n",
      "Episode:  4405 Reward: -200.0 Epsilon 0.1 mean q -16.665277\n",
      "Episode:  4406 Reward: -200.0 Epsilon 0.1 mean q -16.688648\n",
      "Episode:  4407 Reward: -200.0 Epsilon 0.1 mean q -16.653547\n",
      "Episode:  4408 Reward: -200.0 Epsilon 0.1 mean q -16.667614\n",
      "Episode:  4409 Reward: -200.0 Epsilon 0.1 mean q -16.654772\n",
      "Episode:  4410 Reward: -200.0 Epsilon 0.1 mean q -16.66\n",
      "Episode:  4411 Reward: -200.0 Epsilon 0.1 mean q -16.683851\n",
      "Episode:  4412 Reward: -200.0 Epsilon 0.1 mean q -16.63069\n",
      "Episode:  4413 Reward: -200.0 Epsilon 0.1 mean q -16.682856\n",
      "Episode:  4414 Reward: -200.0 Epsilon 0.1 mean q -16.672773\n",
      "Episode:  4415 Reward: -200.0 Epsilon 0.1 mean q -16.68181\n",
      "Episode:  4416 Reward: -200.0 Epsilon 0.1 mean q -16.673365\n",
      "Episode:  4417 Reward: -200.0 Epsilon 0.1 mean q -16.64078\n",
      "Episode:  4418 Reward: -200.0 Epsilon 0.1 mean q -16.661053\n",
      "Episode:  4419 Reward: -200.0 Epsilon 0.1 mean q -16.689669\n",
      "Episode:  4420 Reward: -200.0 Epsilon 0.1 mean q -16.657753\n",
      "Episode:  4421 Reward: -200.0 Epsilon 0.1 mean q -16.65842\n",
      "Episode:  4422 Reward: -200.0 Epsilon 0.1 mean q -16.638643\n",
      "Episode:  4423 Reward: -200.0 Epsilon 0.1 mean q -16.674921\n",
      "Episode:  4424 Reward: -200.0 Epsilon 0.1 mean q -16.686714\n",
      "Episode:  4425 Reward: -200.0 Epsilon 0.1 mean q -16.664711\n",
      "Episode:  4426 Reward: -200.0 Epsilon 0.1 mean q -16.67032\n",
      "Episode:  4427 Reward: -200.0 Epsilon 0.1 mean q -16.689348\n",
      "Episode:  4428 Reward: -200.0 Epsilon 0.1 mean q -16.65491\n",
      "Episode:  4429 Reward: -200.0 Epsilon 0.1 mean q -16.655256\n",
      "Episode:  4430 Reward: -200.0 Epsilon 0.1 mean q -16.654724\n",
      "Episode:  4431 Reward: -200.0 Epsilon 0.1 mean q -16.652624\n",
      "Episode:  4432 Reward: -200.0 Epsilon 0.1 mean q -16.653831\n",
      "Episode:  4433 Reward: -200.0 Epsilon 0.1 mean q -16.619102\n",
      "Episode:  4434 Reward: -200.0 Epsilon 0.1 mean q -16.671618\n",
      "Episode:  4435 Reward: -200.0 Epsilon 0.1 mean q -16.67369\n",
      "Episode:  4436 Reward: -200.0 Epsilon 0.1 mean q -16.65937\n",
      "Episode:  4437 Reward: -200.0 Epsilon 0.1 mean q -16.70633\n",
      "Episode:  4438 Reward: -200.0 Epsilon 0.1 mean q -16.695488\n",
      "Episode:  4439 Reward: -200.0 Epsilon 0.1 mean q -16.670576\n",
      "Episode:  4440 Reward: -200.0 Epsilon 0.1 mean q -16.663853\n",
      "Episode:  4441 Reward: -200.0 Epsilon 0.1 mean q -16.656818\n",
      "Episode:  4442 Reward: -200.0 Epsilon 0.1 mean q -16.624584\n",
      "Episode:  4443 Reward: -200.0 Epsilon 0.1 mean q -16.687197\n",
      "Episode:  4444 Reward: -200.0 Epsilon 0.1 mean q -16.664646\n",
      "Episode:  4445 Reward: -200.0 Epsilon 0.1 mean q -16.639088\n",
      "Episode:  4446 Reward: -200.0 Epsilon 0.1 mean q -16.699514\n",
      "Episode:  4447 Reward: -200.0 Epsilon 0.1 mean q -16.685472\n",
      "Episode:  4448 Reward: -200.0 Epsilon 0.1 mean q -16.646833\n",
      "Episode:  4449 Reward: -200.0 Epsilon 0.1 mean q -16.659397\n",
      "Episode:  4450 Reward: -200.0 Epsilon 0.1 mean q -16.655384\n",
      "Episode:  4451 Reward: -200.0 Epsilon 0.1 mean q -16.613207\n",
      "Episode:  4452 Reward: -200.0 Epsilon 0.1 mean q -16.660212\n",
      "Episode:  4453 Reward: -200.0 Epsilon 0.1 mean q -16.668425\n",
      "Episode:  4454 Reward: -200.0 Epsilon 0.1 mean q -16.671244\n",
      "Episode:  4455 Reward: -200.0 Epsilon 0.1 mean q -16.657845\n",
      "Episode:  4456 Reward: -200.0 Epsilon 0.1 mean q -16.617022\n",
      "Episode:  4457 Reward: -200.0 Epsilon 0.1 mean q -16.633627\n",
      "Episode:  4458 Reward: -200.0 Epsilon 0.1 mean q -16.646599\n",
      "Episode:  4459 Reward: -200.0 Epsilon 0.1 mean q -16.66457\n",
      "Episode:  4460 Reward: -200.0 Epsilon 0.1 mean q -16.689838\n",
      "Episode:  4461 Reward: -200.0 Epsilon 0.1 mean q -16.671423\n",
      "Episode:  4462 Reward: -200.0 Epsilon 0.1 mean q -16.657307\n",
      "Episode:  4463 Reward: -200.0 Epsilon 0.1 mean q -16.650957\n",
      "Episode:  4464 Reward: -200.0 Epsilon 0.1 mean q -16.676113\n",
      "Episode:  4465 Reward: -200.0 Epsilon 0.1 mean q -16.687294\n",
      "Episode:  4466 Reward: -200.0 Epsilon 0.1 mean q -16.644157\n",
      "Episode:  4467 Reward: -200.0 Epsilon 0.1 mean q -16.665411\n",
      "Episode:  4468 Reward: -200.0 Epsilon 0.1 mean q -16.685963\n",
      "Episode:  4469 Reward: -200.0 Epsilon 0.1 mean q -16.676273\n",
      "Episode:  4470 Reward: -200.0 Epsilon 0.1 mean q -16.656612\n",
      "Episode:  4471 Reward: -200.0 Epsilon 0.1 mean q -16.67607\n",
      "Episode:  4472 Reward: -200.0 Epsilon 0.1 mean q -16.685202\n",
      "Episode:  4473 Reward: -200.0 Epsilon 0.1 mean q -16.679094\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"Acrobot-v1\")\n",
    "\n",
    "# Initializations\n",
    "num_actions = env.action_space.n\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "print(env.observation_space)\n",
    "# Our Neural Netork model used to estimate the Q-values\n",
    "model = DoubleQLearningModel(state_dim=obs_dim, action_dim=num_actions, learning_rate=1e-4)\n",
    "\n",
    "# Create replay buffer, where experience in form of tuples <s,a,r,s',t>, gathered from the environment is stored \n",
    "# for training\n",
    "replay_buffer = ExperienceReplay(state_size=obs_dim)\n",
    "\n",
    "# Train\n",
    "num_episodes = 15000\n",
    "batch_size = 256\n",
    "R, R_avg = train_loop_ddqn(model, env, num_episodes, batch_size, eps_decay=0.001,stopping_criteria=-110.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_episodes = 1\n",
    "env = gym.make(\"Acrobot-v1\")\n",
    "\n",
    "for i in range(num_episodes):\n",
    "        state = eMountainCar-v0nv.reset() #reset to initial state\n",
    "        state = np.expand_dims(state, axis=0)/2\n",
    "        terminal = False # reset terminal flag\n",
    "        while not terminal:\n",
    "            env.render()\n",
    "            time.sleep(.04)\n",
    "            q_values = model.get_q_values(state)\n",
    "            policy = eps_greedy_policy(q_values.squeeze(), .1) # greedy policy\n",
    "            action = np.random.choice(num_actions, p=policy)\n",
    "            state, reward, terminal, _ = env.step(action) # take one step in the evironment\n",
    "            state = np.expand_dims(state, axis=0)/2\n",
    "# close window\n",
    "env.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6be3464a29fcec53d4c2434c8af73acd",
     "grade": false,
     "grade_id": "cell-671cfb5a590863e9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Task 3.2 Atari games\n",
    "\n",
    "A common benchmark for reinforcement learning algorithms is the old Atari games. For the Atari games, each observation consists of one screenshot of the current state of the game. Other than adding convolutional layers to your neural network, there is one more issue regarding the new input that needs to be solved. Name at least two solutions to the problem, and why it won't work without these changes. \n",
    "\n",
    "Hint:\n",
    "- Imagine the game of pong. What is important for the algorithm to predict? What is the input to the algorithm? Is it possible to predict what we want from the input given?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8c57f74e2e49c6ee244370df1b46e5a2",
     "grade": true,
     "grade_id": "cell-55e109dd6169612b",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Your answer:** (fill in here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
